{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T12:42:27.569422Z",
     "start_time": "2020-06-22T12:42:21.862980Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run ./FIR_Helper_Methods.ipynb\n",
    "helper_method = helper_methods()\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T18:03:13.228860Z",
     "start_time": "2020-06-21T18:03:11.842860Z"
    }
   },
   "outputs": [],
   "source": [
    "class review_ranked_fairness_UI():\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "\n",
    "        self.ranked_df = kwargs['ranked_df']\n",
    "        self.protected_attributes = kwargs['protected_attributes']\n",
    "        self.group_names = kwargs['group_names']\n",
    "        self.renamed_groups = kwargs['renamed_groups']\n",
    "        self.encoded_groups = kwargs['encoded_groups']\n",
    "\n",
    "        self.high_ranking_positive = kwargs['high_ranking_positive']\n",
    "        self.HIGH_RANGE_POSITIVE = 1\n",
    "        if self.high_ranking_positive == False:\n",
    "            self.HIGH_RANGE_POSITIVE = 0\n",
    "\n",
    "        self.style = {'description_width': 'initial'}\n",
    "        self.layout = {'width': '700px'}\n",
    "        self.layout_short = {'width': '300px'}\n",
    "        self.layout = {'width': 'auto'}\n",
    "        self.layout_short = {'width': 'auto'}\n",
    "        \n",
    "        self.auto_width_layout = {'width': 'auto'}  \n",
    "        \n",
    "        self.dictOfSlidersPercent = {}\n",
    "\n",
    "        self.ranked_df_top = pd.DataFrame()\n",
    "\n",
    "        # Either upload the file or create the class with pandas Dataframe as input\n",
    "        self.fileUploader = FileUpload(accept='.csv',\n",
    "                                       multiple=False,\n",
    "                                       disabled=False,\n",
    "                                       style_button='color: darkblue; background-color: lightsalmon; width: 180px;',\n",
    "                                       compress_level=9\n",
    "                                       )\n",
    "\n",
    "\n",
    "        self.selectYAttribute = widgets.Dropdown(\n",
    "            options=self.ranked_df.columns.values,\n",
    "            value=\"Predicted\",\n",
    "            description='Ranked Output:',\n",
    "            disabled=False,\n",
    "            style=self.style,\n",
    "            layout=self.layout\n",
    "        )\n",
    "\n",
    "        self.selectImpact = widgets.RadioButtons(\n",
    "            options={'A Positive impact on the the life of the individual i.e Assistive': 1,\n",
    "                     'A negative impact on the the life of the individual i.e Punitive': 0},\n",
    "            description='For decisions, a high rank will results in:',\n",
    "            disabled=False,\n",
    "            layout=self.layout,\n",
    "            style=self.style,\n",
    "            value=self.HIGH_RANGE_POSITIVE\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.view_attributes_button = widgets.Button(\n",
    "            description='View Full Ranked List',\n",
    "            disabled=False,\n",
    "            button_style='',  # 'success', 'info', 'warning', 'danger' or ''\n",
    "            tooltip='Click me',\n",
    "            layout = self.auto_width_layout\n",
    "            \n",
    "        )\n",
    "        \n",
    "        self.view_attributes_reduced_list_button = widgets.Button(\n",
    "            description='View ',\n",
    "            disabled=False,\n",
    "            button_style='',  # 'success', 'info', 'warning', 'danger' or ''\n",
    "            tooltip='Click me',\n",
    "            layout = self.auto_width_layout\n",
    "            \n",
    "        )\n",
    "\n",
    "        self.percentOrTopK = widgets.RadioButtons(\n",
    "            options={'Top-K results': 1,\n",
    "                     'Top-K percent of results': 0},\n",
    "            description='For analysis use:',\n",
    "            disabled=False,\n",
    "            layout=self.layout,\n",
    "            style=self.style,\n",
    "            value=1\n",
    "        )\n",
    "\n",
    "        def on_impact_selected(change):\n",
    "            if (change['new'] == 1):\n",
    "                self.HIGH_RANGE_POSITIVE = 1\n",
    "            if (change['new'] == 0):\n",
    "                self.HIGH_RANGE_POSITIVE = 0\n",
    "        self.selectImpact.observe(on_impact_selected, names='value')\n",
    "\n",
    "        # use to define the selected attributes, one or more\n",
    "        self.selectProtectedAttributes = widgets.SelectMultiple(\n",
    "            options=self.ranked_df.columns.values,\n",
    "            value=self.protected_attributes,\n",
    "            description='Protected Attribute(s)',\n",
    "            disabled=False,\n",
    "            style=self.style,\n",
    "            layout=self.layout\n",
    "        )\n",
    "\n",
    "        # use to select the protected attribute to examine\n",
    "        self.selectProtectedAttributeToExamine = widgets.Dropdown(\n",
    "            description='Protected Attributes',\n",
    "            disabled=False,\n",
    "            style=self.style,\n",
    "            layout=self.layout\n",
    "        )\n",
    "        \n",
    "        \n",
    "         # use to select the protected attribute to examine\n",
    "        self.selectProtectedAttributeToExamineReferenceGroup = widgets.Dropdown(\n",
    "            description='Reference Group',\n",
    "            disabled=False,\n",
    "            style=self.style,\n",
    "            layout=self.layout\n",
    "        )\n",
    "\n",
    "        self.choosen_attribute_values = widgets.SelectMultiple(\n",
    "            description='Select attribute value',\n",
    "            disabled=False,\n",
    "            style=self.style,\n",
    "            layout=self.layout_short\n",
    "        )\n",
    "\n",
    "        self.selectFairnessMeasure = widgets.Dropdown(\n",
    "            options=['Counterfactual fairness', \n",
    "                     'Equality of outcome',\n",
    "                     '3'],\n",
    "            # rows=10,\n",
    "            \n",
    "            description='Select the definition of fairness that best applies',\n",
    "            disabled=False,\n",
    "            style=self.style,\n",
    "            layout=self.layout\n",
    "        )\n",
    "        \n",
    "        self.selectFairnessGoal = widgets.Dropdown(\n",
    "            options={'Equal numbers from each group':1, \n",
    "                     'Proportional to representation in population':2,\n",
    "                     'Proportional to representation in domain':3, \n",
    "                     'Proportional to representation in dataset':4,\n",
    "                     'Individual Fairness':5},\n",
    "            description='Fairness goal',\n",
    "            disabled=False,\n",
    "            style=self.style,\n",
    "            layout=self.layout\n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.selectWorldView = widgets.Dropdown(\n",
    "            options={'What you see is what you get':1, \n",
    "                     'We are all equal':2},\n",
    "            description='Fairness worldview',\n",
    "            disabled=False,\n",
    "            style=self.style,\n",
    "            layout=self.layout\n",
    "        )\n",
    "\n",
    "\n",
    "        self.selectPercentageOfResults = widgets.Dropdown(\n",
    "            options=[10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "            # rows=10,\n",
    "            description='Top-K percent of results: ',\n",
    "            disabled=False,\n",
    "            style=self.style,\n",
    "            layout=self.layout\n",
    "        )\n",
    "\n",
    "        self.selectTopKResults = widgets.IntText(\n",
    "            value=200,\n",
    "            description='Top-K results:            ',\n",
    "            disabled=False,\n",
    "            style=self.style,\n",
    "            layout=self.layout,\n",
    "            max=1000,\n",
    "            min=0,\n",
    "        )\n",
    "        \n",
    "        \n",
    "        # Exposure Drop Measure - Relating to the concept of uneven distribution of attention\n",
    "        self.selectExpDropMeasure = widgets.Dropdown(\n",
    "            options={'Standard logarithmic discount (using average)':2,\n",
    "                     'Standard logarithmic discount (using sum)':1,\n",
    "                     'Geometric Distribution - Biega et al (TBD)':3, \n",
    "                     'Viable-n test(TBD)':4},\n",
    "            # rows=10,\n",
    "            description='Exposure Drop-off (Position Bias)',\n",
    "            disabled=False,\n",
    "            style=self.style,\n",
    "            layout=self.layout\n",
    "        )\n",
    "        \n",
    "        self.setSignificance = widgets.FloatSlider(\n",
    "            value=0.1,\n",
    "            min=0,\n",
    "            max=1.0,\n",
    "            step=0.1,\n",
    "            description='Significance paramater (a):',\n",
    "            disabled=False,\n",
    "            continuous_update=False,\n",
    "            orientation='horizontal',\n",
    "            readout=True,\n",
    "            readout_format='.1f',\n",
    "            tooltip = 'A large value means a larger probability of declaring a fair ranking unfair',\n",
    "            style=self.style,\n",
    "            layout=self.layout\n",
    "    )\n",
    "\n",
    "\n",
    "        self.list_info_out = widgets.Output(layout={})\n",
    "        self.viewProtectedPandasPlotA = widgets.Output(layout={})\n",
    "        self.viewFairOutputA = widgets.Output(layout={})\n",
    "        self.viewReducedListInfoOut = widgets.Output(layout={})\n",
    "        \n",
    "        self.upload_data_out = widgets.interactive_output(self.upload_data, {\n",
    "            'fileUploader_value': self.fileUploader})\n",
    "\n",
    "        self.select_protected_out = widgets.interactive_output(self.select_protected, {\n",
    "            'selectProtectedAttributes_values': self.selectProtectedAttributes})\n",
    "\n",
    "        self.select_ranked_list_col_out = widgets.interactive_output(self.select_ranked_column, {\n",
    "            'selectYAttribute_values': self.selectYAttribute})\n",
    "        \n",
    "        \n",
    "        self.set_reference_group_options_out = widgets.interactive_output(self.set_reference_group_options, {\n",
    "            'selectProtectedAttributeToExamine_value': self.selectProtectedAttributeToExamine})\n",
    "\n",
    "        \n",
    "        self.viewProtectedOut = widgets.Output(layout={})\n",
    "        \n",
    "\n",
    "        \n",
    "        self.view_analysis_out = widgets.interactive_output(self.run_analysis, {\n",
    "            'selectExpDropMeasure_value': self.selectExpDropMeasure,\n",
    "            'setSignificance_value': self.setSignificance})\n",
    "        \n",
    "\n",
    "        self.show_hide_ctrls_out = widgets.interactive_output(self.show_hide_ctrls, {\n",
    "            'percentOrTopK_value': self.percentOrTopK})\n",
    "        \n",
    "        self.population_slider_out = widgets.interactive_output(self.create_population_slider,{\n",
    "             'selectFairnessGoal_value':self.selectFairnessGoal\n",
    "        })\n",
    "        \n",
    "\n",
    "        \n",
    "        self.worldview_out = widgets.interactive_output(self.worldview_selected, {\n",
    "            'selectWorldView_value': self.selectWorldView})\n",
    "        \n",
    "        \n",
    "\n",
    "        # to populate the UI at startup - add this to a method later\n",
    "        self.select_protected(self.selectProtectedAttributes.value)\n",
    "        self.select_ranked_column(self.selectYAttribute.value)\n",
    "        \n",
    "        \n",
    "        self.view_attributes_button.on_click(self.on_view_attributes_button_clicked)\n",
    "        with self.view_analysis_out:\n",
    "            self.run_analysis(self.selectExpDropMeasure.value, self.setSignificance.value)      \n",
    "    \n",
    "    #################################################################################################\n",
    "    #  \n",
    "    # \n",
    "    #################################################################################################\n",
    "    def upload_data(self, fileUploader_value):\n",
    "        if not(self.ranked_df.empty):\n",
    "            self.ranked_df.reset_index(drop=True, inplace=True)\n",
    "            display(\"Ranked list already imported\")\n",
    "            display(self.ranked_df.head(5))\n",
    "        try:\n",
    "            for key in fileUploader_value:\n",
    "                display(HTML(\"uploaded: \",\n",
    "                      fileUploader_value[key]['metadata']['name']))\n",
    "                try:\n",
    "                    csvInBytes = fileUploader_value[key]['content']\n",
    "                    s = str(csvInBytes, 'utf-8')\n",
    "                    data = StringIO(s)\n",
    "                    self.ranked_df = pd.read_csv(data)\n",
    "                    csvInBytes = 0\n",
    "                    data = 0\n",
    "                    s = 0\n",
    "                    print(\"\")\n",
    "                    print(\"Snapshot of unmodified data set\")\n",
    "                    display(self.ranked_df.head(5))\n",
    "                except:\n",
    "                    print(\"Error reading file - upload new file\")\n",
    "        except:\n",
    "            print(\"Error uploading file - upload again\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    #################################################################################################\n",
    "    #  \n",
    "    # \n",
    "    #################################################################################################\n",
    "    def select_protected(self, selectProtectedAttributes_values):\n",
    "        try:\n",
    "            with self.select_protected_out:\n",
    "                clear_output(wait=True)\n",
    "                text = \"<b><font color='green'> Protected Attributes: </b> </font> \" + str(selectProtectedAttributes_values)\n",
    "                display(HTML(text)) \n",
    "                self.selectProtectedAttributeToExamine.options = selectProtectedAttributes_values\n",
    "                self.selectProtectedAttributeToExamine.value = selectProtectedAttributes_values[0] \n",
    "                \n",
    "\n",
    "        except:\n",
    "            display(\"Protected attributes not yet set\")\n",
    "\n",
    "    \n",
    "    \n",
    "    #################################################################################################\n",
    "    #  \n",
    "    # \n",
    "    #################################################################################################\n",
    "    def select_ranked_column(self, selectYAttribute_values):\n",
    "        try:\n",
    "            with self.select_ranked_list_col_out:\n",
    "                clear_output(wait=True)\n",
    "                text = \"<b><font color='green'> Ranked output column: </b> </font> \" + selectYAttribute_values\n",
    "                display(HTML(text))\n",
    "\n",
    "        except:\n",
    "            display(\"Ranked column not yet set\")\n",
    "\n",
    "   \n",
    "    \n",
    "\n",
    "    #################################################################################################\n",
    "    #  \n",
    "    # \n",
    "    #################################################################################################\n",
    "    def on_view_attributes_button_clicked (self, b):\n",
    "        try:\n",
    "            with self.viewProtectedOut:\n",
    "                clear_output(wait=True)\n",
    "                helper_method.view_protected(list(self.selectProtectedAttributes.value),\n",
    "                                             self.selectYAttribute.value,\n",
    "                                             self.ranked_df,\n",
    "                                             _w=600, _h=600,\n",
    "                                             y_high_positive = self.high_ranking_positive,\n",
    "                                             persist_impact_col = False,\n",
    "                                             output_type_binary = False)\n",
    "                    \n",
    "        except:\n",
    "            print(\"an error occured viewing protected group\")\n",
    "        \n",
    "      \n",
    "    \n",
    "     \n",
    "    \n",
    "    #################################################################################################\n",
    "    #  Show the top-k count or x-percent control depending on the percentOrTopK.value\n",
    "    # \n",
    "    #################################################################################################        \n",
    "    def show_hide_ctrls(self, percentOrTopK_value):\n",
    "        if (percentOrTopK_value == 0):\n",
    "            print (\"selectPercentageOfResults\", self.selectPercentageOfResults.value)\n",
    "            self.selectPercentageOfResults.layout.visibility = 'visible'\n",
    "            self.selectTopKResults.layout.visibility = 'hidden'\n",
    "        \n",
    "        elif  (percentOrTopK_value == 1):\n",
    "            print (\"selectPercentageOfResults\", self.selectTopKResults.value)\n",
    "            self.selectPercentageOfResults.layout.visibility = 'hidden'\n",
    "            self.selectTopKResults.layout.visibility = 'visible'\n",
    "            \n",
    "      \n",
    "    #################################################################################################\n",
    "    #  Set the contents of the reference group dropdown when the protected feature to examine\n",
    "    # dropdown (selectProtectedAttributeToExamine) changes value. And recreate the population slider\n",
    "    # based on the new protectedAttribute and reference group\n",
    "    ################################################################################################# \n",
    "    def set_reference_group_options(self, selectProtectedAttributeToExamine_value):\n",
    "                print (selectProtectedAttributeToExamine_value)\n",
    "                self.selectProtectedAttributeToExamineReferenceGroup.options = self.ranked_df[selectProtectedAttributeToExamine_value].unique()\n",
    "                self.selectProtectedAttributeToExamineReferenceGroup.value = self.selectProtectedAttributeToExamineReferenceGroup.options[0]\n",
    "                self.create_population_slider(self.selectFairnessGoal.value)   \n",
    "\n",
    "    #################################################################################################\n",
    "    #  \n",
    "    # \n",
    "    #################################################################################################   \n",
    "    def create_population_slider(self, selectFairnessGoal_value):\n",
    "       \n",
    "        \n",
    "        if not self.ranked_df.empty and not self.selectProtectedAttributeToExamine.value == None:\n",
    "            clear_output(wait=True)\n",
    "            print (\"selectFairnessGoal_value\", selectFairnessGoal_value)\n",
    "            print (self.selectProtectedAttributeToExamine.value)\n",
    "            pop_in_data = round ((self.ranked_df[self.selectProtectedAttributeToExamine.value]).value_counts(normalize=True)*100, 2)\n",
    "\n",
    "            \n",
    "            ''' selectFairnessGoal values\n",
    "            'Equal numbers from each group':1, \n",
    "            'Proportional to representation in population':2,\n",
    "            'Proportional to representation in domain':3, \n",
    "            'Affirmative action for representation in domain':4}'''\n",
    "            \n",
    "            desc = ''\n",
    "            if self.selectProtectedAttributeToExamine.value in self.renamed_groups:\n",
    "                merged_values = self.renamed_groups[self.selectProtectedAttributeToExamine.value]\n",
    "                print (\"Merged:\" ,merged_values)\n",
    "            if self.selectProtectedAttributeToExamine.value in self.group_names:\n",
    "                result = self.group_names[self.selectProtectedAttributeToExamine.value]\n",
    "                print (\"Original Group name:\" ,result)\n",
    "            if self.selectProtectedAttributeToExamine.value in self.encoded_groups:\n",
    "                encoded_values = self.encoded_groups[self.selectProtectedAttributeToExamine.value]\n",
    "                print (\"Encoded:\" ,encoded_values)\n",
    "            try:\n",
    "                if not self.ranked_df.empty and selectFairnessGoal_value != 1:\n",
    "                    allGroupsInProtected = self.ranked_df[self.selectProtectedAttributeToExamine.value].unique()\n",
    "\n",
    "                    for group in allGroupsInProtected:\n",
    "                        old_name = \"\"\n",
    "                        try:\n",
    "                            old_name = \" : \" + str(result[str(group)])\n",
    "                        except:\n",
    "                            old_name = \"\"\n",
    "                        group_col = self.selectProtectedAttributeToExamine.value\n",
    "                        if selectFairnessGoal_value == 2:\n",
    "                            desc = group_col + \":\" + str(group) + old_name  + \": Percentage of population\"\n",
    "                        \n",
    "                        elif selectFairnessGoal_value == 3:\n",
    "                            desc = group_col + \":\" + str(group) + old_name + \": Percentage of domain\"\n",
    "                        \n",
    "                        elif selectFairnessGoal_value == 4:\n",
    "                            desc = group_col + \":\" + str(group) + old_name + \": Percent in dataset\"\n",
    "                        \n",
    "                        self.dictOfSlidersPercent[group] = widgets.IntSlider(\n",
    "                                                                                    value=pop_in_data[group],\n",
    "                                                                                    description= desc ,\n",
    "                                                                                    max=100,\n",
    "                                                                                    min=0,\n",
    "                                                                                    style=self.style,\n",
    "                                                                                    layout=self.layout)\n",
    "\n",
    "        \n",
    "                        display (self.dictOfSlidersPercent[group])\n",
    "                else: \n",
    "                    print (\"Equal representation for each group:\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print (e)\n",
    "                traceback.print_exc()\n",
    "                print(\"output not generated yet\")  \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #################################################################################################\n",
    "    #  \n",
    "    # \n",
    "    #################################################################################################        \n",
    "    def worldview_selected(self, selectWorldView_value):\n",
    "        \n",
    "                    \n",
    "        html_worldview = '''\n",
    "                    <a href='https://arxiv.org/pdf/1609.07236v1.pdf'>\n",
    "                    \"On the (im)possibility of fairness∗\"</a> <br>\n",
    "                    <a href='https://arxiv.org/pdf/1808.08619.pdf'>\n",
    "                    \"A Comparison of Fairness Definitions under Different Worldviews\"</a>'''\n",
    "           \n",
    "        \n",
    "        htmlWSYWYG = HTML('''<br><b>What you see is what you get (WYSIWYG)</b> With respect to the concept of \n",
    "                                group fairness this worldview assumes that whatever the data reflects constitutes\n",
    "                                an objective picture of the world, even if inequalities appear across groups in \n",
    "                                the results. In otherwords, that measurable observations objectively reflect \n",
    "                                the ability of groups with respect to a goal(succeeding at university, paying back a loan, \n",
    "                                not re-offending, excelling in role). For example, if a model predicts that \n",
    "                                group A is overall more likely to have a more \n",
    "                                favorable distribution of positive outcomes than Group B a WYSIWIG worldview \n",
    "                                would lead one to conclude, well, that's just the way it is.<br><br>''')\n",
    "\n",
    "\n",
    "\n",
    "        htmlWAE = HTML('''<br><b>We are all equal (WAE)</b> With respect to the concept of group fairness this \n",
    "                            worldview assumes that data does not always constitute an objective picture of the\n",
    "                            world, as structural or systemic bias is inevitibely contained within it, therefor\n",
    "                            when the distribution of measurable observations differ accross groups this should not be \n",
    "                            mistaken for a difference in *distribution of ability* with respect to a goal(succeeding at \n",
    "                            university, paying back a loan, not re-offending, excelling in role) but rather this may indicate\n",
    "                            a fundamental difference in conditions across groups that has resulted in the variance in \n",
    "                            distribution of measurable observations. As a result we might apply a mathematical \n",
    "                            compensation for any major discrepencies. This worldview may example result in the \n",
    "                            observation that as there is no biological basis for race, a difference\n",
    "                            in the distribution of positive outcomes across race 1 compared to race 2 can \n",
    "                            only be accounted for by external factors outside of the control of the individuals constituting\n",
    "                            race 1 and as such should be mathematically addressed.<br><br>''')\n",
    "        \n",
    "        if (selectWorldView_value == 1):\n",
    "            \n",
    "            display( htmlWSYWYG)\n",
    "        \n",
    "        elif  (selectWorldView_value== 2):\n",
    "            display( htmlWAE)\n",
    "            \n",
    "            \n",
    "    #################################################################################################\n",
    "    #  \n",
    "    # \n",
    "    ################################################################################################# \n",
    "    def plot_relevance_exposure_ratio(self, df, protected_feature, reference_group, _count):\n",
    "        display (df)\n",
    "        '''Standard logarithmic discount (using average)':2,\n",
    "         'Standard logarithmic discount (using sum)':1,\n",
    "         'Geometric Distribution - Biega et al (TBD)':3, \n",
    "         'Viable-n test(TBD)':4}'''\n",
    "        measure = self.selectExpDropMeasure.value\n",
    "        if measure == 1:\n",
    "             text = '''Detect Inequality of attention, using a standard logarithmic discount to calculate\n",
    "             as discussed in\n",
    "             \n",
    "             '''\n",
    "        elif measure == 2:\n",
    "            text = '''Detect Inequality of attention, using a standard logarithmic discount \n",
    "            to measure exposure drop off and hence exposure for each position in the ranked list \n",
    "            as discussed by <b>Joachims and Singh</b> in \"Fairness of Exposure in Rankings\"\n",
    "            \n",
    "            comparing the sum of relevance per group against the sum of exposure per group \n",
    "             \n",
    "             '''\n",
    "            \n",
    "        elif measure == 3:\n",
    "            \n",
    "        elif measure == 4:\n",
    "        \n",
    "        # convert Series to Python strings\n",
    "        #fig.update_layout(barmode='group')\n",
    "        _x = []\n",
    "        _y = []\n",
    "        for val in df[protected_feature]:\n",
    "            _x.append(val)\n",
    "            _y.append (_count[val])\n",
    "            \n",
    "        fig = px.bar(df, \n",
    "                     x=protected_feature, \n",
    "                     y='exposure',\n",
    "                     text=round(df['exposure'],2),\n",
    "                     barmode='group',\n",
    "                     color_discrete_sequence =['lightsalmon']*len(df),\n",
    "                     height=400)\n",
    "        fig.update_traces(texttemplate='%{text}', textposition='outside')\n",
    "        fig.update_layout(xaxis_type='category',\n",
    "                          title_text='Exposure')\n",
    "        fig.update_xaxes(tickangle=45, \n",
    "                         showline=True, \n",
    "                         linewidth=2, \n",
    "                         linecolor='black',\n",
    "                         tickfont=dict(family='Rockwell', \n",
    "                                       color='green', \n",
    "                                       size=16))\n",
    "        fig.update_yaxes(showline=True, \n",
    "                         linewidth=2, \n",
    "                         linecolor='black', \n",
    "                         range=[0, df['exposure'].max()+ (df['exposure'].mean()/2)])\n",
    "        fig_1 = go.FigureWidget(fig)\n",
    "        del fig\n",
    "                         \n",
    "        #######                 \n",
    "        fig = px.bar(df, \n",
    "                     x=protected_feature, \n",
    "                     y='relevance', \n",
    "                     text=round(df['relevance'],2),\n",
    "                     barmode='group',\n",
    "                     color_discrete_sequence =['indianred']*len(df),\n",
    "                     height=400)\n",
    "        fig.update_traces( texttemplate='%{text}', textposition='outside')\n",
    "        fig.update_layout(xaxis_type='category',\n",
    "                          title_text='Relevance')\n",
    "        fig.update_xaxes(tickangle=45, \n",
    "                         showline=True, \n",
    "                         linewidth=2, \n",
    "                         linecolor='black',\n",
    "                         tickfont=dict(family='Rockwell', \n",
    "                                       color='green', \n",
    "                                       size=16))\n",
    "        \n",
    "        fig.update_yaxes(showline=True, \n",
    "                         linewidth=2, \n",
    "                         linecolor='black', \n",
    "                         range=[0, df['relevance'].max() + (df['relevance'].mean()/2)])\n",
    "        fig_2 = go.FigureWidget(fig)\n",
    "        del fig\n",
    "        #############\n",
    "        fig = px.bar(x=_x, \n",
    "                     y=_y,\n",
    "                     text=_y,\n",
    "                     barmode='group',\n",
    "                     color_discrete_sequence =['lightsalmon']*len(df),\n",
    "                     height=400,\n",
    "                     labels = {'x':protected_feature,\n",
    "                               'y': 'Count'\n",
    "                              }\n",
    "                    )\n",
    "        fig.update_traces(texttemplate='%{text}', textposition='outside')\n",
    "        fig.update_layout(xaxis_type='category',\n",
    "                          title_text='Count')\n",
    "        \n",
    "        fig.update_xaxes(tickangle=45, \n",
    "                         showline=True, \n",
    "                         linewidth=2, \n",
    "                         linecolor='black',\n",
    "                         tickfont=dict(family='Rockwell', \n",
    "                                       color='green', \n",
    "                                       size=16))\n",
    "        fig.update_yaxes(showline=True, \n",
    "                         linewidth=2, \n",
    "                         linecolor='black', \n",
    "                         range=[0, max(_y)+25])\n",
    "        fig_3 = go.FigureWidget(fig)\n",
    "        del fig\n",
    "        \n",
    "        \n",
    "        display(widgets.HBox([fig_1, fig_2, fig_3]))\n",
    "        \n",
    "    \n",
    "    def get_length_list_to_analyze (self, df):\n",
    "        if not self.ranked_df.empty:\n",
    "            # Now reduce the ranked list based on whethere we are using percentage or top k\n",
    "            if self.percentOrTopK.value == 0:\n",
    "                cut_results_len=round(len(df) *selectPercentageOfResults_value/100)\n",
    "            elif self.percentOrTopK.value == 1:\n",
    "                cut_results_len= self.selectTopKResults.value\n",
    "            try:\n",
    "                with self.list_info_out:\n",
    "                    clear_output(wait=True)\n",
    "                    text_a = 'Total number of records in ranked list (n) = <b>' + str(len(df)) + '</b>'\n",
    "                    text_b = '<br>Number of unique values in ranked output = <b>' + str(len(df[self.selectYAttribute.value].unique())) + '</b>'\n",
    "                    text_c ='''<br>Note: when n is sufficiently small we expect the user to read all results and \n",
    "                    therefor for all outcomes to be equal.'''\n",
    "                    text_d = '''\n",
    "                    <b>The probability ranking principle:</b> states that the ideal ranking should order items in\n",
    "                    the decreasing order of their probability of relevance(as this maximises <b>apparent</b> utility or \n",
    "                    usefulness).\n",
    "                    '''\n",
    "                    helper_method.display_html(text_d, 'black', \"p\")\n",
    "                    text = text_a + text_b + text_c\n",
    "                    helper_method.display_html(text, helper_method.text_color, \"p\")\n",
    " \n",
    "            except:\n",
    "                display ('Data not yet loaded')\n",
    "            return cut_results_len\n",
    "        \n",
    "    \n",
    "    #################################################################################################\n",
    "    #  \n",
    "    # \n",
    "    #################################################################################################\n",
    "   \n",
    "    def run_analysis(self, selectExpDropMeasure_value, setSignificance_value):\n",
    "        \n",
    "        if not self.ranked_df.empty and not self.selectProtectedAttributeToExamine.value == None:\n",
    "            local_ranked_df = self.ranked_df.copy()\n",
    "            cut_results_len = self.get_length_list_to_analyze(self.ranked_df)\n",
    "            self.ranked_df_top=self.ranked_df.head(cut_results_len).copy()\n",
    "            ##local interact method - Examine the new reduced ranked list\n",
    "            def show_view_protected (button_status):\n",
    "                if button_status == True:\n",
    "                    helper_method.view_protected(list(self.selectProtectedAttributes.value),\n",
    "                                                      self.selectYAttribute.value,\n",
    "                                                      self.ranked_df_top, \n",
    "                                                      _w=600, _h=600,\n",
    "                                                      y_high_positive = self.high_ranking_positive,\n",
    "                                                      persist_impact_col = False,\n",
    "                                                      output_type_binary = False,\n",
    "                                                      show_outcome_info = False)\n",
    "            with self.viewReducedListInfoOut:\n",
    "                clear_output(wait=True)\n",
    "                interact(show_view_protected, button_status = widgets.ToggleButton(\n",
    "                                                description='View Reduced Ranked List',\n",
    "                                                disabled=False)\n",
    "                                                )\n",
    "\n",
    "        \n",
    "            #local interact method\n",
    "            def calc_exposure_drop_off(selectExpDropMeasure_value):\n",
    "                expList = []\n",
    "                if (selectExpDropMeasure_value == 1):\n",
    "                    #Calculate the Logrithmic discount exposure drop off for the entire dataset \n",
    "                    #and use the average in the calculations        \n",
    "                    for x in range(len(local_ranked_df)):\n",
    "                    # For each record add the exposure to a pandas Series\n",
    "                        exposure=1/math.log(x+2, 2)\n",
    "                        expList.append(exposure)\n",
    "                \n",
    "                elif (selectExpDropMeasure_value == 2):\n",
    "                    #Calculate the Logrithmic discount exposure drop off for the entire dataset \n",
    "                    #and use the sum in the calculations \n",
    "                    for x in range(len(local_ranked_df)):\n",
    "                        #For each record add the exposure to a pandas Series\n",
    "                        exposure=1/math.log(x+2, 2)\n",
    "                        expList.append(exposure)\n",
    "                \n",
    "                elif (selectExpDropMeasure_value == 3):\n",
    "                    #Calculate the geometric distribution exposure drop off for the entire dataset\n",
    "                    for x in range(len(local_ranked_df)):\n",
    "                        #For each record add the exposure to a pandas Series\n",
    "                        exposure=1/math.log(x+2, 2)\n",
    "                        expList.append(exposure)\n",
    "        \n",
    "                elif (selectExpDropMeasure_value == 4):\n",
    "                    #Calculate the Logrithmic discount exposure drop off for the entire dataset\n",
    "                    for x in range(len(local_ranked_df)):\n",
    "                        #For each record add the exposure to a pandas Series\n",
    "                        exposure=1/math.log(x+2, 2)\n",
    "                        expList.append(exposure)\n",
    "                \n",
    "                else:\n",
    "                    for x in range(len(local_ranked_df)):\n",
    "                    #For each record add the exposure to a pandas Series\n",
    "                        exposure=1/math.log(x+2, 2)\n",
    "                        expList.append(exposure)\n",
    "                       \n",
    "                # Now we have a full list with the \"logarithmic discount\" exposure\n",
    "                local_ranked_df.insert(0, \"exposure\", expList, True)\n",
    "                self.ranked_df_top=local_ranked_df.head(cut_results_len).copy()\n",
    "                \n",
    "                #now we have a local copy of the full ranked list and the reduced ranked list with exposure \n",
    "                if not self.ranked_df_top.empty:\n",
    "                    _count = self.ranked_df_top.groupby(self.selectProtectedAttributeToExamine.value).count()['Predicted']\n",
    "                    adjustment = 0\n",
    "                    lowest_utility = self.ranked_df[self.selectYAttribute.value].min()\n",
    "                    #Adjust all relevance scores if any are less than 0\n",
    "                    if (lowest_utility < 0):\n",
    "                        display(HTML(\"<font color='blue'><b>Note: </b>Relevance score adjusted by min value \" + str(round(lowest_utility,3)) + \" to ensure no negative numbers in measure</font>\") )\n",
    "                        adjustment = lowest_utility\n",
    "                        local_ranked_df['Predicted'] = local_ranked_df['Predicted'].apply(lambda x: x-adjustment)\n",
    "                    #######\n",
    "\n",
    "                    if (selectExpDropMeasure_value == 1):\n",
    "                        #Create a small data frame containing the sum of exposure and relevance per group\n",
    "                        full_exp_util_df=local_ranked_df.groupby(self.selectProtectedAttributeToExamine.value).sum()[['exposure','Predicted']]\n",
    "                        reduced_exp_util_df=self.ranked_df_top.groupby(self.selectProtectedAttributeToExamine.value).sum()[['exposure','Predicted']]\n",
    "        \n",
    "                \n",
    "                    elif (selectExpDropMeasure_value == 2):\n",
    "                        #Create a small data frame containing the average of exposure and relevance per group\n",
    "                        full_exp_util_df=local_ranked_df.groupby(self.selectProtectedAttributeToExamine.value).mean()[['exposure','Predicted']]\n",
    "                        reduced_exp_util_df=self.ranked_df_top.groupby(self.selectProtectedAttributeToExamine.value).mean()[['exposure','Predicted']]\n",
    "   \n",
    "                    #else  #3, 4, 5 to be implemented \n",
    "                     \n",
    "                    full_exp_util_df['exposure_over_relevance']=full_exp_util_df.apply(lambda row: row.exposure/row.Predicted, axis=1)\n",
    "        \n",
    "                    full_exp_util_df.rename(columns={'Predicted':'relevance'}, inplace=True)\n",
    "                        \n",
    "                    display(HTML(\"List reduced to top: \" + str (cut_results_len)))\n",
    "                        \n",
    "                    # Create a ranked list of only the \"top\" records.\n",
    "                    reduced_exp_util_df['exposure_over_relevance']=reduced_exp_util_df.apply(lambda row: row.exposure/row.Predicted, axis=1)\n",
    "                    reduced_exp_util_df.rename(columns={'Predicted':'relevance'}, inplace=True)\n",
    "                    self.plot_relevance_exposure_ratio(reduced_exp_util_df.reset_index(), \n",
    "                                                       self.selectProtectedAttributeToExamine.value,\n",
    "                                                       self.selectProtectedAttributeToExamineReferenceGroup.value,\n",
    "                                                        _count)\n",
    "                        \n",
    "                    display (HTML(\"Full dataset:\"))\n",
    "                    self.plot_relevance_exposure_ratio(full_exp_util_df.reset_index(), \n",
    "                                                           self.selectProtectedAttributeToExamine.value,\n",
    "                                                          self.selectProtectedAttributeToExamineReferenceGroup.value,\n",
    "                                                          _count)\n",
    "            \n",
    "            \n",
    "            interact(calc_exposure_drop_off, selectExpDropMeasure_value = self.selectExpDropMeasure)\n",
    "            #just clear the view_analysis_output as we are about to use it again\n",
    "            #Populate the input to the FA*IR Analysis\n",
    "#             with self.viewFairOutputA:\n",
    "#                 clear_output(wait=True)\n",
    "#                 display(HTML(\"Larger values for significance(a) indicate a stricter necessity to adhere to the required porportion of protected elements at each position\"))\n",
    "                \n",
    "#                 display(self.group_names[selectProtectedAttributeToExamine_value])\n",
    "#                 allGroupsInProtected = self.ranked_df[selectProtectedAttributeToExamine_value].unique()\n",
    "#                 for group in allGroupsInProtected:\n",
    "#                     display(HTML(\"Required percentage for group \"+ str(group) +\" is \" + str (self.dictOfSlidersAffermativeActionGoal[group].value)))\n",
    "                \n",
    "#                 display(HTML(\"K =: \" + str (cut_results_len)))\n",
    "#                 for group in allGroupsInProtected:\n",
    "#                     display(HTML(\"Targeted minimum proportion(p) for group \"+ str(group) +\" is \" + str (self.dictOfSlidersAffermativeActionGoal[group].value/100)))\n",
    "                \n",
    "#                 display(HTML(\"a =: \" + str (self.setSignificance.value)))\n",
    "            \n",
    "        \n",
    "    def render(self):\n",
    "        space=widgets.Label('  ', layout=widgets.Layout(width='100%'))\n",
    "\n",
    "        uploadFileHTML=widgets.HTML(\n",
    "            \"<h3><left>1. Upload Ranked list:</left></h3>\")\n",
    "\n",
    "        setRankedOutputHTML=widgets.HTML(\n",
    "            \"<h3><left>2. Identify the ranked output column:</left></h3>\")\n",
    "\n",
    "        effectOfRankingHTML=widgets.HTML(\n",
    "            \"<h4><left>Set the effect of ranking on the individual or group</left></h4>\")\n",
    "\n",
    "        setProtectedAttributesHTML=widgets.HTML(\n",
    "            \"<h3><left>3. Identify the protected attributes column:</left></h3>\")\n",
    "\n",
    "        visualiseProtectedAttributesHTML=widgets.HTML(\n",
    "            \"<h3><left>4. Visualise protected attributes based on full ranked list:</left></h3>\")\n",
    "\n",
    "        analyzeProtectedHTML=widgets.HTML(\n",
    "            \"<h3><left>5. Analyze ranking for fairness:</left></h3>\")\n",
    "\n",
    "        analyzeProtectedHTML_B=widgets.HTML(\n",
    "            \"<h4><left>Specify the number of results that will receive attention:</left></h4>\")\n",
    "\n",
    "        analyzeProtectedHTML_C=widgets.HTML(\n",
    "            \"<h4><left>Specify the protected attribute to analyse:</left></h4>\")\n",
    "        \n",
    "        analyzeProtectedHTML_C_2=widgets.HTML(\n",
    "            \"<br><h4><left>Specify the protected group to use as a reference wrt Fairness:</left></h4>\")\n",
    "        \n",
    "        analyzeProtectedHTML_D=widgets.HTML(\n",
    "            \"<h4><left>Specify the worldview that will be supported by the ranking model:</left></h4>\")\n",
    "        \n",
    "        analyzeProtectedHTML_E=widgets.HTML(\n",
    "            \"<h4><left>Specify the fairness goal to be supported by the ranking model:</left></h4>\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        resultsHTML=widgets.HTML(\"<h3><left>Results:</left></h3>\")\n",
    "       \n",
    "    \n",
    "    \n",
    "        JoacmAndSinghHTML=widgets.HTML(\n",
    "            '''<h4><left>Joachims and Singh Fairness of Exposure in Ranking (Balancing fairness and perceived utility):</left></h4><h5>\n",
    "            Is exposure fairly allocate(regardless of how relevance/utility is estimated)</h5>\n",
    "            \n",
    "            <a href=\"https://arxiv.org/pdf/1802.07281.pdf\">\"Fairness of Exposure in Rankings\"</a>\n",
    "\n",
    "         ''')\n",
    "        \n",
    "        exposureHTML = widgets.HTML('''\n",
    "        <html><p style=\"display:inline; line-height:0px\"><b>Exposure:</b> There is little doubt that the order of ranking is correlated with the \n",
    "                    result which receive the majority of the user attention and interaction and that our \n",
    "                    cognitive inclinations tend to place a higher value on results positioned at the top of a \n",
    "                    list. The results of a 2008 study (by M. Keane, M. O'Brien, & B. Smyth) has shown definite \n",
    "                    evidence of bias in a user’s interaction with a list returned by a search, whereby the user \n",
    "                    tends to give preferences to items at the top of the list, although they do sometimes seek \n",
    "                    out relevant results with a lower ranking. The measure of this attention is known as \n",
    "                    \"<b>exposure</b>\" and the exposure a person or item will receive is largely determined by the position \n",
    "                    in which they will appear in the final ranking displayed to the end user. \n",
    "\n",
    "                    <br><br>We should consider if the absolute maximization of <b>apparent</b> utility (relevance) is\n",
    "                    appropriate or fair when ranking humans or if we may want to impose some fairness constraints \n",
    "                    that might guarantee a particular notion of fairness. Due to the nature of ranking a \n",
    "                    small difference in utility(relevance) may result in a large difference in exposure</p><br>\n",
    "                    \n",
    "            <b>Note:</b> Using standard log discount with average is not useful when there is very low \n",
    "            representation in one group. \n",
    "            \n",
    "            Utility maximation subject to fairness.\n",
    "        ''')\n",
    "\n",
    "    \n",
    "        FAIRHTML=widgets.HTML(\n",
    "            \"<h4><left>FA*IR: A Fair Top-k Ranking</left></h4><h5>Ranked group fairness: Does the representation of the protected group fall below a minimum proportion(p) at any point in the ranking (regardless of how relevance is estimated)</h5>\")\n",
    "         \n",
    "        \n",
    "        display(\n",
    "            uploadFileHTML,\n",
    "            self.fileUploader,\n",
    "            self.upload_data_out,\n",
    "            \n",
    "            \n",
    "            space,\n",
    "            setRankedOutputHTML,\n",
    "            self.selectYAttribute,\n",
    "            self.select_ranked_list_col_out,\n",
    "            \n",
    "            \n",
    "            space,\n",
    "            effectOfRankingHTML,\n",
    "            self.selectImpact,\n",
    "            \n",
    "            \n",
    "            space,\n",
    "            setProtectedAttributesHTML,\n",
    "            self.selectProtectedAttributes,\n",
    "            self.select_protected_out,\n",
    "            \n",
    "            \n",
    "            space,\n",
    "            visualiseProtectedAttributesHTML,\n",
    "            self.view_attributes_button,\n",
    "            self.viewProtectedOut,\n",
    "\n",
    "            space,\n",
    "            analyzeProtectedHTML,\n",
    "            # view_analysis input fields\n",
    "           \n",
    "            self.list_info_out,\n",
    "            space,\n",
    "                \n",
    "            analyzeProtectedHTML_B,\n",
    "            self.percentOrTopK,\n",
    "            self.selectTopKResults,\n",
    "            self.selectPercentageOfResults,\n",
    "            self.viewReducedListInfoOut,\n",
    "            space,\n",
    "                \n",
    "            analyzeProtectedHTML_C,\n",
    "            self.selectProtectedAttributeToExamine,\n",
    "            analyzeProtectedHTML_C_2,\n",
    "            self.selectProtectedAttributeToExamineReferenceGroup,\n",
    "            self.set_reference_group_options_out,\n",
    "                \n",
    "            space,\n",
    "            analyzeProtectedHTML_D,\n",
    "            self.selectWorldView,\n",
    "            self.worldview_out,\n",
    "            analyzeProtectedHTML_E,\n",
    "            self.selectFairnessGoal,\n",
    "            self.population_slider_out,\n",
    "            space,\n",
    "\n",
    "            space,\n",
    "            resultsHTML,\n",
    "            exposureHTML,\n",
    "            JoacmAndSinghHTML,\n",
    "            space,\n",
    "\n",
    "            self.view_analysis_out,\n",
    "            self.viewProtectedPandasPlotA,\n",
    "            space,\n",
    "            FAIRHTML,\n",
    "            space,\n",
    "            self.setSignificance,\n",
    "            self.viewFairOutputA,\n",
    "            space,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-20T17:53:52.067423Z",
     "start_time": "2020-06-20T17:53:51.781098Z"
    }
   },
   "outputs": [],
   "source": [
    "'''computer scientists typically associate fairness with a property of unbounded nondeterminism while \n",
    "economists believe fairness is an attribute of the rational valuation of goods. \n",
    "Culturally, fairness is associated with behaviors that are not influence by person’s skin color, \n",
    "race or socio-economic status. As per the proposal in we can consider fairness through two world views.\n",
    "If we look at the distribution of an outcome across two groups, group 1 and group 2. \n",
    "Individual vs. Group: Another friction that defines fairness in machine learning algorithms is\n",
    "Group vs. Individual. Group fairness, in its broadest sense, partitions a population into groups\n",
    "defined by protected attributes and seeks for some statistical measure to be equal across groups. \n",
    "Individual fairness, in its broadest sense, seeks for similar individuals to be treated similarly.\n",
    "\n",
    "\n",
    "\n",
    "Individual fairness could be considered as groups of size 1\n",
    "'''\n",
    "\n",
    "demographicParityHTML = '''Demographic Parity states that the proportion of each group within a protected feature/attribute\n",
    "                            (e.g. gender, race) should receive a positive outcome at equal rates. \n",
    "                            Where a positive outcome is the outcome that will benefit the human eg. \n",
    "                            “Getting to university”, \n",
    "                            “Getting a loan”, \n",
    "                            “Not getting flagged for potential recedivism”,\n",
    "                            \"Getting interviewed for the job\",\n",
    "                            \"Not getting flagged for potential fraud\",\n",
    "                            \"Not getting flagged as potential criminal\"\n",
    "                             Ideally the proportions will be equal. A motivation for demographic parity will be to \n",
    "                             change the state of our current world to improve it \n",
    "                             (e.g.: we want to see more minority groups getting to the top).\n",
    "                             Awareness that historical biases may affected the quality of our data \n",
    "                             (e.g.: ML solution trained to hire software engineers, where nearly no women was \n",
    "                             hired before)\n",
    "                            Ideally thre is a plan in place to support the unprivileged group and to prevent the\n",
    "                            reinforcement of historical biases \n",
    "                            (e.g.: setting policies that penalise non inclusive behaviour at a board)'''\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python3.6 PyEnv",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": "30",
    "lenType": "30",
    "lenVar": "200"
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
