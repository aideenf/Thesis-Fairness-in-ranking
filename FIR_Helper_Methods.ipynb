{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T15:53:43.887607Z",
     "start_time": "2020-06-14T15:53:39.108043Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import preprocessing\n",
    "from io import StringIO\n",
    "import pprint\n",
    "import pandas_profiling\n",
    "import re\n",
    "import random\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "from IPython.display import display, clear_output, HTML\n",
    "\n",
    "import math\n",
    "from collections import Counter\n",
    "import heatmap\n",
    "import gc\n",
    "from heatmap import heatmap, corrplot\n",
    "from ipywidgets import Layout, Button, Box\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly.graph_objs import graph_objs as go \n",
    "import plotly.offline\n",
    "from plotly.offline import iplot\n",
    "import threading\n",
    "import time\n",
    "import ipyfilechooser\n",
    "from ipyfilechooser import FileChooser\n",
    "#$ pip install ipyupload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "from ipyupload import FileUpload\n",
    "from itertools import cycle, chain, combinations\n",
    "import dill\n",
    "from IPython.core.display import display, HTML\n",
    "#display(HTML(\"<style>.container {width:80% !important;}</style>\"))\n",
    "%matplotlib inline\n",
    "import shap\n",
    "\n",
    "from aequitas.group import Group\n",
    "from aequitas.bias import Bias\n",
    "from aequitas.fairness import Fairness\n",
    "from aequitas.plotting import Plot\n",
    "from aequitas.preprocessing import preprocess_input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T15:53:45.366369Z",
     "start_time": "2020-06-14T15:53:45.278180Z"
    }
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T14:29:59.620433Z",
     "start_time": "2020-06-16T14:29:58.933919Z"
    }
   },
   "outputs": [],
   "source": [
    "class helper_methods():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.text_color = \"green\"\n",
    "        self.progressBar = widgets.FloatProgress(\n",
    "            value=0.0, \n",
    "            min=0.0, \n",
    "            max=100.0,\n",
    "            #layout = auto_width_layout,\n",
    "        )\n",
    "        \n",
    "        self._percent_slider = \"tbd\"               \n",
    "        self._top_x_slider  = \"tbd\"\n",
    "        \n",
    "    \n",
    "    def display_html(self, text, color, size):\n",
    "        content = \"<\" + size + \">\"  + \"<text style='color:\" + color + \"'>\" + text + \"</text>\" + \"</\" + size + \">\" \n",
    "        display(HTML(content))\n",
    "        \n",
    "      \n",
    "    def work_in_progress(self):\n",
    "        for i in range(100):\n",
    "            if self.progressBar.value != 100:\n",
    "                self.progressBar.value = i# float(i+1)/total\n",
    "                time.sleep(0.3)\n",
    "            if self.progressBar.value == 100:\n",
    "                break\n",
    "            \n",
    "            \n",
    "\n",
    "                \n",
    "    #################################################################################################\n",
    "    #  \n",
    "    # \n",
    "    #################################################################################################\n",
    "    def view_correlations(self, df, column_list, column_list_with_Y, protected_column_list, y_col ):\n",
    "       \n",
    "        feature_set_with_y = df\n",
    "        out1 = widgets.Output(layout={})\n",
    "        out2 = widgets.Output(layout={})\n",
    "        out3 = widgets.Output(layout={})\n",
    "        out4 = widgets.Output(layout={})\n",
    "        tab_contents = [out1, out2, out3]\n",
    "        \n",
    "        children = tab_contents\n",
    "        tab = widgets.Tab()\n",
    "        tab.children = children\n",
    "        \n",
    "        tab.set_title(0, \"Correlation plot\")\n",
    "        tab.set_title(1, \"Pair Plot\")\n",
    "        tab.set_title(2, \"Feature distribution\")\n",
    "      \n",
    "        display(out4)\n",
    "        display(self.progressBar)\n",
    "        display(tab)\n",
    "        \n",
    "        column_to_count = []\n",
    "        column_to_corr = []\n",
    "        for  col in column_list_with_Y:\n",
    "            if len(feature_set_with_y[col].unique ())< 10:\n",
    "                column_to_count.append(col)\n",
    "            else:\n",
    "                column_to_corr.append(col)\n",
    "        \n",
    "        def f_cor(x ): #local method within view_correlations() funct\n",
    "                self.progressBar.value = 0\n",
    "                thread = threading.Thread(target=self.work_in_progress)\n",
    "                thread.start()\n",
    "                plt.clf()\n",
    "                plt.figure(figsize=(12, 12))     \n",
    "                fig1 = corrplot(feature_set_with_y[column_list_with_Y].corr(), size_scale=x, marker=\"o\");       \n",
    "                plt.show(fig1)\n",
    "                plt.clf()\n",
    "                plt.close(fig1)\n",
    "                self.progressBar.value = 100\n",
    "                        \n",
    "        \n",
    "        def f_cor_val( a,b ): #local method within view_correlations() funct\n",
    "                self.display_html (\"The correlation value is \" + str(feature_set_with_y[a].corr(feature_set_with_y[b])), self.text_color, \"p\")\n",
    "        \n",
    "        with out1:\n",
    "            interact(f_cor, x = widgets.IntSlider(description = \"slide to scale\", min=0, max=70000, step=100, value=500, continuous_update=False), );\n",
    "        \n",
    "            interact(f_cor_val, \n",
    "                        a = widgets.Dropdown(description = \"Column 1\", options = column_list_with_Y),\n",
    "                        b = widgets.Dropdown(description = \"Column 2\", options = column_list_with_Y)\n",
    "                );\n",
    "        \n",
    "                    \n",
    "        def f_pp(_hue): #local method within view_correlations() funct\n",
    "            self.progressBar.value = 0\n",
    "            thread = threading.Thread(target=self.work_in_progress)\n",
    "            thread.start()\n",
    "            with out4:\n",
    "                clear_output(wait = False)\n",
    "                self.display_html(\"Calculating pair plot..\", self.text_color, \"p\")\n",
    "            \n",
    "   \n",
    "            plt.figure(figsize=(6, 6))      \n",
    "            pp = sns.pairplot(feature_set_with_y[column_to_corr+[_hue]], corner=True, hue=_hue, diag_kind = 'kde', height=3, plot_kws = { 'alpha': 0.6,'s': 80, 'edgecolor': 'k'});  \n",
    "            pp._legend.get_title().set_fontsize(20)   \n",
    "            plt.show()\n",
    "            plt.clf()\n",
    "            plt.close()\n",
    "            self.progressBar.value = 100\n",
    "                \n",
    "            with out3: \n",
    "                clear_output(wait = False)\n",
    "                self.progressBar.value = 100\n",
    "                a = 0\n",
    "                b = 0\n",
    "                    \n",
    "                num_plots = len(column_to_count)\n",
    "                num_rows = math.ceil(num_plots/2)  \n",
    "                f, axes = plt.subplots(num_rows, 2, figsize=(15, num_rows*5))\n",
    "                for  col in column_to_count:\n",
    "                    sns.countplot(x = col, data = feature_set_with_y, ax=axes[a, b], hue=_hue)\n",
    "                    a = a + 1\n",
    "                    if a == (num_rows):\n",
    "                        b = b + 1\n",
    "                        a = 0\n",
    "                plt.show()\n",
    "                plt.clf()\n",
    "                plt.close()\n",
    "            \n",
    "            with out4:\n",
    "                clear_output(wait = False)\n",
    "                self.display_html(\"Plots complete! Generating pandas profiling.\", self.text_color, \"p\")\n",
    "                self.progressBar.value = 100\n",
    "            \n",
    "       \n",
    "        with out2:\n",
    "            clear_output(wait = False)\n",
    "            interact(f_pp, _hue = widgets.Dropdown(description = \"Hue based on\", \n",
    "                                                           options = protected_column_list));\n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "    #################################################################################################\n",
    "    #  VIEW STATISTICS AROUND. THE PROTECTED FEATURES/ATTRIBUTES\n",
    "    # \n",
    "    #################################################################################################\n",
    "            \n",
    "    def view_protected(self, protected_attributes_list, \n",
    "                             y_value, data_frame, \n",
    "                            _w=600, _h=600, \n",
    "                            y_high_positive = True,\n",
    "                            persist_impact_col = False,\n",
    "                            output_type_binary = False,\n",
    "                            show_outcome_info = True):\n",
    "        protected = []\n",
    "        protectedCount = []\n",
    "        protectedPercentage = []\n",
    "        HIGH_RANGE_POSITIVE = y_high_positive\n",
    "        \n",
    "        out1 = widgets.Output(layout={})\n",
    "        out2 = widgets.Output(layout={})\n",
    "        out3 = widgets.Output(layout={})\n",
    "        out4 = widgets.Output(layout={})\n",
    "        \n",
    "        if show_outcome_info == True:\n",
    "            tab_contents = [out1, out2, out3]\n",
    "        else:\n",
    "            tab_contents = [out1, out2]\n",
    "        \n",
    "        children = tab_contents\n",
    "        tab = widgets.Tab(style={'description_layout':'auto', 'title_layout':'auto'})\n",
    "        tab.children = children\n",
    "        \n",
    "        tab.set_title(0, \"Group Representation in data\")\n",
    "        tab.set_title(1, \"Outcome distribution\")\n",
    "        tab.set_title(2, \"Group Positive outcome representation\")\n",
    "        \n",
    "        local_layout = {'width': 'auto', 'visibility':'visible'}\n",
    "        local_layout_hidden  = {'width': 'auto', 'visibility':'hidden'}\n",
    "        local_style = {'description_width':'initial'}\n",
    "        display(out4)\n",
    "        display(tab)\n",
    "        try:\n",
    "            colType = data_frame[y_value].dtype\n",
    "            if (colType != str and colType != object):\n",
    "                ####### view distribution of groups in the data\n",
    "                with out1:\n",
    "                    clear_output(wait = False)\n",
    "                    fig = self.plot_donut(protected_attributes_list,\n",
    "                               data_frame,\n",
    "                               w=_w, h=_h,\n",
    "                               y_high_positive = HIGH_RANGE_POSITIVE,\n",
    "                               title = \"Representation of Protected group(s) in the data\",\n",
    "                               show_individual = False);\n",
    "                    fig.show()\n",
    "                    \n",
    "                    def show_donut_for(choose): #local method within view_protected() funct\n",
    "                        #plot the representation of data in the dataframe per protected group\n",
    "                        with out4:\n",
    "                            clear_output(wait = False)\n",
    "                            self.display_html(\"loading group representation in data...\", self.text_color, \"p\") \n",
    "                        fig = self.plot_donut([choose],\n",
    "                               data_frame,\n",
    "                               w=_w, h=_h,\n",
    "                               y_high_positive = HIGH_RANGE_POSITIVE,\n",
    "                               title = \"Representation of \" + choose + \" in the data\",\n",
    "                               show_individual = False);\n",
    "                        fig.show()\n",
    "                        del fig\n",
    "                        with out4:\n",
    "                            clear_output(wait = False)\n",
    "                            self.display_html(\"Finished loading\", self.text_color, \"p\")\n",
    "                    if len (protected_attributes_list) > 1:\n",
    "                        interact(show_donut_for, \n",
    "                            choose = widgets.Dropdown(description = \"Select attribute\", \n",
    "                                                      options = protected_attributes_list,\n",
    "                                                     layout = local_layout,\n",
    "                                                     style = local_style),\n",
    "                                );\n",
    "                \n",
    "                \n",
    "                ############## view distribution of results across groups\n",
    "                with out2:\n",
    "                    clear_output(wait = False)\n",
    "                        #plot the distribution of Y-value per protected group\n",
    "                    def show_distribution(choose, curve_type): #local method within view_protected() funct\n",
    "                        #plot the representation of data in the dataframe per protected group\n",
    "                        with out4:\n",
    "                            clear_output(wait = False)\n",
    "                            self.display_html(\"loading outcome distribution...\", self.text_color, \"p\")\n",
    "                        if choose != \"--select--\":\n",
    "                            self.plot_distribution( [choose],\n",
    "                                       y_value, \n",
    "                                       data_frame, \n",
    "                                       w=_w, h=_h, \n",
    "                                       y_high_positive = HIGH_RANGE_POSITIVE,\n",
    "                                       curve_type = curve_type);\n",
    "                        with out4:\n",
    "                            clear_output(wait = False)\n",
    "                            self.display_html(\"Finished loading\", self.text_color, \"p\")\n",
    "                    \n",
    "                    def show_distribution_count(choose): #local method within view_protected() funct\n",
    "                        if choose != \"--select--\":\n",
    "                            output_values = data_frame[y_value].unique()\n",
    "                            group_types = data_frame[choose].unique()\n",
    "                            fig = go.Figure()\n",
    "                            for val in output_values:\n",
    "                                temp = data_frame[data_frame[y_value]==val]\n",
    "                                fig.add_trace(go.Histogram(\n",
    "                                                        x=temp[choose],\n",
    "                                                        y=temp[y_value],\n",
    "                                                        name= \"Output \" + str(val),\n",
    "                                                        histfunc=\"count\",\n",
    "                                                        opacity=0.75))\n",
    "                                fig.update_layout(\n",
    "                                            title_text='Outcome distribution', # title of plot\n",
    "                                            xaxis_title_text=choose, # xaxis label\n",
    "                                            yaxis_title_text='Count', # yaxis label\n",
    "                                            bargap=0.2, # gap between bars of adjacent location coordinates\n",
    "                                            bargroupgap=0.1, # gap between bars of the same location coordinates\n",
    "                                            #legend_title_text=y_value+\" output\"\n",
    "                                            autosize=False\n",
    "                                            )\n",
    "\n",
    "                        fig.show()\n",
    "\n",
    "                    if output_type_binary == False:\n",
    "                        interact(show_distribution, \n",
    "                                 choose = widgets.Dropdown(description = \"Select attribute\",\n",
    "                                                           options = [\"--select--\"] + protected_attributes_list,\n",
    "                                                           layout = local_layout,\n",
    "                                                           style = local_style),\n",
    "                                 curve_type = widgets.Dropdown(description = \"Select Curve type\",\n",
    "                                                               options = {\"Kernel Density Estimation\":\"kde\",\"Normal Distribution\":\"normal\"},\n",
    "                                                               layout = local_layout,\n",
    "                                                               style = local_style),\n",
    "                                );\n",
    "                    \n",
    "                    elif output_type_binary == True:\n",
    "                        interact(show_distribution_count, \n",
    "                                 choose = widgets.Dropdown(description = \"Select attribute\",\n",
    "                                                           options = protected_attributes_list,\n",
    "                                                           layout = local_layout,\n",
    "                                                           style = local_style),\n",
    "                                );\n",
    "                        \n",
    "\n",
    "                with out4:#plot the representation of data in the dataframe per protected group\n",
    "                    clear_output(wait = False)\n",
    "                    self.display_html(\"loading outcome representation per group...\", self.text_color, \"p\")      \n",
    "                ############## view distribution of positive outcome across groups\n",
    "                \n",
    "                with out3:\n",
    "                    clear_output(wait = False)\n",
    "                    if HIGH_RANGE_POSITIVE == True:\n",
    "                        impactTxt = \"<b>Positive</b>\"\n",
    "                    if HIGH_RANGE_POSITIVE == False:\n",
    "                        impactTxt = \"<b>Negative</b>\"\n",
    "                    x = \"The Impact of a high output(ranking) on an individual or group is <b>\" + impactTxt + \"</b>\"\n",
    "                    self.display_html(str(x), self.text_color, \"p\")\n",
    "                    self.display_html(\"Select the decision boundary between a positive and negative outcome for the purpose of the report.\", self.text_color, \"p\")\n",
    "\n",
    "                    def show_outcome(choose, percentile_slider, top_x_slider): #local method within view_protected() funct\n",
    "                        #plot the representation of data in the dataframe per protected group\n",
    "                        self._percent_slider.layout = local_layout_hidden\n",
    "                        self._top_x_slider.layout = local_layout_hidden\n",
    "                        with out4:\n",
    "                            clear_output(wait = False)\n",
    "                            self.display_html(\"loading outcomes across groups...\", self.text_color, \"p\")\n",
    "                        if choose == \"Mean\":\n",
    "                            self._percent_slider.layout = local_layout_hidden\n",
    "                            self._top_x_slider.layout = local_layout_hidden\n",
    "                             #plot the distribution of above and below average score(y-value) per protected group\n",
    "                            self.plot_outcome_representation(protected_attributes_list,\n",
    "                                                             y_value, data_frame,\n",
    "                                                             w=_w, h=_h,\n",
    "                                                             y_high_positive = HIGH_RANGE_POSITIVE,\n",
    "                                                             percentile = None,\n",
    "                                                             top_x = None,\n",
    "                                                             persist_impact_col = persist_impact_col)\n",
    "                                 \n",
    "                        if choose == \"Percentile\":\n",
    "                            self._percent_slider.layout = local_layout\n",
    "                            self._top_x_slider.layout = local_layout_hidden\n",
    "                        #plot the distribution of above and below average score(y-value) per protected group\n",
    "                            self.plot_outcome_representation(protected_attributes_list,\n",
    "                                                             y_value, data_frame,\n",
    "                                                             w=_w, h=_h,\n",
    "                                                             y_high_positive = HIGH_RANGE_POSITIVE,\n",
    "                                                             percentile = percentile_slider,\n",
    "                                                             top_x = None,\n",
    "                                                             persist_impact_col = persist_impact_col)\n",
    "                        if choose == \"Top-n\":\n",
    "                            self._percent_slider.layout = local_layout_hidden\n",
    "                            self._top_x_slider.layout = local_layout\n",
    "                        #plot the distribution of above and below average score(y-value) per protected group\n",
    "                            self.plot_outcome_representation(protected_attributes_list,\n",
    "                                                             y_value, data_frame,\n",
    "                                                             w=_w, h=_h,\n",
    "                                                             y_high_positive = HIGH_RANGE_POSITIVE,\n",
    "                                                             percentile = None,\n",
    "                                                             top_x = top_x_slider,\n",
    "                                                            persist_impact_col = persist_impact_col)\n",
    "\n",
    "                    # see https://pandas.pydata.org/pandas-docs/stable/user_guide/style.html\n",
    "                        with out4:\n",
    "                            clear_output(wait = False)\n",
    "                            self.display_html(\"Finished loading!\", self.text_color, \"p\")\n",
    "                    \n",
    "                    \n",
    "                    if output_type_binary == True:\n",
    "                        _choose = widgets.Dropdown(\n",
    "                                description = \"Positive v's Negative determined by\", \n",
    "                                options = [\"Mean\"],\n",
    "                                layout = local_layout,\n",
    "                                style = local_style)\n",
    "                    else:\n",
    "                        _choose = widgets.Dropdown(\n",
    "                                description = \"Positive v's Negative determined by\", \n",
    "                                options = [\"Mean\",\"Top-n\",\"Percentile\"],\n",
    "                                layout = local_layout,\n",
    "                                style = local_style)\n",
    "                    \n",
    "                    self._percent_slider = widgets.IntSlider(\n",
    "                                description = \"Select Percentile\", \n",
    "                                min=0, max=100,\n",
    "                                step=1, value=80, \n",
    "                                continuous_update=False,\n",
    "                                layout = local_layout_hidden,\n",
    "                                style = local_style)\n",
    "                    \n",
    "                    self._top_x_slider = widgets.IntSlider(\n",
    "                                description = \"Select n for Top_n\", \n",
    "                                min=10, max=1000,\n",
    "                                step=10, value=100, \n",
    "                                continuous_update=False,\n",
    "                                layout = local_layout_hidden,\n",
    "                                style = local_style) \n",
    "                    \n",
    "                    if show_outcome_info == True:\n",
    "                        interact(show_outcome, \n",
    "                                 choose = _choose,\n",
    "                                 percentile_slider = self._percent_slider, \n",
    "                                 top_x_slider = self._top_x_slider,);\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    with out4:#plot the representation of data in the dataframe per protected group\n",
    "                        clear_output(wait = False)\n",
    "                        self.display_html(\"Complete!\", self.text_color, \"p\")\n",
    "                \n",
    "                if (colType == str or colType == object):\n",
    "                    self.display_html(\"Output label is not number and should be converted\", self.text_color, \"h4\")\n",
    "        except Exception as e:\n",
    "            self.display_html(\"Something went wrong in view_protected method\", self.text_color, \"h4\")\n",
    "            print (e)\n",
    "#         gc.collect()\n",
    "        with out4:#plot the representation of data in the dataframe per protected group\n",
    "            clear_output(wait = False)\n",
    "            self.display_html(\"finished loading\", self.text_color, \"p\")\n",
    "        \n",
    "          \n",
    "    #################################################################################################\n",
    "    #  \n",
    "    # \n",
    "    #################################################################################################         \n",
    "    def create_label (self, row):#method local to this method\n",
    "            \n",
    "            names = list (row.index)\n",
    "            values = list( row.values)\n",
    "            text = \"\"\n",
    "            for i in range (len(names)):\n",
    "                text = text + \":\" + names[i] + \"_\" + str(values[i])\n",
    "            text = text[1:]            \n",
    "            return text       \n",
    "    #################################################################################################\n",
    "    #  \n",
    "    # \n",
    "    #################################################################################################       \n",
    "    def plot_donut(self, attributes_list, data_frame, w=800, h=800, y_high_positive = True, title = \"Result\",\n",
    "                         show_individual = True):\n",
    "    \n",
    "        num_of_donuts = len(attributes_list)\n",
    "        if num_of_donuts > 6:\n",
    "            num_of_donuts = 6\n",
    "            display (HTML(\"showing only the first 6 attributes\"))\n",
    "        \n",
    "        sequential_color_list = [\n",
    "            px.colors.sequential.Blues,\n",
    "            px.colors.sequential.Greens, \n",
    "            px.colors.sequential.Oranges, \n",
    "            px.colors.sequential.Purples,\n",
    "            px.colors.sequential.Reds,\n",
    "            px.colors.sequential.Greys,\n",
    "            px.colors.sequential.algae,\n",
    "            px.colors.sequential.amp]\n",
    "    \n",
    "        color_pool = cycle(sequential_color_list)\n",
    "    \n",
    "        pie_list = []    \n",
    "        a_l = []\n",
    "        labels_arr = []\n",
    "        values_arr = []\n",
    "        color_arr = []\n",
    "        annotations_arr = []\n",
    "        annotate = dict(text='woops', \n",
    "            x=0.5, y=0.6, \n",
    "            font_size=15, \n",
    "            showarrow=False)\n",
    "                     \n",
    "        def create_label (row):#method local to this method\n",
    "            \n",
    "            names = list (row.index)\n",
    "            values = list( row.values)\n",
    "            text = \"\"\n",
    "            for i in range (len(names)):\n",
    "                text = text + \":\" + names[i] + \"_\" + str(values[i])\n",
    "            text = text[1:]            \n",
    "            return text\n",
    "            \n",
    "        for a, pos in zip (attributes_list, range(len(attributes_list))):\n",
    "            a_l.append(a)\n",
    "            annotate['text'] = a\n",
    "            annotate['y'] = annotate['y']-0.05\n",
    "            annotations_arr.append(annotate.copy())\n",
    "            #df = data_frame[a_l+[y]].groupby(a_l).count().reset_index().rename(columns={y: \"values\"})\n",
    "            data_frame[\"count\"] = 0\n",
    "            df = data_frame[a_l+[\"count\"]].groupby(a_l).count().reset_index().rename(columns={\"count\": \"values\"})\n",
    "            df['labels'] =  df.apply(lambda row : self.create_label(row[a_l]), axis = 1) \n",
    "            #df['labels'] = df[a_l].astype(str).sum(axis=1) \n",
    "            df['values'].fillna(0,inplace=True)\n",
    "            c = []\n",
    "            s = []\n",
    "            if pos == 0:\n",
    "                for l in range (len(df['labels'].values)):\n",
    "                    c.append(next(color_pool)[0])\n",
    "                    if l >= len(sequential_color_list):\n",
    "                        l = l - len(sequential_color_list)\n",
    "                    s.append(l)\n",
    "                df['colors'] = c\n",
    "                df['color_pool_pos'] = s\n",
    "                \n",
    "            else:\n",
    "                temp_list = list(df['values'].values)\n",
    "                for count, color_index in zip(prev_counts, prev_color_pool) :\n",
    "                    match = 0\n",
    "                    for value, pos in zip (temp_list, range(len(temp_list))):\n",
    "                        s.append(color_index)\n",
    "                        try:\n",
    "                            c.append (sequential_color_list[color_index][pos+1])\n",
    "                        except:\n",
    "                            c.append (sequential_color_list[color_index][2])\n",
    "                        match = match + value\n",
    "                        if match == count:\n",
    "                            del temp_list[0:pos+1]\n",
    "                            break\n",
    "                df['colors'] = c\n",
    "                df['color_pool_pos'] = s\n",
    "            labels_arr.append (df['labels'])\n",
    "            values_arr.append (df['values'])\n",
    "            color_arr.append (df['colors'])\n",
    "        \n",
    "            prev_counts = df['values'].values\n",
    "            prev_color_pool = df['color_pool_pos'].values\n",
    "\n",
    "        \n",
    "        hole = 0.8\n",
    "        x1 = 0\n",
    "        x2 =1\n",
    "        y1 = 0\n",
    "        y2 = 1\n",
    "        adjust = round((1.0 - hole)* 0.5,2) \n",
    "        for x in range (num_of_donuts):\n",
    "            pie_list.append(go.Pie(\n",
    "            hole=hole, #Sets the fraction of the radius to cut out of the pie. Use this to make a donut chart\n",
    "            sort=False,\n",
    "            direction='clockwise',\n",
    "            domain={'x': [x1, x2], 'y': [y1, y2]},\n",
    "            values=values_arr[x],\n",
    "            labels=labels_arr[x],\n",
    "            #text = my_text,\n",
    "            textinfo='label+percent',\n",
    "            textposition='inside',\n",
    "            name=attributes_list[x],\n",
    "            marker={'colors': color_arr[x],'line': {'color': 'black', 'width': 1}}\n",
    "            ))\n",
    "            hole= round(hole - adjust, 2)\n",
    "            x1 = round (x1 + adjust, 2)\n",
    "            x2 = round (x2 - adjust, 2)\n",
    "            y1 = round (y1 + adjust, 2)\n",
    "            y2 = round (y2 - adjust, 2)\n",
    "         \n",
    "    \n",
    "        fig = go.FigureWidget(data=pie_list)#need to reverse the order?\n",
    "        fig.update_layout(autosize=False,\n",
    "                          width=w,\n",
    "                          height=h,\n",
    "                          margin=dict(l=50,r=50,b=100, t=100,pad=4),\n",
    "                          title=str(a_l),\n",
    "                          #Add annotations in the center of the donut pies.\n",
    "                          annotations=annotations_arr,\n",
    "                          legend_orientation=\"h\",\n",
    "                           #paper_bgcolor='rgba(113, 136, 136, 1)', #for transparent set to (0,0,0,0)\n",
    "                          #plot_bgcolor='rgba(113, 136, 136, 1)',\n",
    "                    )\n",
    "\n",
    "        fig.update_traces(textposition='inside')\n",
    "        fig.update(layout_title_text=title,\n",
    "               layout_showlegend=True )  \n",
    "        \n",
    "        \n",
    "        \n",
    "         # # # # # Now create one donut per protected attribute for a clearer view if the call specifies this# # # # # # \n",
    "        if show_individual == True:\n",
    "            specs = []\n",
    "            fig2 = \"\"\n",
    "            full_title =  ''\n",
    "            if len(attributes_list) > 1:\n",
    "                for x in range(len(attributes_list)):\n",
    "                    specs.append ({'type':'domain'})\n",
    "                fig2 = make_subplots(rows=1, cols=len(attributes_list), specs=[specs])\n",
    "                for attribute, index in zip (attributes_list, range(len(attributes_list))):\n",
    "                    full_title =  full_title + \"/ \" + attribute\n",
    "                    df = data_frame[[attribute]+[\"count\"]].groupby([attribute]).count().reset_index().rename(columns={\"count\": \"values\"})\n",
    "                    pie = go.Pie(\n",
    "                    hole=hole, #Sets the fraction of the radius to cut out of the pie. Use this to make a donut chart\n",
    "                    sort=False,\n",
    "                    direction='clockwise',\n",
    "                    values=df[\"values\"],\n",
    "                    labels=df[attribute],\n",
    "                    textinfo='label+percent',\n",
    "                    textposition='inside',\n",
    "                    name=attribute,\n",
    "                    title = attribute,\n",
    "                    #insidetextfont=dict(family=\"sans serif\",size=18,color=\"crimson\"),\n",
    "            \n",
    "                    marker={'colors': color_arr[x],'line': {'color': 'black', 'width': 1}} )\n",
    "                    fig2.add_trace(pie, 1, index+1)\n",
    "    \n",
    "                fig2.update_layout(autosize=False,\n",
    "                          width=600,\n",
    "                          height=300,\n",
    "                         #margin=dict(l=50,r=50,b=100, t=100,pad=4),\n",
    "                  \n",
    "                          )\n",
    "    \n",
    "    \n",
    "                fig2.update_traces(textposition='inside')\n",
    "                fig2.update(layout_title_text='Representation per attribute', layout_showlegend=True)   \n",
    "\n",
    "                fig2.show()\n",
    "        #as this can be a pointer to the input, clean it up\n",
    "        data_frame.drop([\"count\"], axis=1, inplace = True)\n",
    "        gc.collect()\n",
    "        return fig #should also return fig2\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    #################################################################################################\n",
    "    #  \n",
    "    # METHOD USED TO PLOT THE DISTRIBUTION OF THE OUTCOME ACROSS GROUPS\n",
    "    #################################################################################################\n",
    "    \n",
    "    def plot_distribution(self, attributes_list, y, data_frame, w=800, h=800, y_high_positive = True, curve_type = \"kde\"):\n",
    "        try:\n",
    "            dist_arr = []\n",
    "            g_labels = []\n",
    "            for attribute, pos in zip (attributes_list, range(len(attributes_list))):\n",
    "                groups = data_frame[attribute].unique()\n",
    "                for value in range(len(groups)):\n",
    "                    df = data_frame[ data_frame[attribute] == groups[value]]\n",
    "                    dist_arr.append(df[y])\n",
    "                    g_labels.append(attribute + \"-\" + str(groups[value]))\n",
    "                # Add histogram data\n",
    "                # Group data together\n",
    "                hist_data = dist_arr\n",
    "                group_labels = g_labels\n",
    "                #Add the dist of all combined groups\n",
    "                hist_data.append(data_frame[y])\n",
    "                group_labels.append(\"All\")\n",
    "            \n",
    "                # Create distplot with custom bin_size\n",
    "                fig = ff.create_distplot(hist_data, group_labels, curve_type = curve_type, show_hist=True) #, bin_size=[.1, .25, .5, 1]\n",
    "                # Add title\n",
    "                fig.update_layout(\n",
    "                    autosize=False,\n",
    "                    width=900,\n",
    "                    height=500,\n",
    "                    margin=dict(l=50,r=50,b=100, t=100,pad=4),\n",
    "                    paper_bgcolor=\"LightSteelBlue\",\n",
    "                    title=y +' distribution across ' + attribute,\n",
    "                    xaxis=dict(range=[data_frame[y].min(), data_frame[y].max()])\n",
    "                )\n",
    "\n",
    "                f2 = go.FigureWidget(fig)\n",
    "                f2.show()\n",
    "                #f = fig.show(renderer=\"notebook\")\n",
    "                groups = []\n",
    "                dist_arr = []\n",
    "                g_labels = []\n",
    "\n",
    "        except Exception as e:\n",
    "            self.display_html(\"Something went wrong generating the distribution, change the distribution type and ensure group is represented sufficiently to generate dist\", \n",
    "                              self.text_color, \"h4\")\n",
    "            print (e)\n",
    "        gc.collect()\n",
    "        \n",
    "    \n",
    "    #################################################################################################\n",
    "    #  \n",
    "    # \n",
    "    #################################################################################################\n",
    "    def plot_outcome_representation(self, attributes_list, \n",
    "                                    y_value, data_frame, \n",
    "                                    w=800, h=800, \n",
    "                                    y_high_positive = True,\n",
    "                                    percentile = None,\n",
    "                                    top_x = None,\n",
    "                                    persist_impact_col = False):\n",
    "        \n",
    "        \n",
    "        num_of_attributes = len(attributes_list)\n",
    "        if num_of_attributes > 6:\n",
    "            num_of_attributes = 6\n",
    "            display (HTML(\"showing only the first 6 attributes\"))\n",
    "        \n",
    "        #create a new column that categorises positive outcome by default, as above average score and negative \n",
    "        #outcome as below average score\n",
    "        y = y_value #Sort the naming out here later\n",
    "        text = \"\"\n",
    "        HIGH_RANGE_POSITIVE = y_high_positive\n",
    "        yMin = round(data_frame[y_value].min(), 10)\n",
    "        yDivPoint = data_frame[y_value].mean()\n",
    "        yMax = data_frame[y_value].max()   \n",
    "        \n",
    "        outcome = ['', '']      \n",
    "        if HIGH_RANGE_POSITIVE == True:\n",
    "            # min to mean is neg, mean to max is pos\n",
    "            outcome = [\"Neg\", \"Pos\"]\n",
    "            #Rather than having defined bins of [yMin, yMean, yMax] base the display on precentiles.\n",
    "            if not percentile == None:\n",
    "                yDivPoint = data_frame[data_frame[y_value] >= np.percentile(data_frame[y_value],percentile)].min()[y_value]\n",
    "            if not top_x == None:\n",
    "                #Ascending means smallest to largest,\n",
    "                _text = \"Top n = \"+ str (data_frame.sort_values(y_value,ascending = True).head(top_x).shape[0])\n",
    "                self.display_html(_text, self.text_color, \"p\")\n",
    "                yDivPoint = data_frame.sort_values(y_value,ascending = False).head(top_x).min()[y_value]\n",
    "                    \n",
    "        if HIGH_RANGE_POSITIVE == False:\n",
    "            outcome = [\"Pos\", \"Neg\"]\n",
    "            # min to mean is pos, mean to max is neg\n",
    "            #Rather than having defined bins of [yMin, yMean, yMax] base the display on precentiles.\n",
    "            if not percentile == None:\n",
    "                _text = \"bottom percentile = \" + str(percentile)\n",
    "                self.display_html(_text, self.text_color, \"p\")\n",
    "                yDivPoint= data_frame[data_frame[y_value] <= np.percentile(data_frame[y_value],percentile)].max()[y_value]\n",
    "            if not top_x == None:\n",
    "                #Ascending means smallest to largest,\n",
    "                _text = \"Top x =\" + str(data_frame.sort_values(y_value,ascending = True).head(top_x).shape[0])\n",
    "                self.display_html(_text, self.text_color, \"p\")\n",
    "                yDivPoint = data_frame.sort_values(y_value,ascending = True).head(top_x).max()[y_value]\n",
    "        \n",
    "        yMin = round(yMin, 3)\n",
    "        yDivPoint = round(yDivPoint, 3)\n",
    "        yMax = round(yMax, 3) \n",
    "        \n",
    "        def get_next_prev_fraction(num):#local method\n",
    "            n = num\n",
    "            if isinstance(n, float):\n",
    "                s = str(n)\n",
    "                _len = s[::-1].find('.')\n",
    "                add = \"0.\"\n",
    "                if (_len > 0):\n",
    "                    for x in range(_len-1):\n",
    "                        add = add + \"0\"\n",
    "                    add = add +\"1\"\n",
    "                _next = round (n + float(add), _len)\n",
    "                _prev = round (n - float(add), _len)\n",
    "            return _next, _prev\n",
    "\n",
    "        _, yDivPoint = get_next_prev_fraction(yDivPoint)\n",
    "        bins = [yMin-1, yDivPoint, yMax+1]#adding + and -1 to account for any decimal issues\n",
    "                          \n",
    "        impact_col_name = \"impact\"    \n",
    "\n",
    "        data_frame[impact_col_name] = pd.cut(data_frame[y_value], bins, labels=outcome)\n",
    "              \n",
    "        x = \"* Output '\" + str(y_value) + \"' grouped in range:\"\n",
    "        text = text + \"A high output is defined as a relevance(score) between \" + str(yDivPoint) + \" and \" + str(yMax)+\"<br>\"\n",
    "        text = text + \"A low output is defined as a relevance(score) between \" + str(yMin) + \" and \" + str(yDivPoint)\n",
    "        self.display_html(text, self.text_color, \"p\")\n",
    "\n",
    "        sequential_color_list = [\n",
    "            px.colors.sequential.Greens, \n",
    "            px.colors.sequential.Greys]\n",
    "\n",
    "        \n",
    "        fig2 = self.plot_donut( list((attributes_list)), \n",
    "                                 data_frame[(data_frame[impact_col_name]==\"Pos\")] ,\n",
    "                                 w=500, h=500, \n",
    "                                 y_high_positive = True, \n",
    "                                 title = \"Positive impact across groups\", \n",
    "                                 show_individual = False) \n",
    "        \n",
    "        fig3 = self.plot_donut( list((attributes_list)), \n",
    "                                 data_frame[(data_frame[impact_col_name]==\"Neg\")] ,\n",
    "                                 w=500, h=500, \n",
    "                                 y_high_positive = True, \n",
    "                                 title = \"Negative impact across groups\", \n",
    "                                 show_individual = False) \n",
    "        \n",
    "        df_ratios = data_frame[attributes_list+[impact_col_name]+[y_value]].groupby(attributes_list+[impact_col_name]).count().reset_index().rename(columns={y_value: \"values\"})     \n",
    "        \n",
    "        _total =  df_ratios['values'].sum()\n",
    "        _total_pos =  df_ratios[(df_ratios[impact_col_name]==\"Pos\")]['values'].sum()\n",
    "        _total_neg =  df_ratios[(df_ratios[impact_col_name]==\"Neg\")]['values'].sum()\n",
    "        \n",
    "        _text = \"Total Number of samples: \" + str( _total)\n",
    "        _text = _text + \" (Positive: \" + str(_total_pos) + \", Negative: \"+ str(_total_neg) + \")\"\n",
    "        self.display_html(_text, self.text_color, \"p\")\n",
    "        num_unique_out = len(data_frame[y_value].unique())\n",
    "        _text = \"*Note the number may vary from the top-n specified due to multiple records having same value, the number of unique outputs is \" + str(num_unique_out)\n",
    "        self.display_html(_text, self.text_color, \"p\")\n",
    "        one, isto = self.ratio(_total_pos, _total_neg)\n",
    "        df_ratios['labels'] =  df_ratios.apply(lambda row : self.create_label(row[attributes_list]), axis = 1) \n",
    "        df_ratios['labels'].fillna(0,inplace=True)\n",
    "        attr_list = []\n",
    "        attr_list.append(\"All\")\n",
    "        isto_list = []\n",
    "        isto_list.append(isto)\n",
    "        pcnt_list = []\n",
    "        pcnt_list.append((_total_pos/(_total_pos+_total_neg))*100)\n",
    "        for label in df_ratios['labels'].unique():\n",
    "            pos = df_ratios[(df_ratios['labels']==label) & (df_ratios[impact_col_name]==\"Pos\")]['values']\n",
    "            neg = df_ratios[(df_ratios['labels']==label) & (df_ratios[impact_col_name]==\"Neg\")]['values']\n",
    "            one, isto = self.ratio(pos.values[0], neg.values[0])\n",
    "            attr_list.append(label)\n",
    "            isto_list.append(isto)\n",
    "            pcnt = (pos.values[0]/(pos.values[0]+neg.values[0]))*100\n",
    "            if math.isnan(pcnt):\n",
    "                pcnt_list.append(0)\n",
    "            else:\n",
    "                pcnt_list.append(pcnt)\n",
    "        \n",
    "        fig4 = go.Figure()\n",
    "        fig4.add_trace(go.Bar(\n",
    "                            x=attr_list,\n",
    "                            y=isto_list,\n",
    "                            marker_color='indianred'\n",
    "                        ))\n",
    "\n",
    "\n",
    "            # Here we modify the tickangle of the xaxis, resulting in rotated labels.\n",
    "        fig4.update_layout(xaxis_tickangle=-45, \n",
    "                           title = \"Ratio of Positive to Negative (for each 1 positive effect)\",\n",
    "                          autosize=False,\n",
    "                          width=900,\n",
    "                          height=400,)\n",
    "        \n",
    "        fw4 = go.FigureWidget(fig4)\n",
    "        fig5 = go.Figure()\n",
    "        fig5.add_trace(go.Bar(\n",
    "                            x=attr_list,\n",
    "                            y=pcnt_list,\n",
    "                            marker_color='indianred'\n",
    "                        ))\n",
    "\n",
    "\n",
    "            # Here we modify the tickangle of the xaxis, resulting in rotated labels.\n",
    "        fig5.update_layout(xaxis_tickangle=-45, \n",
    "                           title = \"Percentage of positive outcomes per group\",\n",
    "                          autosize=False,\n",
    "                          width=900,\n",
    "                          height=400,)\n",
    "        \n",
    "        fw5 = go.FigureWidget(fig5)\n",
    "        \n",
    "        hbox1 = widgets.HBox([fig2, fig3])\n",
    "        hbox2 = widgets.HBox([fw4])\n",
    "        hbox3 = widgets.HBox([fw5])\n",
    "        display(widgets.VBox([hbox1, hbox2, hbox3]))\n",
    "\n",
    "        del fig2\n",
    "        del fig3\n",
    "        del fig4\n",
    "        del fig5\n",
    "        \n",
    "        num_of_attributes = len(attributes_list)        \n",
    "        def powerset(iterable):\n",
    "            \"powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\"\n",
    "            s = list(iterable)\n",
    "            res = chain.from_iterable(combinations(s, r) for r in range(len(s)+1))\n",
    "            list_set = list(res)\n",
    "            final_list = []\n",
    "            for val in list_set:\n",
    "                if len(val) == 2:\n",
    "                    final_list.append(val)\n",
    "            return final_list\n",
    "        fig = go.Figure()\n",
    "        if num_of_attributes > 1:\n",
    "            \n",
    "            comb = powerset(attributes_list)\n",
    "            #for each combination of 2 protected attributes \n",
    "            for a, pos in zip (comb, range(len(comb))):\n",
    "                df = data_frame[[a[0]]+[a[1]]+[impact_col_name]+[y_value]].groupby([a[0]]+[a[1]]+[impact_col_name]).count().reset_index().rename(columns={y_value: \"values\"})\n",
    "                _total =  df['values'].sum()\n",
    "                _total_pos =  df[(df[impact_col_name]==\"Pos\")]['values'].sum()\n",
    "                _total_neg =  df[(df[impact_col_name]==\"Neg\")]['values'].sum()\n",
    "                color_index = 7\n",
    "                color_index_g = 7\n",
    "                for value in df[a[1]].unique():\n",
    "                    green = px.colors.sequential.Greens[color_index]\n",
    "                    if color_index != 0:\n",
    "                        color_index = color_index - 1\n",
    "                    else:\n",
    "                        color_index = 7\n",
    "                    \n",
    "                    name = a[1]+\"_\"+str(value)\n",
    "                    \n",
    "                    temp = df[(df[a[1]]==value) & (df[impact_col_name]==\"Pos\")]\n",
    "                    _pcnt = list (  round((temp[\"values\"]/_total) * 100 , 2)) \n",
    "                    _pcnt_from_total_pos = list ( round(  (temp[\"values\"]/_total_pos) * 100, 2)) \n",
    "                    \n",
    "                    for x in range (len(_pcnt_from_total_pos)):\n",
    "                        _pcnt_from_total_pos[x] = str(_pcnt_from_total_pos[x]) + \"% of all Positive\"\n",
    "                    fig.add_trace(go.Bar(\n",
    "                            y=df[a[0]].unique(),\n",
    "                            x=temp[\"values\"],\n",
    "                            name='Positive-' + name,\n",
    "                            text = _pcnt_from_total_pos,\n",
    "                            textposition='auto',\n",
    "                            orientation='h',\n",
    "                            marker=dict(\n",
    "                            color=green,\n",
    "                            line=dict(color='rgba(58, 71, 80, 1.0)', width=2)\n",
    "                            )\n",
    "                        ))\n",
    "                for value in df[a[1]].unique():\n",
    "                    grey = px.colors.sequential.Oranges[color_index_g]\n",
    "                    if color_index_g != 0:\n",
    "                        color_index_g = color_index_g - 1\n",
    "                    else:\n",
    "                        color_index_g = 7\n",
    "               \n",
    "                    name = a[1]+\"_\"+str(value)\n",
    "                    temp = df[(df[a[1]]==value) & (df[impact_col_name]==\"Neg\")]\n",
    "                    _pcnt = list ( round(  (temp[\"values\"]/_total) * 100 , 2) )\n",
    "                    _pcnt_from_total_neg = list ( round(  (temp[\"values\"]/_total_neg) * 100, 2) )\n",
    "                    for x in range (len(_pcnt_from_total_neg)):\n",
    "                        _pcnt_from_total_neg[x] = str(_pcnt_from_total_neg[x]) + \"% of all Negative\"\n",
    "                    fig.add_trace(go.Bar(\n",
    "                            y=df[a[0]].unique(),\n",
    "                            x=temp[\"values\"],\n",
    "                            name='Negative_' + name,\n",
    "                            text = _pcnt_from_total_neg,\n",
    "                            textposition='auto',\n",
    "                            orientation='h',\n",
    "                            marker=dict(\n",
    "                            color=grey,\n",
    "                            line=dict(color='rgba(58, 71, 80, 1.0)', width=2)\n",
    "                        )\n",
    "                    ))\n",
    "                        \n",
    "\n",
    "            fig.update_layout(title = \"Impact of results on: \"+ a[0]+ \" and \"+ a[1], \n",
    "                              barmode='stack',\n",
    "                              xaxis_tickangle=-45,\n",
    "                              autosize=False,\n",
    "                              width=900,\n",
    "                              height=h,\n",
    "                              legend_orientation=\"h\",\n",
    "                              margin=dict(l=50,r=50,b=100, t=100,pad=4),\n",
    "                              xaxis=dict(title=a[1]),\n",
    "                              yaxis=dict(title=a[0]), \n",
    "                             )\n",
    "            fig.show()\n",
    "            del fig\n",
    "            \n",
    "        else:#only one protected group so just show it   \n",
    "            df = data_frame[attributes_list+[impact_col_name]+[y_value]].groupby(attributes_list+[impact_col_name]).count().reset_index().rename(columns={y_value: \"values\"})\n",
    "            temp = df[(df[impact_col_name]==\"Pos\")]\n",
    "            _total =  df['values'].sum()\n",
    "            _total_pos =  df[(df[impact_col_name]==\"Pos\")]['values'].sum()\n",
    "            _total_neg =  df[(df[impact_col_name]==\"Neg\")]['values'].sum()\n",
    "            fig.add_trace(go.Bar(\n",
    "                            y=df[attributes_list[0]].unique(),\n",
    "                            x=temp[\"values\"],\n",
    "                            name='Positive',\n",
    "                            text = \"add %\",\n",
    "                            textposition='auto',\n",
    "                            orientation='h',\n",
    "                            marker=dict(\n",
    "                            color=\"green\",\n",
    "                            line=dict(color='rgba(58, 71, 80, 1.0)', width=2)\n",
    "                        )\n",
    "                    ))\n",
    "            \n",
    "            temp = df[(df[impact_col_name]==\"Neg\")]\n",
    "            fig.add_trace(go.Bar(\n",
    "                            y=df[attributes_list[0]].unique(),\n",
    "                            x=temp[\"values\"],\n",
    "                            name='Negative',\n",
    "                            text = \"add %\",\n",
    "                            textposition='auto',\n",
    "                            orientation='h',\n",
    "                            marker=dict(\n",
    "                            color=\"orange\",\n",
    "                            line=dict(color='rgba(58, 71, 80, 1.0)', width=2)\n",
    "                        )\n",
    "                    ))\n",
    "            \n",
    "            fig.update_layout(title = \"Impact of results on: \"+ str(attributes_list[0]), \n",
    "                              barmode='stack',\n",
    "                              xaxis_tickangle=-45,\n",
    "                              autosize=False,\n",
    "                              width=900,\n",
    "                              height=h,\n",
    "                              legend_orientation=\"h\",\n",
    "                              margin=dict(l=50,r=50,b=100, t=100,pad=4),\n",
    "#                               xaxis=dict(title=a[1]),\n",
    "#                               yaxis=dict(title=a[0]), \n",
    "                              )\n",
    "            fig.show()\n",
    "            del fig\n",
    "            \n",
    "        #as we added a column to this dataframe we will remove it here, as maybe a copy was not sent in\n",
    "        if persist_impact_col == False:\n",
    "            data_frame.drop([impact_col_name], axis=1, inplace = True)\n",
    "        else:\n",
    "            data_frame[impact_col_name].replace(['Pos', 'Neg'], [1, 0], inplace=True)\n",
    "            data_frame[\"Transformed_\"+y_value] = data_frame[impact_col_name]\n",
    "            data_frame.drop([impact_col_name], axis=1, inplace = True)\n",
    "        gc.collect()\n",
    "\n",
    "    \n",
    "    #################################################################################################\n",
    "    #  \n",
    "    # \n",
    "    #################################################################################################   \n",
    "    def scale_normalise(self, attributes_list, data_frame, w=20, h=20, apply = False, s_type = \"MIN_MAX_SCALAR\"):\n",
    "        \n",
    "        text = \"You selected \" + str (s_type)\n",
    "        self.display_html(text, self.text_color, \"p\")\n",
    "        scaler = preprocessing.StandardScaler()\n",
    "        \n",
    "        data_frame_to_scale = data_frame[attributes_list]\n",
    "        \n",
    "        if s_type == \"STANDARD_SCALAR\":\n",
    "            scaler = preprocessing.StandardScaler()    \n",
    "        elif s_type == \"MIN_MAX_SCALAR\":\n",
    "            scaler = preprocessing.MinMaxScaler()\n",
    "        elif s_type == \"ROBUST_SCALAR\":\n",
    "            scaler = preprocessing.RobustScaler()\n",
    "        elif s_type == \"NORMALIZER\":\n",
    "            scaler = preprocessing.Normalizer()\n",
    "      \n",
    "        \n",
    "        fig1, (ax1, ax2) = plt.subplots(nrows=2, figsize=(w,h));\n",
    "\n",
    "        plt.tight_layout()\n",
    "        scaled_df = scaler.fit_transform(data_frame_to_scale)\n",
    "        scaled_df = pd.DataFrame(scaled_df, columns=attributes_list)\n",
    "        \n",
    "        ax1.set_title('Before Scaling')\n",
    "        for attribute in attributes_list:\n",
    "            sns.kdeplot(data_frame[attribute], ax=ax1);\n",
    "        \n",
    "       \n",
    "        ax2.set_title('After '+ s_type)\n",
    "        for attribute in attributes_list:\n",
    "            sns.kdeplot(scaled_df[attribute], ax=ax2);\n",
    "        \n",
    "        plt.show()\n",
    "        plt.close(fig1)\n",
    "        plt.clf()\n",
    "        \n",
    "        if apply == True:\n",
    "            for attribute in attributes_list:\n",
    "                data_frame[attribute] = scaled_df[attribute]\n",
    "\n",
    "            return data_frame\n",
    "\n",
    "        return None\n",
    "    \n",
    "    #################################################################################################\n",
    "    #  \n",
    "    # \n",
    "    ################################################################################################# \n",
    "    def label_encoding(self, attributes_list, data_frame):\n",
    "        # creating initial dataframe\n",
    "        labelencoder = LabelEncoder()\n",
    "        return_dict = {}\n",
    "        for attribute in attributes_list:\n",
    "            categories = data_frame[attribute].unique()\n",
    "            temp_df = pd.DataFrame(categories, columns=[attribute])\n",
    "            # Assigning numerical values and storing in another column\n",
    "            temp_df[attribute+\"_benc\"] = temp_df[attribute]\n",
    "            temp_df[attribute] = labelencoder.fit_transform(temp_df[attribute])\n",
    "            # Convert this Temp_df into a dictionary\n",
    "            temp_df.set_index(attribute+\"_benc\", inplace=True)\n",
    "            return_dict.update(temp_df.to_dict())\n",
    "            data_frame[attribute+\"_benc\"] = data_frame[attribute]\n",
    "            data_frame[attribute] = labelencoder.fit_transform(data_frame[attribute])\n",
    "        return return_dict\n",
    "    \n",
    "    \n",
    "    #################################################################################################\n",
    "    #  \n",
    "    # \n",
    "    #################################################################################################   \n",
    "    def gcd(self, p, q): \n",
    "        if (q == 0): \n",
    "            return p\n",
    "        else:\n",
    "            return min(q, p)\n",
    "\n",
    "    def ratio(self, a,b):\n",
    "        _gcd = self.gcd(a,b)\n",
    "        one = round(a/_gcd, 2)\n",
    "        isto = round(b/_gcd, 2)\n",
    "        if one != 1:\n",
    "            isto = round (1/one, 2)\n",
    "            one = 1.0\n",
    "        return one, isto\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #################################################################################################\n",
    "    #  VIEW FAIRNESS MATRICS AEQUITAS\n",
    "    # \n",
    "    #################################################################################################\n",
    "    \"\"\"Difference in means: The difference between the probability for a member of group-a be selected and \n",
    "        the probability for a member of group-b to be selected.\n",
    "\n",
    "        Disparate Impact: the Probability of a member of group-a be selected to be selected divided by\n",
    "        the probability of a member of group-b to be selected\n",
    "\n",
    "        False positive rate Ratio of false positive ratio's among protected groups\n",
    "\n",
    "       False negative rate: Ratio of false negative ratio's among protected groups\"\"\"\n",
    "            \n",
    "    def view_aequitas_fairness_metrics(self, \n",
    "                                       y_column_name,\n",
    "                                       protected_attributes_list,\n",
    "                                       X_data_frame, \n",
    "                                       y_target, \n",
    "                                       y_pred,\n",
    "                                       _w=600, _h=600, \n",
    "                                       y_high_positive = True,\n",
    "                                        ):\n",
    "\n",
    "        HIGH_RANGE_POSITIVE = y_high_positive\n",
    "        aeq_Plot = Plot()\n",
    "        aeq_Group = Group()\n",
    "        aeq_Bias = Bias()\n",
    "        aeq_Fairness = Fairness()\n",
    "\n",
    "        out1 = widgets.Output(layout={})\n",
    "        out2 = widgets.Output(layout={})\n",
    "        out3 = widgets.Output(layout={})\n",
    "        out4 = widgets.Output(layout={})\n",
    "        out5 = widgets.Output(layout={})\n",
    "        out6 = widgets.Output(layout={})\n",
    "        tab_contents = [out1, out2, out3, out4, out5, out6]\n",
    "        \n",
    "        children = tab_contents\n",
    "        tab = widgets.Tab(style={'description_layout':'auto', 'title_layout':'auto'})\n",
    "        tab.children = children\n",
    "        \n",
    "        tab.set_title(0, \"Confusion Matrix\")\n",
    "        tab.set_title(1, \"False Positive\")\n",
    "        tab.set_title(2, \"False Negative\")\n",
    "        tab.set_title(3, \"All Metrics\")\n",
    "        tab.set_title(4, \"Disparate Impact\")\n",
    "        tab.set_title(5, \"Fairness\")\n",
    "        \n",
    "        local_layout = {'width': 'auto', 'visibility':'visible'}\n",
    "        local_layout_hidden  = {'width': 'auto', 'visibility':'hidden'}\n",
    "        local_style = {'description_width':'initial'}\n",
    "\n",
    "        _choose_a = widgets.Dropdown(description = \"Select protected feature\", \n",
    "                                     options = protected_attributes_list,\n",
    "                                     layout = local_layout,\n",
    "                                     style = local_style)\n",
    "                \n",
    "        _choose_b = widgets.Dropdown(description = \"Select protected group\", \n",
    "                                             options = X_data_frame[_choose_a.value].unique(),\n",
    "                                             layout = local_layout,\n",
    "                                             style = local_style)\n",
    "        \n",
    "        _choose_measure = widgets.Dropdown(description = \"Select Metric\", \n",
    "                                             options = {'False Omission Rate' : 'for',\n",
    "                                                        'False Discovery Rate' :'fdr',\n",
    "                                                        'False Positive Rate': 'fpr',\n",
    "                                                        'False Negative Rate': 'fnr',\n",
    "                                                        'Negative Predictive Value': 'npv',\n",
    "                                                        'Precision': 'precision',\n",
    "                                                        'Predicted Positive Ratio_k' :'ppr',\n",
    "                                                        'Predicted Positive Ratio_g': 'pprev',\n",
    "                                                        'Group Prevalence':'prev'},\n",
    "                                             layout = local_layout,\n",
    "                                             value = 'precision',\n",
    "                                             style = local_style)\n",
    "    \n",
    "        \n",
    "        _choose_disparity_measure = widgets.Dropdown(description = \"Select Metric\", \n",
    "                                             options = {'False Positive Rate disparity': 'fpr_disparity',\n",
    "                                                        'False Negative Rate disparity': 'fnr_disparity',\n",
    "                                                        'Predicted Positive Ratio_k' : 'ppr_disparity',\n",
    "                                                        'Predicted Positive Ratio_g disparity' :'pprev_disparity',\n",
    "                                                        'Precision Disparity': 'precision_disparity',\n",
    "                                                        'False Discovery Rate disparity': 'fdr_disparity',\n",
    "                                                        'False Omission Rate disparity': 'for_disparity',\n",
    "                                                        'True Positive Rate disparity': 'tpr_disparity',\n",
    "                                                        'True Negative Rate disparity': 'tnr_disparity',\n",
    "                                                        'npv_disparity': 'npv_disparity',},\n",
    "                                             layout = local_layout,\n",
    "                                             value = 'fpr_disparity',\n",
    "                                             style = local_style)\n",
    "        \n",
    "        html = '''<h3>Aequitas: </h3> is an open source bias audit toolkit for machine learning developers, \n",
    "        analysts, and  policymakers to audit machine learning models for discrimination and bias,\n",
    "        and make informed and equitable decisions around developing and deploying predictive risk-assessment \n",
    "        tools.'''\n",
    "        display (HTML(html))\n",
    "        display(tab)\n",
    "        \n",
    "        df_aequitas = pd.concat([X_data_frame[protected_attributes_list],\n",
    "                                        y_target,\n",
    "                                        pd.DataFrame(y_pred, \n",
    "                                        index=X_data_frame.index)],\n",
    "                                        axis=1, sort=False);\n",
    "        \n",
    "        df_aequitas.rename(columns={y_column_name: 'label_value', 0: 'score'}, inplace=True);\n",
    "        df_aequitas[df_aequitas.columns.difference(['label_value', 'score'])] = df_aequitas[\n",
    "                                                    df_aequitas.columns.difference(['label_value', 'score'])].astype(str);\n",
    "                \n",
    "        cross_tab, _ =  aeq_Group.get_crosstabs(df_aequitas)\n",
    "        absolute_metrics = aeq_Group.list_absolute_metrics(cross_tab) \n",
    "        #columns not in absolute Matrix\n",
    "        counts_metrics = list (cross_tab[[col for col in cross_tab.columns if col not in absolute_metrics]].columns.values)\n",
    "        counts_metrics.remove('model_id') \n",
    "        counts_metrics.remove('score_threshold') \n",
    "        counts_metrics.remove('k') \n",
    "        \n",
    "        ## Read images from file (because this is binary, maybe you can find how to use ByteIO) but this is more easy\n",
    "        img2 = open('count.png', 'rb').read()\n",
    "        img1 = open('absolute.png', 'rb').read()\n",
    "        ## Create image widgets. You can use layout of ipywidgets only with widgets.\n",
    "        ## Set image variable, image format and dimension.\n",
    "        wi1 = widgets.Image(value=img1, format='png', width=300, height=400)\n",
    "        wi2 = widgets.Image(value=img2, format='png', width=300, height=400)\n",
    "        ## Side by side thanks to HBox widgets\n",
    "        sidebyside = widgets.HBox([wi1, wi2])\n",
    "        ## Finally, show.\n",
    "        \n",
    "        with out1:\n",
    "            clear_output(wait = False)\n",
    "            display (HTML (\"<b>Absolute Metrics across protected groups</b>\"))\n",
    "            display ( cross_tab[['attribute_name', 'attribute_value'] + absolute_metrics].round(2))\n",
    "            display (HTML (\"<br><b>Group counts across protected groups</b>\"))\n",
    "            display ( cross_tab[counts_metrics])\n",
    "            display(sidebyside)\n",
    "\n",
    "            \n",
    "        with out2: #False Positive\n",
    "            clear_output(wait = False)\n",
    "            html = '<b>False Positive Rate</b> - the model predicted the subjects outcome was positive when in fact it was not, in other words an incorrect decision TO recommend!<br>'\n",
    "\n",
    "            if  y_high_positive == True:\n",
    "                html = html + '''<b>* </b>You have indicated that a high outcome(ranking) has a positive impact on an individual\n",
    "                                therefore a high false positive rate will have a <b>positive</b> impact on a group\n",
    "                                '''\n",
    "            elif y_high_positive == False:\n",
    "                html = html + '''<b>* </b>You have indicated that a high outcome(ranking) has a negative impact on an individual\n",
    "                                therefore a high false positive rate will have a <b>negative<b> impact on a group\n",
    "                                '''\n",
    "            display (HTML(html))\n",
    "            fig1, (ax1) = plt.subplots(nrows=1, figsize=(10 ,5));\n",
    "            ax1 = aeq_Plot.plot_group_metric(cross_tab,'fpr', ax1);\n",
    "            plt.tight_layout();\n",
    "            ax1.set_title('False Positive ratios');\n",
    "            plt.show();\n",
    "            plt.close(fig1);\n",
    "            plt.clf();\n",
    "        \n",
    "        \n",
    "        with out3:#False Negative\n",
    "            clear_output(wait = False)\n",
    "            html = '<b>False Negative Rate</b> - the model predicted the subjects outcome was negative when in fact it was not, in other words an incorrect decision TO NOT recommend!<br>'\n",
    "            if  y_high_positive == True:\n",
    "                html = html +  '''<b>* </b>You have indicated that a high outcome(ranking) has a positive impact on an individual\n",
    "                                therefore a high false negative rate will have a <b>negative</b> impact on a group.\n",
    "                                '''\n",
    "            elif y_high_positive == False:\n",
    "                html = html + '''<b>* </b>You have indicated that a high outcome(ranking) has a negative impact on an individual\n",
    "                                therefore a high false negative rate will have a <b>positive impact</> on a group.\n",
    "                                '''\n",
    "            display (HTML(html))\n",
    "            fig1, (ax1) = plt.subplots(nrows=1, figsize=(10 ,5));\n",
    "            ax1 = aeq_Plot.plot_group_metric(cross_tab,'fnr', ax1);\n",
    "            plt.tight_layout();\n",
    "            ax1.set_title('False Negative ratios');\n",
    "            plt.show()\n",
    "            plt.close(fig1);\n",
    "            plt.clf();\n",
    "            \n",
    "        with out4:\n",
    "            clear_output(wait = False)\n",
    "            html = '''<b>Select the metric to view</b><br>''' \n",
    "            if  y_high_positive == True:\n",
    "                html = html +  '''<b>* </b>You have indicated that a high outcome(ranking) has a positive impact on an individual\n",
    "                                '''\n",
    "            elif y_high_positive == False:\n",
    "                html = html + '''<b>* </b>You have indicated that a high outcome(ranking) has a negative impact on an individual\n",
    "                               '''\n",
    "            display (HTML(html))\n",
    "            def show_any(choose_measure):\n",
    "                fig1, (ax1) = plt.subplots(nrows=1);\n",
    "                ax1 = aeq_Plot.plot_group_metric(cross_tab, choose_measure, ax1)\n",
    "                plt.tight_layout()\n",
    "                ax1.set_title(choose_measure)\n",
    "                plt.show()\n",
    "                plt.close(fig1)\n",
    "                plt.clf()\n",
    "            interact(show_any, choose_measure = _choose_measure);\n",
    "   \n",
    "        with out5:\n",
    "            clear_output(wait = False)\n",
    "            dict_of_controls = {}\n",
    "            \n",
    "            dis_imp_html = '''<b>Disparate Impact:</b>. A decision-making process suffers from disparate impact if the outcome \n",
    "            of the decision disproportionately benefits one group or disproportionately hurts another group.\n",
    "            It generally results from unintentional discrimination in decision-making systems.\n",
    "            Disparities are calculated as a ratio of a metric for a group of interest compared to a reference group. \n",
    "            For example, the False Negative Rate Disparity for Group-A compared to a reference Group-B is: FNR-B/FNR-A\n",
    "            The calculated disparities are in relation to a reference group, which will always \n",
    "            have a disparity of 1.0. Disparate impact is often measured by the eighty percent or four-fifths rule. '''\n",
    "            \n",
    "            display (HTML(dis_imp_html))\n",
    "            \n",
    "            display (HTML(\"<b>Select a reference group for each protected feature for comparison:</b>\"))\n",
    "            \n",
    "            for feature in protected_attributes_list:\n",
    "                dict_of_controls[feature] = widgets.Dropdown(description = \"-\" + feature +  \"- Ref group\", \n",
    "                                             options = X_data_frame[feature].unique(),\n",
    "                                             layout = local_layout,\n",
    "                                             style = local_style)\n",
    "            for c in dict_of_controls:\n",
    "                display(dict_of_controls[c])\n",
    "                \n",
    "                \n",
    "            \n",
    "            display (HTML(\"<b>Select the metric for which you want to view disparities:</b>\"))\n",
    "            def show_disparity(choose_disparity_measure, button): #local method within view_protected() funct\n",
    "                _ref_groups_dict = {}   \n",
    "                for c in dict_of_controls:\n",
    "                    _ref_groups_dict[c] = str(dict_of_controls[c].value)\n",
    "                \n",
    "                disparity = aeq_Bias.get_disparity_predefined_groups(cross_tab, \n",
    "                                                                     original_df=df_aequitas,\n",
    "                                                                     ref_groups_dict=_ref_groups_dict, \n",
    "                                                                     alpha=0.05,\n",
    "                                                                     mask_significance=True); \n",
    "               \n",
    "                num_rows = math.ceil( (len(protected_attributes_list))/2)\n",
    "                \n",
    "                fig = plt.figure(figsize=(12 ,6*num_rows))\n",
    "                plt.tight_layout()\n",
    "                ax_dict = {}\n",
    "                for x, num in zip (protected_attributes_list, range(len(protected_attributes_list))):\n",
    "                    ax_dict[x] = plt.subplot(1, 2, num+1)\n",
    "                    ax_dict[x] = aeq_Plot.plot_disparity(disparity, \n",
    "                                             group_metric=choose_disparity_measure, \n",
    "                                             attribute_name=x,\n",
    "                                             significance_alpha=0.05,\n",
    "                                             fig = fig,\n",
    "                                             ax = ax_dict[x]);\n",
    "                   \n",
    "                if  y_high_positive == True:\n",
    "                    html =   '''<b>* </b>You have indicated that a high outcome(ranking) has a positive impact on an individual\n",
    "                                therefore a XXX disparity score will have a <b>negative</b> impact on a group.<br>\n",
    "                                '''\n",
    "                elif y_high_positive == False:\n",
    "                    html = '''<b>* </b>You have indicated that a high outcome(ranking) has a negative impact on an individual\n",
    "                                therefore a therefore a XXX disparity score  will have a <b>positive impact</> on a group.<br>\n",
    "                                '''\n",
    "                display(HTML(html))\n",
    "                \n",
    "                plt.show()\n",
    "                display(HTML('''Sized based on group size, color based on disparity magnitude<br>\n",
    "                                Reference groups are displayed in grey with disparity = 1. <br>\n",
    "                                Disparities greater than 10x will show as 10x.<br>\n",
    "                                Disparities less than 0.1x will show as 0.1x.<br>\n",
    "                                Statistical siginificance(default 0.05) will show as ** on square.'''))\n",
    "                plt.close(fig1)\n",
    "                plt.clf()\n",
    "                pd.set_option('display.max_columns', None)\n",
    "                display (HTML(\"<b>All Calculated values:</b>\"))\n",
    "                display (disparity)\n",
    "                \n",
    "                with out6:\n",
    "                    clear_output(wait = False)\n",
    "                    for ref in _ref_groups_dict:\n",
    "                        display(HTML(\"Reference group is \" +_ref_groups_dict[ref] + \" for \" + ref))\n",
    "                        display(HTML(\"Green bar indicates Fair.<br>Red bar indicates unfair.\"))\n",
    "                    group_val_fairness= aeq_Fairness.get_group_value_fairness(disparity)\n",
    "                    parity_detrminations = aeq_Fairness.list_parities(group_val_fairness)\n",
    "                    aeq_Plot.plot_fairness_group_all(group_val_fairness, ncols=5, metrics = \"all\")\n",
    "                    display (group_val_fairness[['attribute_name', 'attribute_value']+parity_detrminations])\n",
    "                \n",
    "                \n",
    "            interact(show_disparity, \n",
    "                     choose_disparity_measure = _choose_disparity_measure,\n",
    "                     button = widgets.ToggleButton(\n",
    "                         description='Apply selected Reference group',\n",
    "                         layout = local_layout,\n",
    "                         style = local_style),\n",
    "                     )\n",
    "\n",
    "        \n",
    "                \n",
    "            di_rule_html =''''Eighty percent rule is a rule of thumb or a guideline applied to the measurement of \n",
    "        disparate impact whereby a selection rate for  a protected group-A which is less than 80% of the\n",
    "        selection rate for group-B, where group-B is the group with the highest selection rate, will generally \n",
    "        be considered as evidence of adverse impact against group-A. The eighty percent rule does not\n",
    "        incorporate probability distribution to determine if the disparity is as a result of chance and therefor is not a definitive \n",
    "        test.''' \n",
    "    \n",
    "\n",
    "# Precision or  positive predictive value(PPV) is the proportion of the individuals with a positive test result for which the true\n",
    "# condition is positive. This rate is sometimes called the precision.\n",
    "#                     print ('''The ppr and difference in means are more generalized fairness metrics, since they \n",
    "#                     only consider how much the outcome differs between the protected groups. \n",
    "#                     This plot will show a Gi% probability for a member of group Gi to obtain a positive outcome. \n",
    "#                     The rate of this metric denotes Disparate Impact''')\n",
    "             \n",
    "        \n",
    "#                 .plot_fairness_group(group_val_fairness, group_metric='fpr')\n",
    "#                 .plot_fairness_group(group_val_fairness, group_metric='fnr'\n",
    "#                 .plot_fairness_group(group_val_fairness, group_metric='ppr')\n",
    "\n",
    "\n",
    "#                 html_parity = \"\"\"Considering the rule of thumb a parity should be between 0.5 and 1.5, \n",
    "#                 The disparate impact still shows that men are somewhat favored over women,\n",
    "#                 but the difference is not much reduced. Based on the false negative ratio parity \n",
    "#                 we can say that we managed to mitigate the bias, but the model is still unfair. \"\"\"\n",
    "                \n",
    "                \n",
    "#         except Exception as e:\n",
    "#             self.display_html(\"Something went wrong viewing Aequitas fairness metrics\", self.text_color, \"h4\")\n",
    "#             print (e)\n",
    "        gc.collect()\n",
    "\n",
    "    def visualise_RMSE_model_eval(self, y_train, y_test, y_pred_train, y_pred_test):\n",
    "        y_predictedTrain = y_pred_train\n",
    "        y_predictedTest = y_pred_test\n",
    "        y_test = y_test\n",
    "        y_train = y_train\n",
    "        '''We will be using Root mean squared error(RMSE) and Coefficient of Determination(R score) to evaluate our model.\n",
    "        RMSE is the square root of the average of the sum of the squares of residuals. \n",
    "        The RMSE is the square root of the variance of the residuals. \n",
    "        #It indicates the absolute fit of the model to the datahow close the observed data points are to the models\n",
    "        #predicted values. Whereas R-squared is a relative measure of fit, RMSE is an absolute measure of fit. \n",
    "        #As the square root of a variance, RMSE can be interpreted as the standard deviation of the unexplained variance, \n",
    "        #and has the useful property of being in the same units as the response variable. \n",
    "        #Lower values of RMSE indicate better fit. \n",
    "        #RMSE is a good measure of how accurately the model predicts the response, and it is the most important criterion\n",
    "        #for fit if the main purpose of the model is prediction.\n",
    "\n",
    "        #Coefficient of Determination(R score) - The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). \n",
    "        #A constant model that always predicts the expected value of y, disregarding the input features, \n",
    "        #would get a R^2 score of 0.0. #R-squared is between 0 and 1, Higher values are better because it means \n",
    "        #that more variance is explained by the model.'''\n",
    "\n",
    " \n",
    "        display(\"*****EVALUATING MODEL WITH TRAINING DATA:***\")\n",
    "        rmse = mean_squared_error(y_train, y_predictedTrain)\n",
    "        r2 = r2_score(y_train, y_predictedTrain)\n",
    "        display(' Root mean squared error: '+ str(rmse))\n",
    "        display(' R2 score: '+ str(r2))\n",
    "\n",
    "        display(\"*****EVALUATING MODEL WITH TEST DATA:******\")\n",
    "        rmse = mean_squared_error(y_test, y_predictedTest)\n",
    "        r2 = r2_score(y_test, y_predictedTest)\n",
    "        display(' Root mean squared error: ' + str(rmse))\n",
    "        display(' R2 score: '+ str(r2))\n",
    "\n",
    "\n",
    "        n_train = len(y_train)\n",
    "\n",
    "\n",
    "        plt.figure(figsize=(20, 10))\n",
    "        plt.plot(range(n_train), y_train, label=\"train\")\n",
    "        plt.plot(range(n_train, len(y_test) + n_train), y_test, '-', label=\"test\")\n",
    "        plt.plot(range(n_train), y_predictedTrain, '--', label=\"prediction train\")\n",
    "\n",
    "        plt.plot(range(n_train, len(y_test) + n_train), y_predictedTest, '--', label=\"prediction test\")\n",
    "        plt.legend(loc=(1.01, 0))\n",
    "        plt.xlabel(\"Score\")\n",
    "        plt.ylabel(\"prediction\")\n",
    "        \n",
    "    def reload_data (self, pickle_path, data_frame_path, print_report = True):\n",
    "    # Reload the file\n",
    "        data_summary = dill.load(open(pickle_path, \"rb\"))\n",
    "        data_frame = pd.read_csv(data_frame_path)\n",
    "        display (HTML('''<b>Values saved in data_summary</b> <br>  \n",
    "        data_summary.renamed <br>\n",
    "        data_summary.referenceNames<br>\n",
    "        data_summary.encoding_dict<br>\n",
    "        data_summary.df_url<br>\n",
    "        data_summary.y_value<br>\n",
    "        data_summary.Y_BINARY<br>\n",
    "        data_summary.Y_CONTINUOUS<br>\n",
    "        data_summary.HIGH_RANGE_POSITIVE<br>\n",
    "        data_summary.protected_x<br>\n",
    "        data_summary.non_protected_x<br>\n",
    "        data_summary.all_columns_in_x<br>\n",
    "        data_summary.proxyAttributes<br>\n",
    "        data_summary.MLAttributes<br>\n",
    "        data_summary.html'''))\n",
    "        if print_report == True:\n",
    "            print(\"Number of samples in dataset: \", data_frame.shape[0])\n",
    "            print (\"Output to predict: \", data_summary.y_value)\n",
    "            print (\"Output is continuous: \", data_summary.Y_CONTINUOUS)\n",
    "            print (\"Output is binary: \", data_summary.Y_BINARY)\n",
    "            print (\"Num of unique outputs: \", len(data_frame[data_summary.y_value].unique()))\n",
    "            print (\"Min output: \", data_frame[data_summary.y_value].min())\n",
    "            print (\"Max output: \", data_frame[data_summary.y_value].max())\n",
    "            print (\"High output range is positive? \", data_summary.HIGH_RANGE_POSITIVE)\n",
    "            #print (\"High ranking is by default \", data_summary.y_mid_rank, \" to \", data_summary.y_max_rank)\n",
    "            #print (\"Low ranking is by default \",data_summary.y_min_rank , \" to \", data_summary.y_mid_rank)\n",
    "            print (\"\")\n",
    "            print (\"Protected input features\", data_summary.protected_x)\n",
    "            print (\"Other input features\", data_summary.non_protected_x)\n",
    "            print(\"\")\n",
    "            print (\"Summary of Data transformation per input feature:\")\n",
    "            for key in data_summary.html:\n",
    "                if data_summary.html[key] != \"\":\n",
    "                    print (\"************\")\n",
    "                    print (key)\n",
    "                    display (HTML (data_summary.html[key]))\n",
    "        \n",
    "            print (\"\")\n",
    "            print (\"Input Features identified as possible proxies to protected Features: \", data_summary.proxyAttributes)\n",
    "            print (\"\")\n",
    "            print (\"Input Features identified as possibly output from another ML Model: \", data_summary.MLAttributes)\n",
    "            print (\"\")\n",
    "            print (\"\")\n",
    "            print (\"The X and y Values to be used in Model Train/Test/Validate\")\n",
    "            display (data_frame[data_summary.protected_x+data_summary.non_protected_x+[data_summary.y_value]].head())\n",
    "            print (\"\")\n",
    "            print (\"\")\n",
    "            print (\"\")\n",
    "            print (\"All versions of all columns to be used for analysis of Test/Validate\")\n",
    "        return data_frame, data_summary\n",
    "    \n",
    "    \n",
    "    def get_train_test_split_data(self, data_frame, data_summary, include_protected):\n",
    "        if include_protected == True:\n",
    "            cols = data_summary.protected_x + data_summary.non_protected_x\n",
    "        else:\n",
    "            cols = data_summary.non_protected_x\n",
    "        return  data_frame.drop(data_summary.y_value, axis = 1), data_frame[data_summary.y_value], cols\n",
    "    \n",
    "    \n",
    "    \n",
    "    def shap_analysis(self, shap_values, explainer, x, data_summary):\n",
    "        try:\n",
    "            shap.initjs()\n",
    "        except:\n",
    "            print ( 'shap.initjs() failed to load javascript')\n",
    "        \n",
    "        outOverview = widgets.Output(layout={})\n",
    "        out1 = widgets.Output(layout={})\n",
    "        out2 = widgets.Output(layout={})\n",
    "        out3 = widgets.Output(layout={})\n",
    "        out4 = widgets.Output(layout={})\n",
    "        out5 = widgets.Output(layout={})\n",
    "        tab_contents = [out1, out2, out3, out4, out5]\n",
    "        \n",
    "        children = tab_contents\n",
    "        tab = widgets.Tab(style={'description_layout':'auto', 'title_layout':'auto'})\n",
    "        tab.children = children\n",
    "        \n",
    "        tab.set_title(0, \"Summary Importance plot\")\n",
    "        tab.set_title(1, \"Importance plot\")\n",
    "        tab.set_title(2, \"Dependence plot\")\n",
    "        tab.set_title(3, \"Individual force plot\")\n",
    "        tab.set_title(4, \"Collective force plot\")\n",
    "        \n",
    "        local_layout = {'width': 'auto', 'visibility':'visible'}\n",
    "        local_layout_hidden  = {'width': 'auto', 'visibility':'hidden'}\n",
    "        local_style = {'description_width':'initial'}\n",
    "        display(outOverview)\n",
    "        display(tab)\n",
    "        \n",
    "        \n",
    "        _choose = widgets.Dropdown(description = \"Select Feature\", \n",
    "                                    options = data_summary.protected_x + data_summary.non_protected_x,\n",
    "                                    layout = local_layout,\n",
    "                                    style = local_style)\n",
    "        all_comb = {}\n",
    "        for f in data_summary.protected_x:\n",
    "            for a in  x[f].unique():\n",
    "                all_comb[(f+\":\"+ str(a))] = a\n",
    "        \n",
    "        _protected = widgets.Dropdown(description = \"Filter by Protected Feature\", \n",
    "                                     options = all_comb,\n",
    "                                     layout = local_layout,\n",
    "                                     style = local_style)\n",
    "        \n",
    "        toggle = widgets.ToggleButton(\n",
    "                            value=False,\n",
    "                            description='Generate',\n",
    "                            disabled=False,\n",
    "                            button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
    "                            \n",
    "                            )\n",
    "        \n",
    "        with outOverview:\n",
    "            display (HTML('''<h3>SHAP</h3>(SHapley Additive exPlanations) KernelExplainer is a \n",
    "            model-agnostic method which builds a weighted linear regression by using training/test data, \n",
    "            training/test predictions, and whatever function that predicts the predicted values. \n",
    "            SHAP values represent a feature's responsibility for a change in the model output.\n",
    "            It computes the variable importance values based on the Shapley values from game theory, \n",
    "            and the coefficients from a local linear regression. </br>\n",
    "            see: https://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions.pdf <br>\n",
    "\n",
    "            It offer a high level of interpretability for a model, through two distinct approaches:\n",
    "\n",
    "            <b>Global interpretability</b>  the SHAP values can show how much each predictor contributes, \n",
    "            either positively or negatively, to the target variable. Similar to a variable importance plot however it also indicates the positive or negative relationship between each feature and the target output.\n",
    "\n",
    "            <b>Local interpretability</b>  each observation is assigned it's own SHAP value. \n",
    "            This provides a very granular level of transparency and interpretability where we can \n",
    "            determine why an individual cases receive a specific prediction  and the contribution of \n",
    "            each feature to the prediction. Generally speaking variable importance algorithms usually \n",
    "            only show the results across the entire dataset but not on each individual case.'''))\n",
    "            \n",
    "        with out1:\n",
    "          \n",
    "            html_desc = '''\n",
    "            <b>Summary importance plot </b><br><b>Feature importance:</b> Variables are ranked in descending order. The top variables contribute more to the model than the bottom ones and thus have high predictive power.<br>\n",
    "            ''' \n",
    "            wi1 = widgets.Output(layout=Layout(width='60%'))\n",
    "            with wi1:\n",
    "                shap.summary_plot(shap_values, x, plot_type=\"bar\"); \n",
    "            wi2 = widgets.HTML(value=html_desc,layout=Layout(width='30%') ) ; \n",
    "            sidebyside = widgets.HBox([wi1, wi2])\n",
    "            display (sidebyside)\n",
    "        with out2:\n",
    "            display (HTML('''<b>Importance plot:</b> lists the most significant variables in descending order. \n",
    "                          The top variables contribute more to the model than the bottom ones and thus have high predictive power.'''))\n",
    "            html_desc = '''\n",
    "            <b>Feature importance:</b> Variables are ranked in descending order.<br>\n",
    "            <b>Impact:</b> Horizontal location indicates if effect of feature is associated with a higher or lower prediction.<br>\n",
    "            <b>Original value:</b> Colour indicates if feature variable is high(red) or low(blue) for the particular observation.<br>\n",
    "            <b>Correlation:</b> A high or low impact(indicated by colour), a positive or negative impact(indicated by position on x-axis)\n",
    "                '''  \n",
    "            wi1 = widgets.Output(layout={})\n",
    "            with wi1:\n",
    "                shap.summary_plot(shap_values, x);\n",
    "            wi2 = widgets.HTML(value=html_desc,layout=Layout(width='30%') )  \n",
    "            sidebyside = widgets.HBox([wi1, wi2])\n",
    "            display (sidebyside)\n",
    "                \n",
    "        with out3:\n",
    "            \n",
    "            display (HTML (\"The decision variable is \" + str(data_summary.y_value)))\n",
    "            display (HTML ('''To understand how a single feature effects the output of the model a \n",
    "                             dependency plot plots the SHAP value of  that feature vs. the value of \n",
    "                             the feature for all the examples in a dataset.'''))\n",
    "            def show_dependancy_plot(choose):\n",
    "                html_desc = '''The dependency plots show relationship between the target ('''+ data_summary.y_value +  ''') \n",
    "                   and the selected feature ('''+ choose + ''') to review if it is linear, monotonic or \n",
    "                  more complex.  The additionla variable is the variable that the selected feature (''' + choose + ''') \n",
    "                  interacts with the most frequently. Vertical dispersion at a single value represents interaction \n",
    "                  effects with the other features.  '''\n",
    "                display (HTML(html_desc))\n",
    "                display (shap.dependence_plot(choose, shap_values, x))\n",
    "            interact(show_dependancy_plot, choose = _choose);\n",
    "    \n",
    "        with out4:\n",
    "            display (HTML (\"The decision variable is \" + str(data_summary.y_value)))\n",
    "            display (HTML ('''<b>Individual Force plot</b> shows the features which each contribute to push the model output \n",
    "                            from the base value (the average model output over the dataset passed) to the\n",
    "                            model output. Features pushing the prediction higher are shown in red, \n",
    "                            those pushing the prediction lower are shown in blue.'''))\n",
    "            # visualize the first prediction's explanation (use matplotlib=True to avoid Javascript)\n",
    "            display (HTML (\"<b>Generate random sample to investigate:</b>\"))\n",
    "            def show_individual_force_plot(protected, toggle):\n",
    "                feat = _protected.label.split(':')[0]\n",
    "                index = x[x[feat] == _protected.value].sample(1).index[0]\n",
    "                display (shap.force_plot(explainer.expected_value, \n",
    "                                     shap_values[index,:], \n",
    "                                     x.iloc[index,:],\n",
    "                                     matplotlib=True))\n",
    "            \n",
    "            interact(show_individual_force_plot, protected = _protected, toggle = toggle);\n",
    "         \n",
    "        with out5:\n",
    "            display (HTML (\"The decision variable is \" + str(data_summary.y_value)))\n",
    "            display (HTML ('''<b>Collective Force plot</b> A combination of all individual force plots, each rotated 90 degrees, and stacked\n",
    "                                horizontally, to explanation an entire dataset.'''))\n",
    "            display (shap.force_plot(explainer.expected_value, \n",
    "                                     shap_values, \n",
    "                                     x))\n",
    "\n",
    "    def get_protected (self, summary):\n",
    "        return summary.protected_x\n",
    "    \n",
    "    def get_protected_before_merge (self, summary):\n",
    "        return summary.all_columns_in_x\n",
    "        print (list([all_columns_in_x.contains('_bm')]))\n",
    "        print (list(X_train.columns[X_train.columns.str.contains('_benc')]))\n",
    "\n",
    "\n",
    "    def get_protected_before_transform (self, summary):\n",
    "        all_cols = summary.all_columns_in_x\n",
    "        prot = summary.protected_x\n",
    "\n",
    "        new_prot = []\n",
    "        for f in prot:\n",
    "            found = False\n",
    "            if f+'_bm' in all_cols:\n",
    "                new_prot.append(f+'_bm')\n",
    "                found = True\n",
    "            if f+'_benc' in all_cols:\n",
    "                new_prot.append(f+'_benc')\n",
    "                found = True\n",
    "            if f.endswith('_oh_benc'):\n",
    "                new_prot.append(f)\n",
    "                found = True\n",
    "        \n",
    "            if found == False:\n",
    "                new_prot.append(f)\n",
    "        return new_prot\n",
    "    \n",
    "    def prepare_to_shap(self, X_in, count = 100, save_to_path = './'):\n",
    "        x = shap.sample( X_in, count)\n",
    "        x = x.reset_index(drop=True)\n",
    "        explainer = shap.KernelExplainer(logistic_reg_model.predict, x ) # The second argument is the \"background\" dataset; a size of 100 rows is gently encouraged by the code\n",
    "        shap_values = explainer.shap_values(x, l1_reg=\"num_features(10)\")\n",
    "        print(f'length of SHAP values: {len(shap_values)}')\n",
    "        print(f'Shape of each element: {shap_values[0].shape}')\n",
    "        path =  save_to_path + \"shap_values.pickle\"\n",
    "        print (\"Shap_values saved to\", path)\n",
    "        dill.dump(shap_values, file = open(path, \"wb\"))\n",
    "        path =  save_to_path + \"shap_explainer.pickle\"\n",
    "        print (\"Shap_explainer saved to\", path)\n",
    "        dill.dump(explainer, file = open(path, \"wb\"))\n",
    "        path =  save_to_path +\"shap_x.pickle\"\n",
    "        print (\"Shap_explainer saved to\", path)\n",
    "        dill.dump(x, file = open(path, \"wb\"))\n",
    "        return explainer, shap_values, x\n",
    "\n",
    "    def reload_shap_data (self, _path):\n",
    "        path = _path \n",
    "        shap_values_path = path + \"/shap_values.pickle\"\n",
    "        explainer_path = path + \"/shap_explainer.pickle\"\n",
    "        x_path = path + \"/shap_x.pickle\"\n",
    "        shap_values = dill.load(open(shap_values_path, \"rb\"))\n",
    "        explainer = dill.load(open(explainer_path, \"rb\"))\n",
    "        x = dill.load(open(x_path, \"rb\"))\n",
    "        # Reload the file\n",
    "        return shap_values, explainer, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python3.6 PyEnv",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": "30",
    "lenType": "30",
    "lenVar": "200"
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
