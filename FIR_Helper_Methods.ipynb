{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-26T18:45:12.555549Z",
     "start_time": "2020-07-26T18:45:05.532207Z"
    }
   },
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "import os\n",
    "from datetime import date\n",
    "import re\n",
    "import random\n",
    "import math\n",
    "from collections import Counter, namedtuple\n",
    "import gc\n",
    "import threading\n",
    "import time\n",
    "from itertools import cycle, chain, combinations\n",
    "import itertools\n",
    "import warnings\n",
    "import kaleido \n",
    "from contextlib import suppress\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#import pprint\n",
    "import pandas_profiling\n",
    "from pandas_profiling.config import config\n",
    "from pandas_profiling.model.base import Variable\n",
    "import phik\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Layout, Button, Box\n",
    "from ipywidgets import interact, interact_manual\n",
    "from IPython.display import display, clear_output, HTML\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "#from plotly.graph_objs import graph_objs as go \n",
    "\n",
    "\n",
    "\n",
    "import ipyfilechooser\n",
    "from ipyfilechooser import FileChooser\n",
    "import dill\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "import shap\n",
    "\n",
    "from aequitas.group import Group\n",
    "from aequitas.bias import Bias\n",
    "from aequitas.fairness import Fairness\n",
    "from aequitas.plotting import Plot\n",
    "from aequitas.preprocessing import preprocess_input_df\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import chi2\n",
    "from typing import Callable, Dict, List, Optional, Union\n",
    "\n",
    "import benfordslaw as bl\n",
    "import missingno as msno\n",
    "\n",
    "# from confuse import NotFoundError\n",
    "# from pandas.core.base import DataError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T15:53:45.366369Z",
     "start_time": "2020-06-14T15:53:45.278180Z"
    }
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T19:49:13.995547Z",
     "start_time": "2020-07-31T19:49:12.762786Z"
    }
   },
   "outputs": [],
   "source": [
    "class helper_methods():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.text_color = \"green\"\n",
    "        self.progressBar = widgets.FloatProgress(\n",
    "            value=0.0, \n",
    "            min=0.0, \n",
    "            max=100.0,\n",
    "            #layout = auto_width_layout,\n",
    "        )\n",
    "        \n",
    "        self._percent_slider = \"tbd\"               \n",
    "        self._top_x_slider  = \"tbd\"\n",
    "        \n",
    "    \n",
    "    def display_html(self, text, color, size):\n",
    "        content = \"<\" + size + \">\"  + \"<text style='color:\" + color + \"'>\" + text + \"</text>\" + \"</\" + size + \">\" \n",
    "        display (widgets.HTML(content, layout=Layout(width='100%')))\n",
    "        \n",
    "      \n",
    "    def work_in_progress(self):\n",
    "        for i in range(100):\n",
    "            if self.progressBar.value != 100:\n",
    "                self.progressBar.value = i# float(i+1)/total\n",
    "                time.sleep(0.3)\n",
    "            if self.progressBar.value == 100:\n",
    "                break\n",
    "            \n",
    "            \n",
    "\n",
    "                \n",
    "    #################################################################################################\n",
    "    #  \n",
    "    # \n",
    "    #################################################################################################\n",
    "    def view_correlations(self, df, column_list, column_list_with_Y, protected_column_list, y_col ):\n",
    "       \n",
    "        feature_set_with_y = df\n",
    "        out1 = widgets.Output(layout={})\n",
    "        out2 = widgets.Output(layout={})\n",
    "        out3 = widgets.Output(layout={})\n",
    "        out4 = widgets.Output(layout={})\n",
    "        tab_contents = [out1, out2, out3]\n",
    "        \n",
    "        children = tab_contents\n",
    "        tab = widgets.Tab()\n",
    "        tab.children = children\n",
    "        \n",
    "        tab.set_title(0, \"Correlation plot\")\n",
    "        tab.set_title(1, \"Pair Plot\")\n",
    "        tab.set_title(2, \"Feature distribution\")\n",
    "      \n",
    "        display(out4)\n",
    "        display(self.progressBar)\n",
    "        display(tab)\n",
    "        \n",
    "        column_to_count = []\n",
    "        column_to_corr = []\n",
    "        for  col in column_list_with_Y:\n",
    "            if len(feature_set_with_y[col].dropna().unique ())< 10:\n",
    "                column_to_count.append(col)\n",
    "            else:\n",
    "                column_to_corr.append(col)\n",
    "        \n",
    "        def f_cor(x ): #local method within view_correlations() funct\n",
    "                self.progressBar.value = 0\n",
    "                thread = threading.Thread(target=self.work_in_progress)\n",
    "                thread.start()\n",
    "                plt.clf()\n",
    "                plt.figure(figsize=(12, 12))     \n",
    "                fig1 = corrplot(feature_set_with_y[column_list_with_Y].corr(), size_scale=x, marker=\"o\");       \n",
    "                plt.show(fig1)\n",
    "                plt.clf()\n",
    "                plt.close(fig1)\n",
    "                self.progressBar.value = 100\n",
    "                        \n",
    "        \n",
    "        def f_cor_val( a,b ): #local method within view_correlations() funct\n",
    "                self.display_html (\"The correlation value is \" + str(feature_set_with_y[a].corr(feature_set_with_y[b])), self.text_color, \"p\")\n",
    "        \n",
    "        with out1:\n",
    "            interact(f_cor, x = widgets.IntSlider(description = \"slide to scale\", min=0, max=70000, step=100, value=500, continuous_update=False), );\n",
    "        \n",
    "            interact(f_cor_val, \n",
    "                        a = widgets.Dropdown(description = \"Column 1\", options = column_list_with_Y),\n",
    "                        b = widgets.Dropdown(description = \"Column 2\", options = column_list_with_Y)\n",
    "                );\n",
    "        \n",
    "                    \n",
    "        def f_pp(_hue): #local method within view_correlations() funct\n",
    "            self.progressBar.value = 0\n",
    "            thread = threading.Thread(target=self.work_in_progress)\n",
    "            thread.start()\n",
    "            with out4:\n",
    "                clear_output(wait = True)\n",
    "                self.display_html(\"Calculating pair plot..\", self.text_color, \"p\")\n",
    "            \n",
    "   \n",
    "            plt.figure(figsize=(6, 6))      \n",
    "            pp = sns.pairplot(feature_set_with_y[column_to_corr+[_hue]], corner=True, hue=_hue, diag_kind = 'kde', height=3, plot_kws = { 'alpha': 0.6,'s': 80, 'edgecolor': 'k'});  \n",
    "            pp._legend.get_title().set_fontsize(20)   \n",
    "            plt.show()\n",
    "            plt.clf()\n",
    "            plt.close()\n",
    "            self.progressBar.value = 100\n",
    "                \n",
    "            with out3: \n",
    "                clear_output(wait = True)\n",
    "                self.progressBar.value = 100\n",
    "                a = 0\n",
    "                b = 0\n",
    "                    \n",
    "                num_plots = len(column_to_count)\n",
    "                num_rows = math.ceil(num_plots/2)  \n",
    "                f, axes = plt.subplots(num_rows, 2, figsize=(15, num_rows*5))\n",
    "                for  col in column_to_count:\n",
    "                    sns.countplot(x = col, data = feature_set_with_y, ax=axes[a, b], hue=_hue)\n",
    "                    a = a + 1\n",
    "                    if a == (num_rows):\n",
    "                        b = b + 1\n",
    "                        a = 0\n",
    "                plt.show()\n",
    "                plt.clf()\n",
    "                plt.close()\n",
    "            \n",
    "            with out4:\n",
    "                clear_output(wait = True)\n",
    "                self.display_html(\"Plots complete!\", self.text_color, \"p\")\n",
    "                self.progressBar.value = 100\n",
    "            \n",
    "       \n",
    "        with out2:\n",
    "            clear_output(wait = True)\n",
    "            interact(f_pp, _hue = widgets.Dropdown(description = \"Hue based on\", \n",
    "                                                           options = protected_column_list));\n",
    "            \n",
    "            \n",
    "\n",
    "      \n",
    "    #################################################################################################\n",
    "    #  VIEW Group representation in the data and display in the ouutput area provided\n",
    "    # \n",
    "    #################################################################################################\n",
    "    def display_group_representation(self, data_frame, protected_features_list, output_area, _w=600, _h=600):\n",
    "        try:\n",
    "\n",
    "            with  output_area:\n",
    "                clear_output(wait = True)\n",
    "                fig_wig_a, fig_wig_b = self.plot_donut(protected_features_list,\n",
    "                                                       data_frame,\n",
    "                                                       w=_w, h=_h,\n",
    "                                                       title = \"Representation of Protected group(s) in the data\");\n",
    "                    \n",
    "                    \n",
    "                accordion = widgets.Accordion(children=[fig_wig_b, fig_wig_a])\n",
    "                accordion.set_title(0, 'Tree Map View')\n",
    "                accordion.set_title(1, 'Donut View')\n",
    "                display(accordion)\n",
    "                del fig_wig_a\n",
    "                del fig_wig_b\n",
    "        except:\n",
    "            print (\"Error in display_group_representation\")\n",
    "                    \n",
    "    \n",
    "    \n",
    "    #################################################################################################\n",
    "    #  VIEW analysis of NUMERIC features across protected groups, also used to show outcome distributio\n",
    "    #  across groups\n",
    "    #################################################################################################\n",
    "    def numeric_feature_analysis_across_groups(self, \n",
    "                                       data_frame, \n",
    "                                       feature,\n",
    "                                       protected_attributes_list,\n",
    "                                       label_y,\n",
    "                                       group_descriptions_dict,\n",
    "                                       label_encoding_dict,\n",
    "                                       reference_groups_dict,\n",
    "                                       _w=600, _h=600,\n",
    "                                       high_range_pos = True):\n",
    "        \n",
    "        local_layout = {'width': 'auto', 'visibility':'visible'}\n",
    "        local_layout_hidden  = {'width': 'auto', 'visibility':'hidden'}\n",
    "        local_style = {'description_width':'initial'}\n",
    "        HIGH_RANGE_POSITIVE = high_range_pos\n",
    "        \n",
    "        #If any of the protected features have a description replace the entry in the data-frame\n",
    "        #with the description so it is easier to read.\n",
    "        \n",
    "      \n",
    "        \n",
    "        def show_analysis(selected_protected, label, curve_type, remove_outliers): \n",
    "            #local method \n",
    "            #plot the representation of data in the dataframe per protected group\n",
    "            if selected_protected != \"--select--\": \n",
    "                #define a progress bar thread\n",
    "                \n",
    "                for feat in protected_attributes_list:\n",
    "                    #get_feature_info returns _choice_dict_for_drop, original_values, label_encoded_values, descriptions\n",
    "                    mapping = self.get_feature_info(feat, \n",
    "                                            data_frame[feat].dropna().unique(), \n",
    "                                            group_descriptions_dict,\n",
    "                                            label_encoding_dict,\n",
    "                                            {},\n",
    "                                            {})[0]\n",
    "                    keys = list( mapping.keys())\n",
    "                    values = list (mapping.values())\n",
    "                    reverse_mapping = dict(zip(values, keys))\n",
    "                    data_frame[feat] = data_frame[feat].map(reverse_mapping)###\n",
    "                    #now the dataframe has the description.\n",
    "                \n",
    "                \n",
    "                progress = widgets.FloatProgress(value=0.0, \n",
    "                                                 min=0.0, \n",
    "                                                 max=1.0)\n",
    "                progress.layout.width = '100%'\n",
    "                finished = False\n",
    "                def work(progress):\n",
    "                    total = 200\n",
    "                    for i in range(total):\n",
    "                        if finished != True:\n",
    "                            time.sleep(0.2)\n",
    "                            progress.value = float(i+1)/total\n",
    "                        else:\n",
    "                            progress.value = 200\n",
    "                            progress.style.bar_color = \"green\"\n",
    "                            break\n",
    "\n",
    "                thread = threading.Thread(target=work, args=(progress,))\n",
    "                display(progress)\n",
    "                #start the progress bar thread\n",
    "                thread.start()\n",
    "                #If a description was saved, use the desc rather than the actual values\n",
    "                #to achieve this we change the contents of the column to reflect the\n",
    "                #description, not the value.\n",
    "               \n",
    "                \n",
    "                \n",
    "                if group_descriptions_dict.get(selected_protected, False) != False:\n",
    "                    print(\"Descriptions have been saved for the Feature values\")\n",
    "                    \n",
    "                \n",
    "                if label_encoding_dict.get(selected_protected, False) != False:\n",
    "                    print(\"Feature has been label encoded. view with pre-encoded values?\")\n",
    "                \n",
    "                if selected_protected+\"_bm\" in data_frame.columns:\n",
    "                    print (\"feature has had values merged, view analysis with pre-merged valies?\")\n",
    "                \n",
    "                groups = data_frame[selected_protected].dropna().unique()\n",
    "                \n",
    "                tab = widgets.Tab()\n",
    "                widget_html_arr = []\n",
    "                tab_titles = []\n",
    "                for group in groups:\n",
    "                    filtered = data_frame[data_frame[selected_protected]==group]\n",
    "                    \n",
    "                    html_summary, outliers = self.detect_outlier_and_describe(filtered[feature],\n",
    "                                                                              3, \n",
    "                                                                              data_type = \"numeric\")\n",
    "                    \n",
    "                    widget_html_arr.append(widgets.HTML(html_summary))\n",
    "                    tab_titles.append(str(group))\n",
    "                    if remove_outliers == True:\n",
    "                        for val in outliers:\n",
    "                            indexNames = data_frame[ (data_frame[selected_protected] == group) & (data_frame[feature] == val) ].index\n",
    "                            data_frame.drop(indexNames , inplace=True) \n",
    "                tab.children = widget_html_arr\n",
    "                for x in range(len(tab_titles)):\n",
    "                    tab.set_title(x, tab_titles[x])\n",
    "\n",
    "                if curve_type == \"normal\":       \n",
    "                    text = ''' <b>Normal distribution:</b> A parametric approach which represents the behavior of most of the situations in \n",
    "                                   the universe. It's characterised by a bell shaped. The diameter, weight, strength, \n",
    "                                   and many other characteristics of natural, human or machine-made items are normally distributed.\n",
    "                                   In humans, performance, outcomes, grade point averages etc. are all normally distributed. \n",
    "                                   The normal distribution really is a normal occurrence. If we compare the normal distribution\n",
    "                                   of training data outcomes across two groups we can preform statistical test (such as the one below)\n",
    "                                   to determine if there is a <b>significant variance</b> between groups'''\n",
    "\n",
    "\n",
    "                if curve_type == \"kde\":         \n",
    "                    text = ''' <b>Kernel Density estimate:</b> is a nonparametric approach. Parametric estimation requires a \n",
    "                                    parametric family of distributions to be assumed(e.g Normal distribution). \n",
    "                                    If you have a basis to believe the model is approxiamtely correct it is advantageous to do parametric \n",
    "                                    inference. On the other hand it is possible that the data does not fit well to any member of the family.\n",
    "                                    In that case it is better to use kernel density estimation because it will construct a density that \n",
    "                                    reasonably fit the data. It does not require any assumption regarding parametric families.'''\n",
    "\n",
    "\n",
    "                fig_wig_dist, dist_output_per_group, groups = self.plot_distribution(selected_protected,\n",
    "                                                                                     feature, \n",
    "                                                                                     data_frame, \n",
    "                                                                                     w=_w, h=_h, \n",
    "                                                                                     y_high_positive = HIGH_RANGE_POSITIVE,\n",
    "                                                                                     curve_type = curve_type)\n",
    "                distOut = widgets.Output(layout={})\n",
    "                with distOut:\n",
    "                    display(fig_wig_dist)#as this returns an array of widgets\n",
    "                    display(HTML(\"\"\"Interactive version available <a href=\"output_dist.html\" target=\"_blank\"> here</a>\"\"\"))\n",
    "                    self.display_html(text, \"grey\", \"p\")\n",
    "                \n",
    "\n",
    "                #reference_group for t_test is the actual value in the dataframe (not the description)\n",
    "                reference_group = reference_groups_dict[selected_protected]\n",
    "                #Now if there is a description we should convert to the description\n",
    "                try:\n",
    "                    reference_group_to_use = group_descriptions_dict [selected_protected][reference_group]\n",
    "                except:\n",
    "                    reference_group_to_use = reference_group  \n",
    "\n",
    "                #Now add the two tailed T-test*************\n",
    "                t_testOut = widgets.Output(layout={})\n",
    "                with t_testOut:\n",
    "                    clear_output(wait = True)\n",
    "                    self.get_t_test_info(dist_output_per_group, groups, reference_group_to_use) \n",
    "\n",
    "                #Now add correlation matrix*************\n",
    "                correlationOut = widgets.Output(layout={})               \n",
    "                with correlationOut:\n",
    "                    clear_output(wait = True)\n",
    "                    \n",
    "                    self.feature_analysis_plot_correlation(data_frame[[feature]+[selected_protected]+[label_y]],\n",
    "                                                           label_y,\n",
    "                                                           feature,\n",
    "                                                           selected_protected)\n",
    "                    \n",
    "\n",
    "                #Now add scatter plot*************\n",
    "                scatterPlotOut = widgets.Output(layout={})                        \n",
    "                if label_y != feature:\n",
    "                    with scatterPlotOut:\n",
    "                        tab_scat = widgets.Tab()\n",
    "                        clear_output(wait = True)\n",
    "                        wig1 = go.FigureWidget(px.scatter_3d(data_frame[[feature]+[selected_protected]+[label_y]], x=label_y, y=feature, z=selected_protected,\n",
    "                                        color=selected_protected,\n",
    "                                        width=600, height=600,\n",
    "                                        title=label_y+\" \"+feature+ \" \" + selected_protected))\n",
    "        \n",
    "\n",
    "                        wig2 = go.FigureWidget(px.scatter(data_frame[[feature]+[selected_protected]+[label_y]], x=label_y, y=feature, \n",
    "                                     color=selected_protected,\n",
    "                                     width=600, height=600,\n",
    "                                     title=label_y+\" \"+feature))\n",
    "    \n",
    "                        \n",
    "                        tab_scat.children = [wig1,wig2]\n",
    "                        tab_scat.set_title(0, \"3D view\")\n",
    "                        tab_scat.set_title(1, \"2D view\")\n",
    "                        display(tab_scat)\n",
    "                          \n",
    "                BenfordsLawOut = widgets.Output(layout={}) \n",
    "                with BenfordsLawOut:\n",
    "                    benHTML = widgets.HTML(\"\"\"\n",
    "                    Also known as the Law of First Digits or the Phenomenon of Significant Digits, \n",
    "                    this law is the finding that the first numerals of the numbers found in series\n",
    "                    of records of the most varied sources do not display a uniform distribution,\n",
    "                    but rather are arranged in such a way that the digit “1” is the most frequent,\n",
    "                    followed by “2”, “3”...in a successively decreasing manner down to “9”. This\n",
    "                    can be a useful way of analysing data for fraud detection for example. \n",
    "                    <br><b>Note:</b> The law is not applicable to all numeric series but rather to those:<br>\n",
    "                    <b>*</b> With a high order of magnitude.<br>\n",
    "                    <b>*</b> No pre-established min or max <br>\n",
    "                    <b>*</b> Not numbers used as identifiers, e.g social security, identity, bank acc.<br>\n",
    "                    <b>*</b> Have a mean which is less than the median.<br>\n",
    "                    <b>*</b> Data is not concentrated around the mean.<br>\n",
    "                    \"\"\")\n",
    "                    display(benHTML)\n",
    "                    display (self.Benfords_law(data_frame[[feature]+[selected_protected]+[label_y]], \n",
    "                                               feature, \n",
    "                                               selected_protected))\n",
    "                    \n",
    "                if label_y != feature:\n",
    "                    accordion = widgets.Accordion(children=[distOut,\n",
    "                                                        tab,\n",
    "                                                        t_testOut,\n",
    "                                                        correlationOut,\n",
    "                                                        scatterPlotOut,\n",
    "                                                        BenfordsLawOut])\n",
    "                    accordion.set_title(0, 'Distribution of ' + feature + ' grouped by '+selected_protected)\n",
    "                    accordion.set_title(1, 'Describe (min/max/mean/outliers) for  ' + feature + ' grouped by '+selected_protected)\n",
    "                    accordion.set_title(2, 'Two tailed T-test for ' + feature + ' based on ' + selected_protected)\n",
    "                    accordion.set_title(3, 'Correlation between ' + feature + \", \" + label_y + ' and '+ selected_protected)\n",
    "                    accordion.set_title(4, 'Scatter plot ' + feature + ' and ' + label_y)\n",
    "                    accordion.set_title(5, 'Benfords_law for ' + feature + ' based on ' + selected_protected )\n",
    "                    accordion.selected_index=0 \n",
    "                    \n",
    "                if label_y == feature:\n",
    "                    accordion = widgets.Accordion(children=[distOut,\n",
    "                                                        tab,\n",
    "                                                        t_testOut,\n",
    "                                                        correlationOut,\n",
    "                                                        BenfordsLawOut])\n",
    "                    accordion.set_title(0, 'Distribution of ' + feature + ' grouped by '+selected_protected)\n",
    "                    accordion.set_title(1, 'Describe (min/max/mean/outliers) for  ' + feature + ' grouped by '+selected_protected)\n",
    "                    accordion.set_title(2, 'Two tailed T-test for ' + feature + ' based on ' + selected_protected)\n",
    "                    accordion.set_title(3, 'Correlation between ' + feature + ' and '+ selected_protected)\n",
    "                    accordion.set_title(4,'Newcomb/Benford law for ' + feature + ' based on ' + selected_protected )\n",
    "                    accordion.selected_index=0  \n",
    "                display (accordion)\n",
    "                finished = True\n",
    "\n",
    "        \n",
    "                \n",
    "        if feature == label_y:\n",
    "            self.display_html(\"Analysis of the distribution of the target (\"+ feature + \") across groups\", \"black\", \"h4\")\n",
    "        else:\n",
    "            self.display_html(\"Select the protected feature: \", \"black\", \"h4\")\n",
    "            \n",
    "  \n",
    "        interact(show_analysis, \n",
    "                     selected_protected = widgets.Dropdown(description = \"Protected Feature\",\n",
    "                                                options = [\"--select--\"] + protected_attributes_list,\n",
    "                                                layout = local_layout,\n",
    "                                                style = local_style),\n",
    "                    label = widgets.HTML(description=f\"<b><font color='black'>{'Density estimation configuration :'}</b>\",\n",
    "                                         style = {'description_width': 'initial'},\n",
    "                                         layout=Layout(width='90%')\n",
    "                                        ),\n",
    "                    curve_type = widgets.Dropdown(description = \"Density Estimation\",\n",
    "                                                  options = {\"Normal Distribution\":\"normal\", \"Kernel Density Estimation\":\"kde\"},\n",
    "                                                  layout = local_layout,\n",
    "                                                  style = local_style),\n",
    "                    remove_outliers = widgets.Checkbox(value=False,\n",
    "                                                       description='Remove outliers (per group) for analysis',\n",
    "                                                       disabled=False,\n",
    "                                                       layout = local_layout,\n",
    "                                                       style = local_style,\n",
    "                                                       indent=False),\n",
    "                                                );\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    #################################################################################################\n",
    "    #  VIEW analysis of CATEGORIC features across protected groups, also used to show outcome distributio\n",
    "    #  across groups\n",
    "    #################################################################################################\n",
    "    def categoric_feature_analysis_across_groups(self, \n",
    "                                       data_frame, \n",
    "                                       feature,\n",
    "                                       protected_attributes_list,\n",
    "                                       label_y,\n",
    "                                       group_descriptions_dict,\n",
    "                                       encoding_dict,\n",
    "                                       reference_groups_dict,\n",
    "                                       _w=600, _h=600,\n",
    "                                       high_range_pos = True):\n",
    "        \n",
    "        local_layout = {'width': 'auto', 'visibility':'visible'}\n",
    "        local_layout_hidden  = {'width': 'auto', 'visibility':'hidden'}\n",
    "        local_style = {'description_width':'initial'}\n",
    "        HIGH_RANGE_POSITIVE = high_range_pos\n",
    "        \n",
    "        \n",
    "        \n",
    "        def show_analysis(selected_protected): #local method within view_protected() funct\n",
    "            #choose is the protected attribute we will analyze against\n",
    "            if selected_protected != \"--select--\":\n",
    "                \n",
    "                #If a description was saved, use the desc rather than the actual values\n",
    "                #to achieve this we change the contents of the column to reflect the\n",
    "                #description, not the value.\n",
    "                for feat in protected_attributes_list:\n",
    "                    mapping = self.get_feature_info(feat, \n",
    "                                    data_frame[feat].dropna().unique(), \n",
    "                                    group_descriptions_dict,\n",
    "                                    encoding_dict,\n",
    "                                        {},{})[0]\n",
    "                keys = list( mapping.keys())\n",
    "                values = list (mapping.values())\n",
    "                reverse_mapping = dict(zip(values, keys))\n",
    "            \n",
    "                data_frame[feat] = data_frame[feat].map(reverse_mapping)\n",
    "                ####\n",
    "                #set up a threaded progress bar\n",
    "                progress = widgets.FloatProgress(value=0.0, min=0.0, max=1.0)\n",
    "                progress.layout.width = '100%'\n",
    "                finished = False\n",
    "                def work(progress):\n",
    "                    total = 200\n",
    "                    for i in range(total):\n",
    "                        if finished != True:\n",
    "                            time.sleep(0.2)\n",
    "                            progress.value = float(i+1)/total\n",
    "                        else:\n",
    "                            progress.value = 200\n",
    "                            progress.style.bar_color = \"green\"\n",
    "                            break\n",
    "\n",
    "                thread = threading.Thread(target=work, args=(progress,))\n",
    "                display(progress)\n",
    "                #start the progress bar\n",
    "                thread.start()\n",
    "\n",
    "                groups = data_frame[selected_protected].dropna().unique()\n",
    "                output_values = data_frame[feature].dropna().unique()\n",
    "                layout = go.Layout(xaxis=dict(type='category'))\n",
    "                fig_hist_count = go.FigureWidget(layout=layout)  \n",
    "                fig_hist_percent = go.FigureWidget(layout=layout)\n",
    "                with fig_hist_count.batch_update():\n",
    "                    for group in groups:\n",
    "                        temp = data_frame[[selected_protected, feature]].fillna(\"@Unknown\")\n",
    "                        temp = temp[temp[selected_protected]==group]\n",
    "                        if feature == label_y:\n",
    "                            if high_range_pos == True:\n",
    "                                temp.loc[(temp[feature] == 1)] = \"1(Positive impact)\"\n",
    "                                temp.loc[(temp[feature] == 0)] = \"0(Negative impact)\"\n",
    "                                \n",
    "                            elif high_range_pos == False:\n",
    "                                temp.loc[(temp[feature] == 0)] = \"0(Positive impact)\"\n",
    "                                temp.loc[(temp[feature] == 1)] = \"1(Negative impact)\"\n",
    "\n",
    "                        fig_hist_count.add_trace(go.Histogram(\n",
    "                                                    x=temp[feature],\n",
    "                                                    name = selected_protected +\":\"+group,\n",
    "                                                    histfunc=\"count\",\n",
    "                                                    opacity=0.75))\n",
    "        \n",
    "                        fig_hist_percent.add_trace(go.Histogram(\n",
    "                                                    x=temp[feature],\n",
    "                                                    name = selected_protected +\":\"+group,\n",
    "                                                    histnorm = 'percent',\n",
    "                                                    opacity=0.75))\n",
    "                        \n",
    "                    fig_hist_count.update_layout(\n",
    "                                        title_text='Count across groups', # title of plot\n",
    "                                        xaxis_title_text=feature, # xaxis label\n",
    "                                        yaxis_title_text='Count', # yaxis label\n",
    "                                        bargap = 0.2, # gap between bars of adjacent location coordinates\n",
    "                                        bargroupgap = 0.1, # gap between bars of the same location coordinates\n",
    "                                        legend_title = selected_protected,\n",
    "                                        autosize = False\n",
    "                                        )\n",
    "                    fig_hist_percent.update_layout(\n",
    "                                        title_text='Percentage across groups', # title of plot\n",
    "                                        xaxis_title_text = selected_protected, # xaxis label\n",
    "                                        yaxis_title_text='Percent', # yaxis label\n",
    "                                        bargap=0.2, # gap between bars of adjacent location coordinates\n",
    "                                        bargroupgap=0.1, # gap between bars of the same location coordinates\n",
    "                                        legend_title = selected_protected,\n",
    "                                        autosize=False\n",
    "                                        )\n",
    "                \n",
    "                \n",
    "                ####get information about each group, such as the count, num unique values.\n",
    "                describe_tab = widgets.Tab()\n",
    "                widget_html_arr = []\n",
    "                tab_titles = []\n",
    "                for group in groups:\n",
    "                    filtered = data_frame[data_frame[selected_protected]==group]\n",
    "                    html_summary = self.detect_outlier_and_describe(filtered[feature], \n",
    "                                                                    3, \n",
    "                                                                    data_type = \"categoric\")[0]\n",
    "\n",
    "                    widget_html_arr.append(widgets.HTML(html_summary))\n",
    "                    tab_titles.append(str(group))\n",
    "                describe_tab.children = widget_html_arr\n",
    "                for x in range(len(tab_titles)):\n",
    "                    describe_tab.set_title(x, tab_titles[x])\n",
    "                histOut = widgets.Output(layout={})\n",
    "                with histOut:\n",
    "                    hist_tab = widgets.Tab()\n",
    "                    hist_tab.children = [fig_hist_count,fig_hist_percent]\n",
    "                    hist_tab.set_title(0, \"Count\")\n",
    "                    hist_tab.set_title(1, \"Percentage\")\n",
    "                    display(hist_tab)\n",
    "                    display (\"add the ratio view when Y is analysed\")    \n",
    "                describeOut = widgets.Output(layout={})\n",
    "                with describeOut:\n",
    "                    display(describe_tab)\n",
    "                \n",
    "                sigOut = widgets.Output(layout={})\n",
    "                with sigOut:\n",
    "                    #reference_group for t_test is the actual value in the dataframe (not the description)\n",
    "                    reference_group = reference_groups_dict[selected_protected]\n",
    "                    #Now if there is a description we should convert to the description\n",
    "                    try:\n",
    "                        reference_group_to_use = group_descriptions_dict [selected_protected][reference_group]\n",
    "                    except:\n",
    "                        reference_group_to_use = reference_group \n",
    "                        \n",
    "                    self.get_chi_square_test_info(data_frame[[feature]+[selected_protected]], \n",
    "                                                   feature, \n",
    "                                                   selected_protected, \n",
    "                                                   reference_group_to_use) \n",
    " \n",
    "                    \n",
    "                correlationOut = widgets.Output(layout={})\n",
    "                with correlationOut:\n",
    "                    self.feature_analysis_plot_correlation(data_frame[[feature]+[selected_protected]+[label_y]],\n",
    "                                                           label_y,feature,\n",
    "                                                           selected_protected)\n",
    "                    \n",
    "                \n",
    "                accordion = widgets.Accordion(children=[histOut,\n",
    "                                                        describeOut,\n",
    "                                                        sigOut,\n",
    "                                                        correlationOut,\n",
    "                                                        ])\n",
    "                accordion.set_title(0, 'Count of ' + feature + ' grouped by '+ selected_protected)\n",
    "                accordion.set_title(1, 'Describe ' + feature + ' grouped by '+ selected_protected)\n",
    "                accordion.set_title(2, 'Pearson’s chi-squared significance test  ' + feature + ' based on ' + selected_protected)\n",
    "                accordion.set_title(3, 'Correlation between ' + feature + \", \" + label_y + ' and '+ selected_protected)\n",
    "                accordion.selected_index=0 \n",
    "                display(accordion)\n",
    "                #end the progress bar thread\n",
    "                finished = True\n",
    "\n",
    "        if feature == label_y:\n",
    "            self.display_html(\"Analysis of the distribution of the target (\"+ feature + \") across groups.\", \"black\", \"h4\")\n",
    "        else:\n",
    "            self.display_html(\"Analysis of input feature: \"+ feature + \" across groups.\", \"black\", \"h4\")\n",
    "            \n",
    "        \n",
    "        interact(show_analysis, \n",
    "                 selected_protected = widgets.Dropdown(description = \"Protected Feature\",\n",
    "                                            options = [\"--select--\"] + protected_attributes_list,\n",
    "                                            layout = local_layout,\n",
    "                                            style = local_style),\n",
    "                )\n",
    "\n",
    "    \n",
    "    \n",
    "    ################################################################################################\n",
    "    # Correlation plot for protected group and all values\n",
    "    # \n",
    "    ################################################################################################\n",
    "    def plot_correlation_per_group(self, data_frame, protected_feature):\n",
    "        widget_dict = {}\n",
    "        plt.figure(figsize=(8, 8)) \n",
    "        for group in data_frame[protected_feature].dropna().unique():\n",
    "            print(group)\n",
    "            temp_df = data_frame[data_frame[protected_feature]== group]\n",
    "            temp_df.drop(protected_feature, axis=1, inplace = True )\n",
    "            corr = self.phi_k_correlation(temp_df)\n",
    "            corr.reset_index(drop=True, inplace=True)\n",
    "            corr[\"index\"] = pd.Series(list(corr.columns))\n",
    "            corr = corr.set_index(\"index\")\n",
    "\n",
    "            heatmap = go.FigureWidget(go.Heatmap(z=corr,\n",
    "                         zmin=0, \n",
    "                         zmax=1,\n",
    "                         x=corr.columns,\n",
    "                         y=corr.columns,\n",
    "                        xgap=1, ygap=1,\n",
    "                        colorscale= px.colors.sequential.Blues,\n",
    "                        colorbar_thickness=20,\n",
    "                        colorbar_ticklen=3))\n",
    "\n",
    "            title = 'Correlation Matrix'               \n",
    "            with heatmap.batch_update():\n",
    "                heatmap.update_layout(go.Layout(title_text=title, title_x=0.5, \n",
    "                                        width=300, height=300,\n",
    "                                        xaxis_showgrid=False,\n",
    "                                        yaxis_showgrid=False,\n",
    "                                        yaxis_autorange='reversed'\n",
    "                                        ))\n",
    "            widget_dict[group] = heatmap\n",
    "        return widget_dict\n",
    "        box = widgets.HBox(widget_dict.values)\n",
    "        display(box )\n",
    "       \n",
    "        \n",
    "    #################################################################################################\n",
    "    # Correlation plot for feature or label vs protected feature\n",
    "    # \n",
    "    ################################################################################################\n",
    "    def feature_analysis_plot_correlation(self, data_frame, label_y, feature, protected_feature):\n",
    "        #remove any duplicate column that might occur when feature is the label\n",
    "        data_frame = data_frame.loc[:,~data_frame.columns.duplicated()]\n",
    "        html = widgets.HTML(\"\"\"<b>Phik (φk)</b><br>\n",
    "                        Phik (φk) is a new and practical correlation coefficient that\n",
    "                        works consistently between categorical, ordinal and interval\n",
    "                        variables, captures non-linear dependency and reverts to \n",
    "                        the Pearson correlation coefficient in case of a bivariate \n",
    "                        normal input distribution. There is extensive documentation\n",
    "                        available here https://phik.readthedocs.io/en/latest/index.html\"\"\")\n",
    "\n",
    "        display(html)\n",
    "       \n",
    "        plt.figure(figsize=(6, 6)) \n",
    "        \n",
    "            \n",
    "        if label_y != feature:\n",
    "            corr = self.phi_k_correlation(data_frame[[feature]+[protected_feature]+[label_y]])\n",
    "            res1 = corr.loc[ feature , : ][protected_feature]\n",
    "            res2 = corr.loc[ feature , : ][label_y]\n",
    "            text = \"Correlation value for \" + feature + \" and \" + protected_feature + \" is \" + str (res1)\n",
    "            text = text + \"<br>Correlation value for \" + feature + \" and \" + label_y + \" is \" + str (res2)\n",
    "\n",
    "        elif label_y == feature:\n",
    "            corr = self.phi_k_correlation(data_frame[[label_y]+[protected_feature]])\n",
    "            res1 = corr.loc[ feature , : ][protected_feature]\n",
    "            text = \"Correlation value for \" + feature + \" and \" + protected_feature + \" is \" + str (res1)\n",
    "\n",
    "        corr.reset_index(drop=True, inplace=True)\n",
    "        corr[\"index\"] = pd.Series(list(corr.columns))\n",
    "        corr = corr.set_index(\"index\")\n",
    "\n",
    "        heatmap = go.FigureWidget(go.Heatmap(z=corr, \n",
    "                         x=corr.columns,\n",
    "                         y=corr.columns,\n",
    "                        xgap=1, ygap=1,\n",
    "                        colorscale= px.colors.sequential.Blues,\n",
    "                        colorbar_thickness=20,\n",
    "                        colorbar_ticklen=3))\n",
    "\n",
    "        title = 'Correlation Matrix'               \n",
    "        with heatmap.batch_update():\n",
    "            heatmap.update_layout(go.Layout(title_text=title, title_x=0.5, \n",
    "                                        width=300, height=300,\n",
    "                                        xaxis_showgrid=False,\n",
    "                                        yaxis_showgrid=False,\n",
    "                                        yaxis_autorange='reversed'\n",
    "                                        ))\n",
    "        display(heatmap)\n",
    "        display (HTML(text))\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #################################################################################################\n",
    "    #  VIEW STATISTICS AROUND. THE PROTECTED FEATURES/ATTRIBUTES\n",
    "    # \n",
    "    #################################################################################################\n",
    "            \n",
    "    def view_protected(self, protected_attributes_list,\n",
    "                             group_descriptions_dict,\n",
    "                             reference_groups_dict,\n",
    "                             encoding_dict,\n",
    "                             y_value, data_frame, \n",
    "                             _w=600, _h=600, \n",
    "                             y_high_positive = True,\n",
    "                             persist_impact_col = False,\n",
    "                             output_type_binary = False,\n",
    "                             show_outcome_info = True):\n",
    "        protected = []\n",
    "        protectedCount = []\n",
    "        protectedPercentage = []\n",
    "        HIGH_RANGE_POSITIVE = y_high_positive\n",
    "        \n",
    "        out1 = widgets.Output(layout={})\n",
    "        out2 = widgets.Output(layout={})\n",
    "        out3 = widgets.Output(layout={})\n",
    "        out4 = widgets.Output(layout={})\n",
    "        out5 = widgets.Output(layout={})\n",
    "        \n",
    "        if show_outcome_info == True:\n",
    "            tab_contents = [out1, out2, out3, out4]\n",
    "        else:\n",
    "            tab_contents = [out1, out2, out3]\n",
    "        \n",
    "        children = tab_contents\n",
    "        tab = widgets.Tab(style={'description_layout':'auto', 'title_layout':'auto'})\n",
    "        tab.children = children\n",
    "        \n",
    "        tab.set_title(0, \"Group Representation in data\")\n",
    "        tab.set_title(1, \"Outcome distribution\")\n",
    "        tab.set_title(2, \"Feature distribution\")\n",
    "        tab.set_title(3, \"Group Positive outcome representation\")\n",
    "        \n",
    "        local_layout = {'width': 'auto', 'visibility':'visible'}\n",
    "        local_layout_hidden  = {'width': 'auto', 'visibility':'hidden'}\n",
    "        local_style = {'description_width':'initial'}\n",
    "        display(out5)#Show progress of other tab content loading\n",
    "        display(tab)\n",
    "\n",
    "        try:\n",
    "            colType = data_frame[y_value].dtype\n",
    "            if (colType != str and colType != object):\n",
    "                ####### view distribution of groups in the data\n",
    "                \n",
    "                #with out1\n",
    "                self.display_group_representation(data_frame, protected_attributes_list, out1, _w=600, _h=600)\n",
    "                    \n",
    "                \n",
    "                ############## view distribution of results across groups\n",
    "                with out2:\n",
    "                    clear_output(wait = True)\n",
    "                    self.feature_analysis_across_groups(data_frame, \n",
    "                                                       Y_value, \n",
    "                                                       protected_attributes_list,\n",
    "                                                       Y_value,\n",
    "                                                       group_descriptions_dict,\n",
    "                                                       encoding_dict,\n",
    "                                                       reference_groups_dict,\n",
    "                                                       _w=600, _h=600,\n",
    "                                                       high_range_pos = y_high_positiv,\n",
    "                                                       output_type_binary = output_type_binary)\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                \n",
    "                ############## view distribution of results across groups\n",
    "                with out5:#plot the representation of data in the dataframe per protected group\n",
    "                    clear_output(wait = True)\n",
    "                    self.display_html(\"loading outcome representation per group...\", self.text_color, \"p\")      \n",
    "                ############## view distribution of positive outcome across groups\n",
    "                \n",
    "                with out4:\n",
    "                    clear_output(wait = True)\n",
    "                    if HIGH_RANGE_POSITIVE == True:\n",
    "                        impactTxt = \"<b>Positive</b>\"\n",
    "                    if HIGH_RANGE_POSITIVE == False:\n",
    "                        impactTxt = \"<b>Negative</b>\"\n",
    "                    x = \"The Impact of a high output(ranking) on an individual or group is <b>\" + impactTxt + \"</b>\"\n",
    "                    self.display_html(str(x), self.text_color, \"p\")\n",
    "                    self.display_html(\"Select the decision boundary between a positive and negative outcome for the purpose of the report.\", \"black\", \"h4\")\n",
    "\n",
    "                    def show_outcome(choose, percentile_slider, top_x_slider): #local method within view_protected() funct\n",
    "                        #plot the representation of data in the dataframe per protected group\n",
    "                        self._percent_slider.layout = local_layout_hidden\n",
    "                        self._top_x_slider.layout = local_layout_hidden\n",
    "                        with out5:\n",
    "                            clear_output(wait = True)\n",
    "                            self.display_html(\"loading outcomes across groups...\", self.text_color, \"p\")\n",
    "                        if choose == \"Mean\":\n",
    "                            self._percent_slider.layout = local_layout_hidden\n",
    "                            self._top_x_slider.layout = local_layout_hidden\n",
    "                             #plot the distribution of above and below average score(y-value) per protected group\n",
    "                            self.plot_outcome_representation(protected_attributes_list,\n",
    "                                                             y_value, data_frame,\n",
    "                                                             w=_w, h=_h,\n",
    "                                                             y_high_positive = HIGH_RANGE_POSITIVE,\n",
    "                                                             percentile = None,\n",
    "                                                             top_x = None,\n",
    "                                                             persist_impact_col = persist_impact_col)\n",
    "                                 \n",
    "                        if choose == \"Percentile\":\n",
    "                            self._percent_slider.layout = local_layout\n",
    "                            self._top_x_slider.layout = local_layout_hidden\n",
    "                        #plot the distribution of above and below average score(y-value) per protected group\n",
    "                            self.plot_outcome_representation(protected_attributes_list,\n",
    "                                                             y_value, data_frame,\n",
    "                                                             w=_w, h=_h,\n",
    "                                                             y_high_positive = HIGH_RANGE_POSITIVE,\n",
    "                                                             percentile = percentile_slider,\n",
    "                                                             top_x = None,\n",
    "                                                             persist_impact_col = persist_impact_col)\n",
    "                        if choose == \"Top-n\":\n",
    "                            self._percent_slider.layout = local_layout_hidden\n",
    "                            self._top_x_slider.layout = local_layout\n",
    "                        #plot the distribution of above and below average score(y-value) per protected group\n",
    "                            self.plot_outcome_representation(protected_attributes_list,\n",
    "                                                             y_value, data_frame,\n",
    "                                                             w=_w, h=_h,\n",
    "                                                             y_high_positive = HIGH_RANGE_POSITIVE,\n",
    "                                                             percentile = None,\n",
    "                                                             top_x = top_x_slider,\n",
    "                                                            persist_impact_col = persist_impact_col)\n",
    "\n",
    "                    # see https://pandas.pydata.org/pandas-docs/stable/user_guide/style.html\n",
    "                        with out5:\n",
    "                            clear_output(wait = True)\n",
    "                            self.display_html(\"Finished loading!\", self.text_color, \"p\")\n",
    "                    \n",
    "                    \n",
    "                    if output_type_binary == True:\n",
    "                        _choose = widgets.Dropdown(\n",
    "                                description = \"Positive v's Negative determined by\", \n",
    "                                options = [\"Mean\"],\n",
    "                                layout = local_layout,\n",
    "                                style = local_style)\n",
    "                    else:\n",
    "                        _choose = widgets.Dropdown(\n",
    "                                description = \"Positive v's Negative determined by\", \n",
    "                                options = [\"Mean\",\"Top-n\",\"Percentile\"],\n",
    "                                layout = local_layout,\n",
    "                                style = local_style)\n",
    "                    \n",
    "                    self._percent_slider = widgets.IntSlider(\n",
    "                                description = \"Select Percentile\", \n",
    "                                min=0, max=100,\n",
    "                                step=1, value=80, \n",
    "                                continuous_update=False,\n",
    "                                layout = local_layout_hidden,\n",
    "                                style = local_style)\n",
    "                    \n",
    "                    self._top_x_slider = widgets.IntSlider(\n",
    "                                description = \"Select n for Top_n\", \n",
    "                                min=10, max=1000,\n",
    "                                step=10, value=100, \n",
    "                                continuous_update=False,\n",
    "                                layout = local_layout_hidden,\n",
    "                                style = local_style) \n",
    "                    \n",
    "                    if show_outcome_info == True:\n",
    "                        interact(show_outcome, \n",
    "                                 choose = _choose,\n",
    "                                 percentile_slider = self._percent_slider, \n",
    "                                 top_x_slider = self._top_x_slider,);\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    with out5:#plot the representation of data in the dataframe per protected group\n",
    "                        clear_output(wait = True)\n",
    "                        self.display_html(\"Complete!\", self.text_color, \"p\")\n",
    "                \n",
    "                if (colType == str or colType == object):\n",
    "                    self.display_html(\"Output label is not number and should be converted\", self.text_color, \"h4\")\n",
    "        except Exception as e:\n",
    "            self.display_html(\"Something went wrong in view_protected method\", self.text_color, \"h4\")\n",
    "            print (e)\n",
    "        with out5:#plot the representation of data in the dataframe per protected group\n",
    "            clear_output(wait = True)\n",
    "            self.display_html(\"Finished loading\", self.text_color, \"p\")\n",
    "        \n",
    "          \n",
    "    #################################################################################################\n",
    "    #  \n",
    "    # \n",
    "    #################################################################################################         \n",
    "    def create_label (self, row):\n",
    "            \n",
    "            names = list (row.index)\n",
    "            values = list( row.values)\n",
    "            text = \"\"\n",
    "            for i in range (len(names)):\n",
    "                text = text + \":\" + names[i] + \"_\" + str(values[i])\n",
    "            text = text[1:]            \n",
    "            return text       \n",
    "    #################################################################################################\n",
    "    #  \n",
    "    # \n",
    "    #################################################################################################       \n",
    "    def plot_donut(self, attributes_list, data_frame, w=800, h=800, title = \"Result\"):\n",
    "    \n",
    "        num_of_donuts = len(attributes_list)\n",
    "        if num_of_donuts > 6:\n",
    "            num_of_donuts = 6\n",
    "            display (HTML(\"showing only the first 6 attributes\"))\n",
    "        \n",
    "        sequential_color_list = [\n",
    "            px.colors.sequential.Blues,\n",
    "            px.colors.sequential.Greens, \n",
    "            px.colors.sequential.Oranges, \n",
    "            px.colors.sequential.Purples,\n",
    "            px.colors.sequential.Reds,\n",
    "            px.colors.sequential.Greys,\n",
    "            px.colors.sequential.algae,\n",
    "            px.colors.sequential.amp]\n",
    "    \n",
    "        color_pool = cycle(sequential_color_list)\n",
    "    \n",
    "        pie_list = []    \n",
    "        labels_arr = []\n",
    "        values_arr = []\n",
    "        color_arr = []\n",
    "        annotations_arr = []\n",
    "        annotate = dict(text='woops', \n",
    "            x=0.5, y=0.6, \n",
    "            font_size=15, \n",
    "            showarrow=False)\n",
    "                     \n",
    "        def create_label (row):#method local to this method\n",
    "            \n",
    "            names = list (row.index)\n",
    "            values = list( row.values)\n",
    "            text = \"\"\n",
    "            for i in range (len(names)):\n",
    "                text = text + \":\" + names[i] + \"_\" + str(values[i])\n",
    "            text = text[1:]            \n",
    "            return text\n",
    "        \n",
    "        attribute_hierarchy = []\n",
    "        for a, pos in zip (attributes_list, range(len(attributes_list))):\n",
    "            attribute_hierarchy.append(a)\n",
    "            annotate['text'] = a\n",
    "            annotate['y'] = annotate['y']-0.05\n",
    "            annotations_arr.append(annotate.copy())\n",
    "            data_frame[\"count\"] = 0\n",
    "            df = data_frame[attribute_hierarchy+[\"count\"]].fillna(\"@Unknown\").groupby(attribute_hierarchy).count().reset_index().rename(columns={\"count\": \"values\"})\n",
    "            df['labels'] =  df.apply(lambda row : self.create_label(row[attribute_hierarchy]), axis = 1) \n",
    "            df['values'].fillna(0,inplace=True)\n",
    "            c = []\n",
    "            s = []\n",
    "            if pos == 0:\n",
    "                for l in range (len(df['labels'].to_numpy())):\n",
    "                    c.append(next(color_pool)[0])\n",
    "                    if l >= len(sequential_color_list):\n",
    "                        l = l - len(sequential_color_list)\n",
    "                    s.append(l)\n",
    "                df['colors'] = c\n",
    "                df['color_pool_pos'] = s\n",
    "                \n",
    "            else:\n",
    "                temp_list = list(df['values'].to_numpy())#changed from .list\n",
    "                for count, color_index in zip(prev_counts, prev_color_pool) :\n",
    "                    match = 0\n",
    "                    for value, pos in zip (temp_list, range(len(temp_list))):\n",
    "                        s.append(color_index)\n",
    "                        try:\n",
    "                            c.append (sequential_color_list[color_index][pos+1])\n",
    "                        except:\n",
    "                            c.append (sequential_color_list[color_index][2])\n",
    "                        match = match + value\n",
    "                        if match == count:\n",
    "                            del temp_list[0:pos+1]\n",
    "                            break\n",
    "                df['colors'] = c\n",
    "                df['color_pool_pos'] = s\n",
    "            labels_arr.append (df['labels'])\n",
    "            values_arr.append (df['values'])\n",
    "            color_arr.append (df['colors'])\n",
    "        \n",
    "            prev_counts = df['values'].values\n",
    "            prev_color_pool = df['color_pool_pos'].values\n",
    "        hole = 0.8\n",
    "        x1 = 0\n",
    "        x2 =1\n",
    "        y1 = 0\n",
    "        y2 = 1\n",
    "        adjust = round((1.0 - hole)* 0.5,2) \n",
    "        for x in range (num_of_donuts):\n",
    "            pie_list.append(go.Pie(\n",
    "            hole=hole, #Sets the fraction of the radius to cut out of the pie. Use this to make a donut chart\n",
    "            sort=False,\n",
    "            direction='clockwise',\n",
    "            domain={'x': [x1, x2], 'y': [y1, y2]},\n",
    "            values=values_arr[x],\n",
    "            labels=labels_arr[x],\n",
    "            textinfo='label+percent',\n",
    "            textposition='inside',\n",
    "            name=attributes_list[x],\n",
    "            marker={'colors': color_arr[x],'line': {'color': 'black', 'width': 1}}\n",
    "            ))\n",
    "            hole= round(hole - adjust, 2)\n",
    "            x1 = round (x1 + adjust, 2)\n",
    "            x2 = round (x2 - adjust, 2)\n",
    "            y1 = round (y1 + adjust, 2)\n",
    "            y2 = round (y2 - adjust, 2)\n",
    "         \n",
    "        \n",
    "        fig = go.FigureWidget(data=pie_list);#need to reverse the order?\n",
    "        fig.update_layout(autosize=False,\n",
    "                          width=w,\n",
    "                          height=h,\n",
    "                          margin=dict(l=50,r=50,b=100, t=100,pad=4),\n",
    "                          title=str(attribute_hierarchy),\n",
    "                          #Add annotations in the center of the donut pies.\n",
    "                          annotations=annotations_arr,\n",
    "                          legend_orientation=\"h\",\n",
    "                           #paper_bgcolor='rgba(113, 136, 136, 1)', #for transparent set to (0,0,0,0)\n",
    "                          #plot_bgcolor='rgba(113, 136, 136, 1)',\n",
    "                    );\n",
    "\n",
    "        fig.update_traces(textposition='inside');\n",
    "        fig.update(layout_title_text=title,\n",
    "               layout_showlegend=False );\n",
    "        df[\"all\"] = \"all\"\n",
    "        fig_2 = px.treemap(df, \n",
    "                           path=[\"all\"]+attributes_list, \n",
    "                           values='values',  \n",
    "                          )\n",
    "        \n",
    "        fig_2.data[0].textinfo = 'current path+ label+value+percent parent+percent root'\n",
    "         # # # # # Now create one donut per protected attribute for a clearer view if the call specifies this# # # # # # \n",
    "        fig_2.update(layout_title_text=title,\n",
    "               layout_showlegend=True );\n",
    "        fig_wig_2 = go.FigureWidget(fig_2);\n",
    "\n",
    "        #as this can be a pointer to the input, clean it up\n",
    "        data_frame.drop([\"count\"], axis=1, inplace = True)\n",
    "        gc.collect()\n",
    "        return fig, fig_wig_2\n",
    "        \n",
    "    #################################################################################################\n",
    "    # Pearson’s Chi-Squared Test....\n",
    "    # METHOD USED TO Perform Independent chi_square_test. can be used as a test for independance\n",
    "    # between categorical variables\n",
    "    #################################################################################################\n",
    "    #################################################################################################\n",
    "    def get_chi_square_test_info(self, df, feature, protected_feature, ref_group): \n",
    "        '''A categorical variable is a variable that may take on one of a set of labels.\n",
    "           Here we will examine a categorical variable as they pertain to another categorical label, \n",
    "           specifically a protected feature such as Gender(Male, Female), or Race(Black, White)\n",
    "           as it pertains to another variable such as Score, Success etc,\n",
    "            Large values of X^2 indicate that observed and expected frequencies are far apart. \n",
    "            Small values of X^2 indicate that observed are close to expecteds.\n",
    "            X^2 give a measure of the distance between observed and expected frequencies.\n",
    "            expected frequency is that there will be no difference between observed and expected\n",
    "            above what would be expected by chance (no statistically significant difference)'''\n",
    "        try:\n",
    "            groups = df[protected_feature].dropna().unique()\n",
    "            table = pd.crosstab(df[protected_feature], df[feature])\n",
    "            prob = 0.95\n",
    "            \n",
    "\n",
    "            #can be used to create multiple plots, however we only call it with attribute_list of len 1.            \n",
    "            def test_res(group_1, group_2):\n",
    "                filter_table  = table[table.index.isin([group_1,group_2])]\n",
    "                for col in filter_table.columns:\n",
    "                    if filter_table[col].sum() == 0:\n",
    "                        filter_table.drop(col, inplace=True)\n",
    "                chi2_stat, p_value, dof, expected = chi2_contingency(filter_table)\n",
    "                ######\n",
    "                #Interprert the critical value\n",
    "                # critical = chi2.ppf(prob, dof)\n",
    "                #print (\"critical(chi2.ppf(prob, dof)): \", critical)\n",
    "                #if abs(chi2_stat) >= critical:\n",
    "                     #print('Dependent (reject H0)')\n",
    "                #else:\n",
    "                   #print('Independent (fail to reject H0)')\n",
    "                #######\n",
    "\n",
    "                # interpret p-value for consistency with other test\n",
    "                     #alpha = 1.0 - prob\n",
    "                    #print('significance=%.3f, p=%.3f' % (alpha, p_value))\n",
    "\n",
    "                     #if  p_value <= alpha:\n",
    "                     #    print('Dependent (reject H0)')\n",
    "                     #else:\n",
    "                     #    print('Independent (fail to reject H0)')\n",
    "\n",
    "                ####\n",
    "\n",
    "                matrix_twosample = [\n",
    "                                    ['', 'Chi-2 Test Statistic(T-Value)', 'P-value'],\n",
    "                                    ['Sample Data', abs(chi2_stat), p_value]\n",
    "                                    ]\n",
    "\n",
    "                wig2 = go.FigureWidget(ff.create_table(matrix_twosample, index=True))\n",
    "                display (wig2)\n",
    "                text = \"There is a \"+ str (round ((p_value*100),3)) +  \"% probability that a difference of \" + str(chi2_stat)\n",
    "                text = text + \"\"\" occured by chance. A usual interpretation is that a p-value of less than 0.05 (5% probability)\n",
    "                is deemed to indicate that the difference has not occured by chance (rejecting H0)\"\"\"\n",
    "\n",
    "                self.display_html(text, self.text_color, \"p\")\n",
    "\n",
    "            self.display_html(\"Chi-Squared T-Test \", \"black\", \"h3\")\n",
    "            text = ''' <b>Significant variance:</b> The statistic test will tell us if there is a significant difference in the \n",
    "                        distribution of categories, if this difference is due to chance, or how likely it is that it is not due to chance but\n",
    "                        rather to an unobserved factor. <br>\n",
    "\n",
    "\n",
    "                        <b>T-Value:</b>This value represents the distance between the observed distribution\n",
    "                        and the expected distribution in a fair world. \n",
    "                        The larger the value of T, the greater the evidence against the difference\n",
    "                        occuring by chance in a fair world. <br>'''\n",
    "            self.display_html(text, \"black\", \"p\")\n",
    "\n",
    "            interact(test_res, \n",
    "                        group_1 = widgets.Dropdown(description = \"Reference Group\", \n",
    "                                                   options =  groups, \n",
    "                                                   value = ref_group,\n",
    "                                                   style = {'description_width': 'initial'}),\n",
    "                        group_2 = widgets.Dropdown(description = \"Focal Group\", \n",
    "                                                   options =  groups)\n",
    "                );\n",
    "\n",
    "        except Exception as e:\n",
    "            self.display_html(\"Something went wrong generating the distribution, change the distribution type and ensure group is represented sufficiently to generate dist\", \n",
    "                              self.text_color, \"h4\")\n",
    "            print (e)  \n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "    #################################################################################################\n",
    "    #  \n",
    "    # METHOD USED TO Perform Independent t-Test. A t-test is a type of inferential statistic which is used to\n",
    "    # determine if there is a significant difference between the means of two groups which may be \n",
    "    # related in certain features\n",
    "    #################################################################################################\n",
    "    def get_t_test_info(self, dist_output_per_group, groups, ref_group):\n",
    "        try:\n",
    "            #can be used to create multiple plots, however we only call it with attribute_list of len 1.            \n",
    "            def test_res(group_1, group_2):\n",
    "                group_index_1 = list(groups).index(group_1)\n",
    "                group_index_2 = list(groups).index(group_2)\n",
    "\n",
    "                twosample_results = stats.ttest_ind(dist_output_per_group[group_index_1],  dist_output_per_group[group_index_2])\n",
    "                matrix_twosample = [\n",
    "                                    ['', 'Test Statistic(T-Value)', 'P-value'],\n",
    "                                    ['Sample Data', twosample_results[0], twosample_results[1]]\n",
    "                                    ]\n",
    "\n",
    "                wig2 = go.FigureWidget(ff.create_table(matrix_twosample, index=True))\n",
    "                display (wig2)\n",
    "                text = \"There is a \"+ str (round ((twosample_results[1]*100),3)) +  \"% probability that a difference of \" +str(twosample_results[0]) +\" occured by chance.\"\n",
    "                self.display_html(text, self.text_color, \"p\")\n",
    "           \n",
    "            self.display_html(\"Two-Tailed T-Test \", \"black\", \"h3\")\n",
    "            text = ''' <b>Significant variance:</b> The statistic test will tell us if there is a significant variance in the distribution \n",
    "                        and if this variance is due to chance, or how likely it is that it is not due to chance but\n",
    "                        rather to an unobserved factor. <br>\n",
    "                        \n",
    "                        \n",
    "                        <b>T-Value:</b>The greater the magnitude of T, the greater the evidence against the variance\n",
    "                        occuring by chance. <br>'''\n",
    "            self.display_html(text, \"black\", \"p\")    \n",
    "            interact(test_res, \n",
    "                        group_1 = widgets.Dropdown(description = \"Reference Group\", \n",
    "                                                   options =  groups, \n",
    "                                                   value = ref_group,\n",
    "                                                   style = {'description_width': 'initial'}),\n",
    "                        group_2 = widgets.Dropdown(description = \"Focal Group\", \n",
    "                                                   options =  groups)\n",
    "                );\n",
    "                 \n",
    "                            \n",
    "\n",
    "        except Exception as e:\n",
    "            self.display_html(\"Something went wrong generating the distribution, change the distribution type and ensure group is represented sufficiently to generate dist\", \n",
    "                              self.text_color, \"h4\")\n",
    "            print (e)\n",
    "\n",
    "           \n",
    "        \n",
    "    #################################################################################################\n",
    "    #  \n",
    "    # METHOD USED TO PLOT THE DISTRIBUTION OF THE OUTCOME ACROSS GROUPS\n",
    "    #################################################################################################\n",
    "    \n",
    "    def plot_distribution(self, attribute, y, data_frame, w=800, h=800, y_high_positive = True, curve_type = \"kde\"):\n",
    "        try:\n",
    "            #can be used to creatr multiple plots, however we only call it with attribute_list of len 1.\n",
    "            dist_output_per_group = []\n",
    "            group_labels = []\n",
    "            groups = data_frame[attribute].dropna().unique()\n",
    "            #For every group in the protected feature\n",
    "            \n",
    "            \n",
    "            for group in range(len(groups)):\n",
    "                group_df = data_frame[data_frame[attribute] == groups[group]]\n",
    "                dist_output_per_group.append(group_df[y])\n",
    "                group_labels.append(attribute + \"-\" + str(groups[group]))\n",
    "                # Add histogram data\n",
    "                # Group data together\n",
    "                \n",
    "            #Add the dist of all combined groups\n",
    "            dist_output_per_group.append(data_frame[y])\n",
    "            group_labels.append(\"All\")\n",
    "            \n",
    "            # Create distplot with custom bin_size\n",
    "            \n",
    "            # Add title\n",
    "            \n",
    "            wig = go.Figure(ff.create_distplot(dist_output_per_group, \n",
    "                                           group_labels, \n",
    "                                           curve_type = curve_type, \n",
    "                                           show_hist=False) )#, bin_size=[.1, .25, .5, 1])\n",
    "    \n",
    "            with wig.batch_update():\n",
    "                wig.update_layout(autosize=False,\n",
    "                              width=900,\n",
    "                              height=500,\n",
    "                              #margin=dict(l=50,r=50,b=100, t=100,pad=4),\n",
    "                              #paper_bgcolor=\"LightSteelBlue\",\n",
    "                              title=y +' distribution across ' + attribute,\n",
    "                              xaxis=dict(range=[data_frame[y].min(), data_frame[y].max()])\n",
    "                            )\n",
    "            \n",
    "            img_bytes = wig.to_image(format=\"png\", engine=\"kaleido\")\n",
    "            wig.write_html(\"output_dist.html\")\n",
    "\n",
    "            image_wig = widgets.Image(value=img_bytes,\n",
    "                                   format='png',\n",
    "                                   width=800,\n",
    "                                   height=500)\n",
    "            \n",
    "\n",
    "            del wig\n",
    "            return image_wig, dist_output_per_group, groups\n",
    "\n",
    "        except Exception as e:\n",
    "            self.display_html(\"Something went wrong generating the distribution, change the distribution type and ensure group is represented sufficiently to generate dist\", \n",
    "                              self.text_color, \"h4\")\n",
    "            print (e)\n",
    "\n",
    "        \n",
    "    \n",
    "    #################################################################################################\n",
    "    #  \n",
    "    # \n",
    "    #################################################################################################\n",
    "    def plot_outcome_representation(self, attributes_list, \n",
    "                                    y_value, data_frame, \n",
    "                                    w=800, h=800, \n",
    "                                    y_high_positive = True,\n",
    "                                    percentile = None,\n",
    "                                    top_x = None,\n",
    "                                    persist_impact_col = False):\n",
    "        \n",
    "        \n",
    "        num_of_attributes = len(attributes_list)\n",
    "        if num_of_attributes > 6:\n",
    "            num_of_attributes = 6\n",
    "            display (HTML(\"showing only the first 6 attributes\"))\n",
    "        \n",
    "        #create a new column that categorises positive outcome by default, as above average score and negative \n",
    "        #outcome as below average score\n",
    "        y = y_value #Sort the naming out here later\n",
    "        text = \"\"\n",
    "        HIGH_RANGE_POSITIVE = y_high_positive\n",
    "        yMin = round(data_frame[y_value].min(), 10)\n",
    "        yDivPoint = data_frame[y_value].mean()\n",
    "        yMax = data_frame[y_value].max()   \n",
    "        \n",
    "        outcome = ['', '']      \n",
    "        if HIGH_RANGE_POSITIVE == True:\n",
    "            # min to mean is neg, mean to max is pos\n",
    "            outcome = [\"Neg\", \"Pos\"]\n",
    "            #Rather than having defined bins of [yMin, yMean, yMax] base the display on precentiles.\n",
    "            if not percentile == None:\n",
    "                yDivPoint = data_frame[data_frame[y_value] >= np.percentile(data_frame[y_value],percentile)].min()[y_value]\n",
    "            if not top_x == None:\n",
    "                #Ascending means smallest to largest,\n",
    "                _text = \"Top n = \"+ str (data_frame.sort_values(y_value,ascending = True).head(top_x).shape[0])\n",
    "                self.display_html(_text, self.text_color, \"p\")\n",
    "                yDivPoint = data_frame.sort_values(y_value,ascending = False).head(top_x).min()[y_value]\n",
    "                    \n",
    "        if HIGH_RANGE_POSITIVE == False:\n",
    "            outcome = [\"Pos\", \"Neg\"]\n",
    "            # min to mean is pos, mean to max is neg\n",
    "            #Rather than having defined bins of [yMin, yMean, yMax] base the display on precentiles.\n",
    "            if not percentile == None:\n",
    "                _text = \"bottom percentile = \" + str(percentile)\n",
    "                self.display_html(_text, self.text_color, \"p\")\n",
    "                yDivPoint= data_frame[data_frame[y_value] <= np.percentile(data_frame[y_value],percentile)].max()[y_value]\n",
    "            if not top_x == None:\n",
    "                #Ascending means smallest to largest,\n",
    "                _text = \"Top x =\" + str(data_frame.sort_values(y_value,ascending = True).head(top_x).shape[0])\n",
    "                self.display_html(_text, self.text_color, \"p\")\n",
    "                yDivPoint = data_frame.sort_values(y_value,ascending = True).head(top_x).max()[y_value]\n",
    "        \n",
    "        yMin = round(yMin, 3)\n",
    "        yDivPoint = round(yDivPoint, 3)\n",
    "        yMax = round(yMax, 3) \n",
    "        \n",
    "        def get_next_prev_fraction(num):#local method\n",
    "            n = num\n",
    "            if isinstance(n, float):\n",
    "                s = str(n)\n",
    "                _len = s[::-1].find('.')\n",
    "                add = \"0.\"\n",
    "                if (_len > 0):\n",
    "                    for x in range(_len-1):\n",
    "                        add = add + \"0\"\n",
    "                    add = add +\"1\"\n",
    "                _next = round (n + float(add), _len)\n",
    "                _prev = round (n - float(add), _len)\n",
    "            return _next, _prev\n",
    "\n",
    "        _, yDivPoint = get_next_prev_fraction(yDivPoint)\n",
    "        bins = [yMin-1, yDivPoint, yMax+1]#adding + and -1 to account for any decimal issues\n",
    "                          \n",
    "        impact_col_name = \"impact\"    \n",
    "\n",
    "        data_frame[impact_col_name] = pd.cut(data_frame[y_value], bins, labels=outcome)\n",
    "              \n",
    "       \n",
    "        text = text + \"A high output is defined as a relevance (score) between \" + str(yDivPoint) + \" and \" + str(yMax)+\"<br>\"\n",
    "        text = text + \"A low output is defined as a relevance (score) between \" + str(yMin) + \" and \" + str(yDivPoint)\n",
    "        self.display_html(text, self.text_color, \"p\")\n",
    "\n",
    "        sequential_color_list = [\n",
    "            px.colors.sequential.Greens, \n",
    "            px.colors.sequential.Greys]\n",
    "\n",
    "        \n",
    "        fig2 = self.plot_donut( list((attributes_list)), \n",
    "                                 data_frame[(data_frame[impact_col_name]==\"Pos\")] ,\n",
    "                                 w=500, h=500, \n",
    "                                 title = \"Positive impact across groups\") [0]\n",
    "        \n",
    "        fig3 = self.plot_donut( list((attributes_list)), \n",
    "                                 data_frame[(data_frame[impact_col_name]==\"Neg\")] ,\n",
    "                                 w=500, h=500, \n",
    "                                 title = \"Negative impact across groups\") [0]\n",
    "        \n",
    "        df_ratios = data_frame[attributes_list+[impact_col_name]+[y_value]].groupby(attributes_list+[impact_col_name]).count().reset_index().rename(columns={y_value: \"values\"})     \n",
    "        \n",
    "        _total =  df_ratios['values'].sum()\n",
    "        _total_pos =  df_ratios[(df_ratios[impact_col_name]==\"Pos\")]['values'].sum()\n",
    "        _total_neg =  df_ratios[(df_ratios[impact_col_name]==\"Neg\")]['values'].sum()\n",
    " \n",
    "        _text = \"Total Number of samples: \" + str( _total)\n",
    "        _text = _text + \" (Positive: \" + str(_total_pos) + \", Negative: \"+ str(_total_neg) + \")\"\n",
    "        num_unique_out = len(data_frame[y_value].dropna().unique())\n",
    "        _text = _text +  \"<br>\" +  \"*Note the number may vary from the top-n specified as the number of unique outputs is \" + str(num_unique_out)\n",
    "        self.display_html(_text, self.text_color, \"p\")\n",
    "        one, isto = self.ratio(_total_pos, _total_neg)\n",
    "        df_ratios['labels'] =  df_ratios.apply(lambda row : self.create_label(row[attributes_list]), axis = 1) \n",
    "        df_ratios['labels'].fillna(0,inplace=True)\n",
    "        attr_list = []\n",
    "        attr_list.append(\"All\")\n",
    "        isto_list = []\n",
    "        isto_list.append(isto)\n",
    "        pcnt_list = []\n",
    "        pcnt_list.append((_total_pos/(_total_pos+_total_neg))*100)\n",
    "        for label in df_ratios['labels'].dropna().unique():\n",
    "            pos = df_ratios[(df_ratios['labels']==label) & (df_ratios[impact_col_name]==\"Pos\")]['values']\n",
    "            neg = df_ratios[(df_ratios['labels']==label) & (df_ratios[impact_col_name]==\"Neg\")]['values']\n",
    "            one, isto = self.ratio(pos.values[0], neg.values[0])\n",
    "            attr_list.append(label)\n",
    "            isto_list.append(isto)\n",
    "            pcnt = (pos.values[0]/(pos.values[0]+neg.values[0]))*100\n",
    "            if math.isnan(pcnt):\n",
    "                pcnt_list.append(0)\n",
    "            else:\n",
    "                pcnt_list.append(pcnt)\n",
    "        \n",
    "        fig4 = go.Figure()\n",
    "        fig4.add_trace(go.Bar(\n",
    "                            x=attr_list,\n",
    "                            y=isto_list,\n",
    "                            marker_color='indianred'\n",
    "                        ))\n",
    "\n",
    "\n",
    "            # Here we modify the tickangle of the xaxis, resulting in rotated labels.\n",
    "        fig4.update_layout(xaxis_tickangle=-45, \n",
    "                           title = \"Ratio of Positive to Negative (for each 1 positive effect)\",\n",
    "                          autosize=False,\n",
    "                          width=900,\n",
    "                          height=400,)\n",
    "        \n",
    "        fw4 = go.FigureWidget(fig4)\n",
    "        fig5 = go.Figure()\n",
    "        fig5.add_trace(go.Bar(\n",
    "                            x=attr_list,\n",
    "                            y=pcnt_list,\n",
    "                            marker_color='indianred'\n",
    "                        ))\n",
    "\n",
    "\n",
    "            # Here we modify the tickangle of the xaxis, resulting in rotated labels.\n",
    "        fig5.update_layout(xaxis_tickangle=-45, \n",
    "                           title = \"Percentage of positive outcomes per group\",\n",
    "                          autosize=False,\n",
    "                          width=900,\n",
    "                          height=400,)\n",
    "        \n",
    "        fw5 = go.FigureWidget(fig5)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        num_of_attributes = len(attributes_list)        \n",
    "        def powerset(iterable):\n",
    "            \"powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\"\n",
    "            s = list(iterable)\n",
    "            res = chain.from_iterable(combinations(s, r) for r in range(len(s)+1))\n",
    "            list_set = list(res)\n",
    "            final_list = []\n",
    "            for val in list_set:\n",
    "                if len(val) == 2:\n",
    "                    final_list.append(val)\n",
    "            return final_list\n",
    "        fig = go.Figure()\n",
    "        if num_of_attributes > 1:\n",
    "            \n",
    "            comb = powerset(attributes_list)\n",
    "            #for each combination of 2 protected attributes \n",
    "            for a, pos in zip (comb, range(len(comb))):\n",
    "                df = data_frame[[a[0]]+[a[1]]+[impact_col_name]+[y_value]].groupby([a[0]]+[a[1]]+[impact_col_name]).count().reset_index().rename(columns={y_value: \"values\"})\n",
    "                _total =  df['values'].sum()\n",
    "                _total_pos =  df[(df[impact_col_name]==\"Pos\")]['values'].sum()\n",
    "                _total_neg =  df[(df[impact_col_name]==\"Neg\")]['values'].sum()\n",
    "                color_index = 7\n",
    "                color_index_g = 7\n",
    "                for value in df[a[1]].dropna().unique():\n",
    "                    green = px.colors.sequential.Greens[color_index]\n",
    "                    if color_index != 0:\n",
    "                        color_index = color_index - 1\n",
    "                    else:\n",
    "                        color_index = 7\n",
    "                    \n",
    "                    name = a[1]+\"_\"+str(value)\n",
    "                    \n",
    "                    temp = df[(df[a[1]]==value) & (df[impact_col_name]==\"Pos\")]\n",
    "                    _pcnt = list (  round((temp[\"values\"]/_total) * 100 , 2)) \n",
    "                    _pcnt_from_total_pos = list ( round(  (temp[\"values\"]/_total_pos) * 100, 2)) \n",
    "                    \n",
    "                    for x in range (len(_pcnt_from_total_pos)):\n",
    "                        _pcnt_from_total_pos[x] = str(_pcnt_from_total_pos[x]) + \"% of all Positive\"\n",
    "                    fig.add_trace(go.Bar(\n",
    "                            y=df[a[0]].dropna().unique(),\n",
    "                            x=temp[\"values\"],\n",
    "                            name='Positive-' + name,\n",
    "                            text = _pcnt_from_total_pos,\n",
    "                            textposition='auto',\n",
    "                            orientation='h',\n",
    "                            marker=dict(\n",
    "                            color=green,\n",
    "                            line=dict(color='rgba(58, 71, 80, 1.0)', width=2)\n",
    "                            )\n",
    "                        ))\n",
    "                for value in df[a[1]].dropna().unique():\n",
    "                    grey = px.colors.sequential.Oranges[color_index_g]\n",
    "                    if color_index_g != 0:\n",
    "                        color_index_g = color_index_g - 1\n",
    "                    else:\n",
    "                        color_index_g = 7\n",
    "               \n",
    "                    name = a[1]+\"_\"+str(value)\n",
    "                    temp = df[(df[a[1]]==value) & (df[impact_col_name]==\"Neg\")]\n",
    "                    _pcnt = list ( round(  (temp[\"values\"]/_total) * 100 , 2) )\n",
    "                    _pcnt_from_total_neg = list ( round(  (temp[\"values\"]/_total_neg) * 100, 2) )\n",
    "                    for x in range (len(_pcnt_from_total_neg)):\n",
    "                        _pcnt_from_total_neg[x] = str(_pcnt_from_total_neg[x]) + \"% of all Negative\"\n",
    "                    fig.add_trace(go.Bar(\n",
    "                            y=df[a[0]].dropna().unique(),\n",
    "                            x=temp[\"values\"],\n",
    "                            name='Negative_' + name,\n",
    "                            text = _pcnt_from_total_neg,\n",
    "                            textposition='auto',\n",
    "                            orientation='h',\n",
    "                            marker=dict(\n",
    "                            color=grey,\n",
    "                            line=dict(color='rgba(58, 71, 80, 1.0)', width=2)\n",
    "                        )\n",
    "                    ))\n",
    "                        \n",
    "\n",
    "            fig.update_layout(title = \"Impact of results on: \"+ a[0]+ \" and \"+ a[1], \n",
    "                              barmode='stack',\n",
    "                              xaxis_tickangle=-45,\n",
    "                              autosize=False,\n",
    "                              width=900,\n",
    "                              height=h,\n",
    "                              legend_orientation=\"h\",\n",
    "                              margin=dict(l=50,r=50,b=100, t=100,pad=4),\n",
    "                              xaxis=dict(title=a[1]),\n",
    "                              yaxis=dict(title=a[0]), \n",
    "                             )\n",
    "            \n",
    "            fw6 = go.FigureWidget(fig)\n",
    "            del fig\n",
    "         \n",
    "            \n",
    "        else:#only one protected group so just show it   \n",
    "            df = data_frame[attributes_list+[impact_col_name]+[y_value]].groupby(attributes_list+[impact_col_name]).count().reset_index().rename(columns={y_value: \"values\"})\n",
    "            temp = df[(df[impact_col_name]==\"Pos\")]\n",
    "            _total =  df['values'].sum()\n",
    "            _total_pos =  df[(df[impact_col_name]==\"Pos\")]['values'].sum()\n",
    "            _total_neg =  df[(df[impact_col_name]==\"Neg\")]['values'].sum()\n",
    "            fig.add_trace(go.Bar(\n",
    "                            y=df[attributes_list[0]].dropna().unique(),\n",
    "                            x=temp[\"values\"],\n",
    "                            name='Positive',\n",
    "                            text = \"add %\",\n",
    "                            textposition='auto',\n",
    "                            orientation='h',\n",
    "                            marker=dict(\n",
    "                            color=\"green\",\n",
    "                            line=dict(color='rgba(58, 71, 80, 1.0)', width=2)\n",
    "                        )\n",
    "                    ))\n",
    "            \n",
    "            temp = df[(df[impact_col_name]==\"Neg\")]\n",
    "            fig.add_trace(go.Bar(\n",
    "                            y=df[attributes_list[0]].dropna().unique(),\n",
    "                            x=temp[\"values\"],\n",
    "                            name='Negative',\n",
    "                            text = \"add %\",\n",
    "                            textposition='auto',\n",
    "                            orientation='h',\n",
    "                            marker=dict(\n",
    "                            color=\"orange\",\n",
    "                            line=dict(color='rgba(58, 71, 80, 1.0)', width=2)\n",
    "                        )\n",
    "                    ))\n",
    "            \n",
    "            fig.update_layout(title = \"Impact of results on: \"+ str(attributes_list[0]), \n",
    "                              barmode='stack',\n",
    "                              xaxis_tickangle=-45,\n",
    "                              autosize=False,\n",
    "                              width=900,\n",
    "                              height=h,\n",
    "                              legend_orientation=\"h\",\n",
    "                              margin=dict(l=50,r=50,b=100, t=100,pad=4),\n",
    "#                               xaxis=dict(title=a[1]),\n",
    "#                               yaxis=dict(title=a[0]), \n",
    "                              )\n",
    "            fw6 = go.FigureWidget(fig)\n",
    "            del fig\n",
    "        \n",
    "        hbox1 = widgets.HBox([fig2, fig3])\n",
    "        hbox2 = widgets.HBox([fw4])\n",
    "        hbox3 = widgets.HBox([fw5])\n",
    "        hbox4 = widgets.HBox([fw6])\n",
    "        accordion = widgets.Accordion(children=[hbox1, hbox2, hbox3, hbox4 ])\n",
    "        accordion.set_title(0, 'Outcome impact across groups')\n",
    "        accordion.set_title(1, 'Ratio of positive outcomes per group')\n",
    "        accordion.set_title(2, 'Percentage of positive outcomes per group')\n",
    "        accordion.set_title(3, 'Outcomes per group')\n",
    "        display(accordion)\n",
    "            \n",
    "        del fig2\n",
    "        del fig3\n",
    "        del fig4\n",
    "        del fig5\n",
    "        \n",
    "        #as we added a column to this dataframe we will remove it here, as maybe a copy was not sent in\n",
    "        if persist_impact_col == False:\n",
    "            data_frame.drop([impact_col_name], axis=1, inplace = True)\n",
    "        else:\n",
    "            data_frame[impact_col_name].replace(['Pos', 'Neg'], [1, 0], inplace=True)\n",
    "            data_frame[\"Transformed_\"+y_value] = data_frame[impact_col_name]\n",
    "            data_frame.drop([impact_col_name], axis=1, inplace = True)\n",
    "        gc.collect()\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    #################################################################################################\n",
    "    #  \n",
    "    # \n",
    "    ################################################################################################# \n",
    "    def label_encoding(self, attributes_list, data_frame):\n",
    "        # creating initial dataframe\n",
    "        labelencoder = LabelEncoder()\n",
    "        return_dict = {}\n",
    "        for attribute in attributes_list:\n",
    "            categories = data_frame[attribute].dropna().unique()\n",
    "            temp_df = pd.DataFrame(categories, columns=[attribute])\n",
    "            # Assigning numerical values and storing in another column\n",
    "            temp_df[attribute+\"_benc\"] = temp_df[attribute]\n",
    "            temp_df[attribute] = labelencoder.fit_transform(temp_df[attribute])\n",
    "            # Convert this Temp_df into a dictionary\n",
    "            temp_df.set_index(attribute+\"_benc\", inplace=True)\n",
    "            return_dict.update(temp_df.to_dict())\n",
    "            data_frame[attribute+\"_benc\"] = data_frame[attribute]\n",
    "            data_frame[attribute] = labelencoder.fit_transform(data_frame[attribute])\n",
    "        return return_dict\n",
    "    \n",
    "    \n",
    "    #################################################################################################\n",
    "    #  \n",
    "    # \n",
    "    #################################################################################################   \n",
    "    def gcd(self, p, q): \n",
    "        if (q == 0): \n",
    "            return p\n",
    "        else:\n",
    "            return min(q, p)\n",
    "\n",
    "    def ratio(self, a,b):\n",
    "        _gcd = self.gcd(a,b)\n",
    "        one = round(a/_gcd, 2)\n",
    "        isto = round(b/_gcd, 2)\n",
    "        if one != 1:\n",
    "            isto = round (1/one, 2)\n",
    "            one = 1.0\n",
    "        return one, isto\n",
    "\n",
    "    \n",
    "    #################################################################################################\n",
    "    #  VIEW FAIRNESS MATRICS AEQUITAS\n",
    "    # \n",
    "    #################################################################################################\n",
    "    \"\"\"Difference in means: The difference between the probability for a member of group-a be selected and \n",
    "        the probability for a member of group-b to be selected.\n",
    "\n",
    "        Disparate Impact: the Probability of a member of group-a be selected to be selected divided by\n",
    "        the probability of a member of group-b to be selected\n",
    "\n",
    "        False positive rate Ratio of false positive ratio's among protected groups\n",
    "\n",
    "       False negative rate: Ratio of false negative ratio's among protected groups\"\"\"\n",
    "            \n",
    "    def view_aequitas_fairness_metrics(self, \n",
    "                                       y_column_name,\n",
    "                                       protected_attributes_list,\n",
    "                                       X_data_frame, \n",
    "                                       y_target, \n",
    "                                       y_pred,\n",
    "                                       _w=600, _h=600, \n",
    "                                       y_high_positive = True,\n",
    "                                        ):\n",
    "\n",
    "        HIGH_RANGE_POSITIVE = y_high_positive\n",
    "        aeq_Plot = Plot()\n",
    "        aeq_Group = Group()\n",
    "        aeq_Bias = Bias()\n",
    "        aeq_Fairness = Fairness()\n",
    "\n",
    "        out1 = widgets.Output(layout={})\n",
    "        out2 = widgets.Output(layout={})\n",
    "        out3 = widgets.Output(layout={})\n",
    "        out4 = widgets.Output(layout={})\n",
    "        out5 = widgets.Output(layout={})\n",
    "        out6 = widgets.Output(layout={})\n",
    "        tab_contents = [out1, out2, out3, out4, out5, out6]\n",
    "        \n",
    "        children = tab_contents\n",
    "        tab = widgets.Tab(style={'description_layout':'auto', 'title_layout':'auto'})\n",
    "        tab.children = children\n",
    "        \n",
    "        tab.set_title(0, \"Confusion Matrix\")\n",
    "        tab.set_title(1, \"False Positive\")\n",
    "        tab.set_title(2, \"False Negative\")\n",
    "        tab.set_title(3, \"All Metrics\")\n",
    "        tab.set_title(4, \"Disparate Impact\")\n",
    "        tab.set_title(5, \"Fairness\")\n",
    "        \n",
    "        local_layout = {'width': 'auto', 'visibility':'visible'}\n",
    "        local_layout_hidden  = {'width': 'auto', 'visibility':'hidden'}\n",
    "        local_style = {'description_width':'initial'}\n",
    "\n",
    "        _choose_a = widgets.Dropdown(description = \"Select protected feature\", \n",
    "                                     options = protected_attributes_list,\n",
    "                                     layout = local_layout,\n",
    "                                     style = local_style)\n",
    "                \n",
    "        _choose_b = widgets.Dropdown(description = \"Select protected group\", \n",
    "                                             options = X_data_frame[_choose_a.value].dropna().unique(),\n",
    "                                             layout = local_layout,\n",
    "                                             style = local_style)\n",
    "        \n",
    "        _choose_measure = widgets.Dropdown(description = \"Select Metric\", \n",
    "                                             options = {'False Omission Rate' : 'for',\n",
    "                                                        'False Discovery Rate' :'fdr',\n",
    "                                                        'False Positive Rate': 'fpr',\n",
    "                                                        'False Negative Rate': 'fnr',\n",
    "                                                        'Negative Predictive Value': 'npv',\n",
    "                                                        'Precision': 'precision',\n",
    "                                                        'Predicted Positive Ratio_k' :'ppr',\n",
    "                                                        'Predicted Positive Ratio_g': 'pprev',\n",
    "                                                        'Group Prevalence':'prev'},\n",
    "                                             layout = local_layout,\n",
    "                                             value = 'precision',\n",
    "                                             style = local_style)\n",
    "    \n",
    "        \n",
    "        _choose_disparity_measure = widgets.Dropdown(description = \"Select Metric\", \n",
    "                                             options = {'False Positive Rate disparity': 'fpr_disparity',\n",
    "                                                        'False Negative Rate disparity': 'fnr_disparity',\n",
    "                                                        'Predicted Positive Ratio_k' : 'ppr_disparity',\n",
    "                                                        'Predicted Positive Ratio_g disparity' :'pprev_disparity',\n",
    "                                                        'Precision Disparity': 'precision_disparity',\n",
    "                                                        'False Discovery Rate disparity': 'fdr_disparity',\n",
    "                                                        'False Omission Rate disparity': 'for_disparity',\n",
    "                                                        'True Positive Rate disparity': 'tpr_disparity',\n",
    "                                                        'True Negative Rate disparity': 'tnr_disparity',\n",
    "                                                        'npv_disparity': 'npv_disparity',},\n",
    "                                             layout = local_layout,\n",
    "                                             value = 'fpr_disparity',\n",
    "                                             style = local_style)\n",
    "        \n",
    "        html = '''<h3>Aequitas: </h3> is an open source bias audit toolkit for machine learning developers, \n",
    "        analysts, and  policymakers to audit machine learning models for discrimination and bias,\n",
    "        and make informed and equitable decisions around developing and deploying predictive risk-assessment \n",
    "        tools.'''\n",
    "        display (HTML(html))\n",
    "        display(tab)\n",
    "        \n",
    "        df_aequitas = pd.concat([X_data_frame[protected_attributes_list],\n",
    "                                        y_target,\n",
    "                                        pd.DataFrame(y_pred, \n",
    "                                        index=X_data_frame.index)],\n",
    "                                        axis=1, sort=False);\n",
    "        \n",
    "        df_aequitas.rename(columns={y_column_name: 'label_value', 0: 'score'}, inplace=True);\n",
    "        df_aequitas[df_aequitas.columns.difference(['label_value', 'score'])] = df_aequitas[\n",
    "                                                    df_aequitas.columns.difference(['label_value', 'score'])].astype(str);\n",
    "                \n",
    "        cross_tab, _ =  aeq_Group.get_crosstabs(df_aequitas)\n",
    "        absolute_metrics = aeq_Group.list_absolute_metrics(cross_tab) \n",
    "        #columns not in absolute Matrix\n",
    "        counts_metrics = list (cross_tab[[col for col in cross_tab.columns if col not in absolute_metrics]].columns.values)\n",
    "        counts_metrics.remove('model_id') \n",
    "        counts_metrics.remove('score_threshold') \n",
    "        counts_metrics.remove('k') \n",
    "        \n",
    "        ## Read images from file (because this is binary, maybe you can find how to use ByteIO) but this is more easy\n",
    "        img2 = open('count.png', 'rb').read()\n",
    "        img1 = open('absolute.png', 'rb').read()\n",
    "        ## Create image widgets. You can use layout of ipywidgets only with widgets.\n",
    "        ## Set image variable, image format and dimension.\n",
    "        wi1 = widgets.Image(value=img1, format='png', width=300, height=400)\n",
    "        wi2 = widgets.Image(value=img2, format='png', width=300, height=400)\n",
    "        ## Side by side thanks to HBox widgets\n",
    "        sidebyside = widgets.HBox([wi1, wi2])\n",
    "        ## Finally, show.\n",
    "        \n",
    "        with out1:\n",
    "            clear_output(wait = True)\n",
    "            display (HTML (\"<b>Absolute Metrics across protected groups</b>\"))\n",
    "            display ( cross_tab[['attribute_name', 'attribute_value'] + absolute_metrics].round(2))\n",
    "            display (HTML (\"<br><b>Group counts across protected groups</b>\"))\n",
    "            display ( cross_tab[counts_metrics])\n",
    "            display(sidebyside)\n",
    "\n",
    "            \n",
    "        with out2: #False Positive\n",
    "            clear_output(wait = True)\n",
    "            html = '<b>False Positive Rate</b> - the model predicted the subjects outcome was positive when in fact it was not, in other words an incorrect decision TO recommend!<br>'\n",
    "\n",
    "            if  y_high_positive == True:\n",
    "                html = html + '''<b>* </b>You have indicated that a high outcome(ranking) has a positive impact on an individual\n",
    "                                therefore a high false positive rate will have a <b>positive</b> impact on a group\n",
    "                                '''\n",
    "            elif y_high_positive == False:\n",
    "                html = html + '''<b>* </b>You have indicated that a high outcome(ranking) has a negative impact on an individual\n",
    "                                therefore a high false positive rate will have a <b>negative<b> impact on a group\n",
    "                                '''\n",
    "            display (HTML(html))\n",
    "            fig1, (ax1) = plt.subplots(nrows=1, figsize=(10 ,5));\n",
    "            ax1 = aeq_Plot.plot_group_metric(cross_tab,'fpr', ax1);\n",
    "            plt.tight_layout();\n",
    "            ax1.set_title('False Positive ratios');\n",
    "            plt.show();\n",
    "            plt.close(fig1);\n",
    "            plt.clf();\n",
    "        \n",
    "        \n",
    "        with out3:#False Negative\n",
    "            clear_output(wait = True)\n",
    "            html = '<b>False Negative Rate</b> - the model predicted the subjects outcome was negative when in fact it was not, in other words an incorrect decision TO NOT recommend!<br>'\n",
    "            if  y_high_positive == True:\n",
    "                html = html +  '''<b>* </b>You have indicated that a high outcome(ranking) has a positive impact on an individual\n",
    "                                therefore a high false negative rate will have a <b>negative</b> impact on a group.\n",
    "                                '''\n",
    "            elif y_high_positive == False:\n",
    "                html = html + '''<b>* </b>You have indicated that a high outcome(ranking) has a negative impact on an individual\n",
    "                                therefore a high false negative rate will have a <b>positive impact</> on a group.\n",
    "                                '''\n",
    "            display (HTML(html))\n",
    "            fig1, (ax1) = plt.subplots(nrows=1, figsize=(10 ,5));\n",
    "            ax1 = aeq_Plot.plot_group_metric(cross_tab,'fnr', ax1);\n",
    "            plt.tight_layout();\n",
    "            ax1.set_title('False Negative ratios');\n",
    "            plt.show()\n",
    "            plt.close(fig1);\n",
    "            plt.clf();\n",
    "            \n",
    "        with out4:\n",
    "            clear_output(wait = True)\n",
    "            html = '''<b>Select the metric to view</b><br>''' \n",
    "            if  y_high_positive == True:\n",
    "                html = html +  '''<b>* </b>You have indicated that a high outcome(ranking) has a positive impact on an individual\n",
    "                                '''\n",
    "            elif y_high_positive == False:\n",
    "                html = html + '''<b>* </b>You have indicated that a high outcome(ranking) has a negative impact on an individual\n",
    "                               '''\n",
    "            display (HTML(html))\n",
    "            def show_any(choose_measure):\n",
    "                fig1, (ax1) = plt.subplots(nrows=1);\n",
    "                ax1 = aeq_Plot.plot_group_metric(cross_tab, choose_measure, ax1)\n",
    "                plt.tight_layout()\n",
    "                ax1.set_title(choose_measure)\n",
    "                plt.show()\n",
    "                plt.close(fig1)\n",
    "                plt.clf()\n",
    "            interact(show_any, choose_measure = _choose_measure);\n",
    "   \n",
    "        with out5:\n",
    "            clear_output(wait = True)\n",
    "            dict_of_controls = {}\n",
    "            \n",
    "            dis_imp_html = '''<b>Disparate Impact:</b>. A decision-making process suffers from disparate impact if the outcome \n",
    "            of the decision disproportionately benefits one group or disproportionately hurts another group.\n",
    "            It generally results from unintentional discrimination in decision-making systems.\n",
    "            Disparities are calculated as a ratio of a metric for a group of interest compared to a reference group. \n",
    "            For example, the False Negative Rate Disparity for Group-A compared to a reference Group-B is: FNR-B/FNR-A\n",
    "            The calculated disparities are in relation to a reference group, which will always \n",
    "            have a disparity of 1.0. Disparate impact is often measured by the eighty percent or four-fifths rule. '''\n",
    "            \n",
    "            display (HTML(dis_imp_html))\n",
    "            \n",
    "            display (HTML(\"<b>Select a reference group for each protected feature for comparison:</b>\"))\n",
    "            \n",
    "            for feature in protected_attributes_list:\n",
    "                dict_of_controls[feature] = widgets.Dropdown(description = \"-\" + feature +  \"- Ref group\", \n",
    "                                             options = X_data_frame[feature].dropna().unique(),\n",
    "                                             layout = local_layout,\n",
    "                                             style = local_style)\n",
    "            for c in dict_of_controls:\n",
    "                display(dict_of_controls[c])\n",
    "                \n",
    "                \n",
    "            \n",
    "            display (HTML(\"<b>Select the metric for which you want to view disparities:</b>\"))\n",
    "            def show_disparity(choose_disparity_measure, button): #local method within view_protected() funct\n",
    "                _ref_groups_dict = {}   \n",
    "                for c in dict_of_controls:\n",
    "                    _ref_groups_dict[c] = str(dict_of_controls[c].value)\n",
    "                \n",
    "                disparity = aeq_Bias.get_disparity_predefined_groups(cross_tab, \n",
    "                                                                     original_df=df_aequitas,\n",
    "                                                                     ref_groups_dict=_ref_groups_dict, \n",
    "                                                                     alpha=0.05,\n",
    "                                                                     mask_significance=True); \n",
    "               \n",
    "                num_rows = math.ceil( (len(protected_attributes_list))/2)\n",
    "                \n",
    "                fig = plt.figure(figsize=(12 ,6*num_rows))\n",
    "                plt.tight_layout()\n",
    "                ax_dict = {}\n",
    "                for x, num in zip (protected_attributes_list, range(len(protected_attributes_list))):\n",
    "                    ax_dict[x] = plt.subplot(1, 2, num+1)\n",
    "                    ax_dict[x] = aeq_Plot.plot_disparity(disparity, \n",
    "                                             group_metric=choose_disparity_measure, \n",
    "                                             attribute_name=x,\n",
    "                                             significance_alpha=0.05,\n",
    "                                             fig = fig,\n",
    "                                             ax = ax_dict[x]);\n",
    "                   \n",
    "                if  y_high_positive == True:\n",
    "                    html =   '''<b>* </b>You have indicated that a high outcome(ranking) has a positive impact on an individual\n",
    "                                therefore a XXX disparity score will have a <b>negative</b> impact on a group.<br>\n",
    "                                '''\n",
    "                elif y_high_positive == False:\n",
    "                    html = '''<b>* </b>You have indicated that a high outcome(ranking) has a negative impact on an individual\n",
    "                                therefore a therefore a XXX disparity score  will have a <b>positive impact</> on a group.<br>\n",
    "                                '''\n",
    "                display(HTML(html))\n",
    "                \n",
    "                plt.show()\n",
    "                display(HTML('''Sized based on group size, color based on disparity magnitude<br>\n",
    "                                Reference groups are displayed in grey with disparity = 1. <br>\n",
    "                                Disparities greater than 10x will show as 10x.<br>\n",
    "                                Disparities less than 0.1x will show as 0.1x.<br>\n",
    "                                Statistical siginificance(default 0.05) will show as ** on square.'''))\n",
    "                plt.close(fig1)\n",
    "                plt.clf()\n",
    "                pd.set_option('display.max_columns', None)\n",
    "                display (HTML(\"<b>All Calculated values:</b>\"))\n",
    "                display (disparity)\n",
    "                \n",
    "                with out6:\n",
    "                    clear_output(wait = True)\n",
    "                    for ref in _ref_groups_dict:\n",
    "                        display(HTML(\"Reference group is \" +_ref_groups_dict[ref] + \" for \" + ref))\n",
    "                        display(HTML(\"Green bar indicates Fair.<br>Red bar indicates unfair.\"))\n",
    "                    group_val_fairness= aeq_Fairness.get_group_value_fairness(disparity)\n",
    "                    parity_detrminations = aeq_Fairness.list_parities(group_val_fairness)\n",
    "                    aeq_Plot.plot_fairness_group_all(group_val_fairness, ncols=5, metrics = \"all\")\n",
    "                    display (group_val_fairness[['attribute_name', 'attribute_value']+parity_detrminations])\n",
    "                \n",
    "                \n",
    "            interact(show_disparity, \n",
    "                     choose_disparity_measure = _choose_disparity_measure,\n",
    "                     button = widgets.ToggleButton(\n",
    "                         description='Apply selected Reference group',\n",
    "                         layout = local_layout,\n",
    "                         style = local_style),\n",
    "                     )\n",
    "\n",
    "        \n",
    "        gc.collect()\n",
    "\n",
    "    def visualise_RMSE_model_eval(self, y_train, y_test, y_pred_train, y_pred_test):\n",
    "        y_predictedTrain = y_pred_train\n",
    "        y_predictedTest = y_pred_test\n",
    "        y_test = y_test\n",
    "        y_train = y_train\n",
    "        '''We will be using Root mean squared error(RMSE) and Coefficient of Determination(R² score) to evaluate our model.\n",
    "        RMSE is the square root of the average of the sum of the squares of residuals. \n",
    "        The RMSE is the square root of the variance of the residuals. \n",
    "        #It indicates the absolute fit of the model to the data–how close the observed data points are to the model’s\n",
    "        #predicted values. Whereas R-squared is a relative measure of fit, RMSE is an absolute measure of fit. \n",
    "        #As the square root of a variance, RMSE can be interpreted as the standard deviation of the unexplained variance, \n",
    "        #and has the useful property of being in the same units as the response variable. \n",
    "        #Lower values of RMSE indicate better fit. \n",
    "        #RMSE is a good measure of how accurately the model predicts the response, and it is the most important criterion\n",
    "        #for fit if the main purpose of the model is prediction.\n",
    "\n",
    "        #Coefficient of Determination(R² score) - The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). \n",
    "        #A constant model that always predicts the expected value of y, disregarding the input features, \n",
    "        #would get a R^2 score of 0.0. #R-squared is between 0 and 1, Higher values are better because it means \n",
    "        #that more variance is explained by the model.'''\n",
    "\n",
    "        display(\"*****EVALUATING MODEL WITH TRAINING DATA:***\")\n",
    "        rmse = mean_squared_error(y_train, y_predictedTrain)\n",
    "        r2 = r2_score(y_train, y_predictedTrain)\n",
    "        display(' Root mean squared error: '+ str(rmse))\n",
    "        display(' R2 score: '+ str(r2))\n",
    "\n",
    "        display(\"*****EVALUATING MODEL WITH TEST DATA:******\")\n",
    "        rmse = mean_squared_error(y_test, y_predictedTest)\n",
    "        r2 = r2_score(y_test, y_predictedTest)\n",
    "        display(' Root mean squared error: ' + str(rmse))\n",
    "        display(' R2 score: '+ str(r2))\n",
    "\n",
    "        n_train = len(y_train)\n",
    "\n",
    "        plt.figure(figsize=(20, 10))\n",
    "        plt.plot(range(n_train), y_train, label=\"train\")\n",
    "        plt.plot(range(n_train, len(y_test) + n_train), y_test, '-', label=\"test\")\n",
    "        plt.plot(range(n_train), y_predictedTrain, '--', label=\"prediction train\")\n",
    "\n",
    "        plt.plot(range(n_train, len(y_test) + n_train), y_predictedTest, '--', label=\"prediction test\")\n",
    "        plt.legend(loc=(1.01, 0))\n",
    "        plt.xlabel(\"Score\")\n",
    "        plt.ylabel(\"prediction\")\n",
    "        \n",
    "        \n",
    "        \n",
    "    def reload_data (self, pickle_path, data_frame_path, print_report = True):\n",
    "    # Reload the file\n",
    "        data_summary = dill.load(open(pickle_path, \"rb\"))\n",
    "        data_frame = pd.read_csv(data_frame_path)\n",
    "        display (HTML('''<b>Values saved in data_summary</b> <br>  \n",
    "        data_summary.renamed <br>\n",
    "        data_summary.referenceNames<br>\n",
    "        data_summary.label_encoding_dict<br>\n",
    "        data_summary.oh_encoding_dict<br>\n",
    "        data_summary.df_url<br>\n",
    "        data_summary.y_value<br>\n",
    "        data_summary.Y_BINARY<br>\n",
    "        data_summary.Y_CONTINUOUS<br>\n",
    "        data_summary.HIGH_RANGE_POSITIVE<br>\n",
    "        data_summary.protected_x<br>\n",
    "        data_summary.non_protected_x<br>\n",
    "        data_summary.all_columns_in_x<br>\n",
    "        data_summary.proxyAttributes<br>\n",
    "        data_summary.MLAttributes<br>\n",
    "        data_summary.html'''))\n",
    "        if print_report == True:\n",
    "            print(\"Number of samples in dataset: \", data_frame.shape[0])\n",
    "            print (\"Output to predict: \", data_summary.y_value)\n",
    "            print (\"Output is continuous: \", data_summary.Y_CONTINUOUS)\n",
    "            print (\"Output is binary: \", data_summary.Y_BINARY)\n",
    "            print (\"Num of unique outputs: \", len(data_frame[data_summary.y_value].dropna().unique()))\n",
    "            print (\"Min output: \", data_frame[data_summary.y_value].min())\n",
    "            print (\"Max output: \", data_frame[data_summary.y_value].max())\n",
    "            print (\"High output range is positive? \", data_summary.HIGH_RANGE_POSITIVE)\n",
    "            #print (\"High ranking is by default \", data_summary.y_mid_rank, \" to \", data_summary.y_max_rank)\n",
    "            #print (\"Low ranking is by default \",data_summary.y_min_rank , \" to \", data_summary.y_mid_rank)\n",
    "            print (\"\")\n",
    "            print (\"Protected input features\", data_summary.protected_x)\n",
    "            print (\"Other input features\", data_summary.non_protected_x)\n",
    "            print(\"\")\n",
    "            print (\"Summary of Data transformation per input feature:\")\n",
    "            for key in data_summary.html:\n",
    "                if data_summary.html[key] != \"\":\n",
    "                    print (\"************\")\n",
    "                    print (key)\n",
    "                    display (HTML (data_summary.html[key]))\n",
    "        \n",
    "            print (\"\")\n",
    "            print (\"Input Features identified as possible proxies to protected Features: \", data_summary.proxyAttributes)\n",
    "            print (\"\")\n",
    "            print (\"Input Features identified as possibly output from another ML Model: \", data_summary.MLAttributes)\n",
    "            print (\"\")\n",
    "            print (\"\")\n",
    "            print (\"The X and y Values to be used in Model Train/Test/Validate\")\n",
    "            display (data_frame[data_summary.protected_x+data_summary.non_protected_x+[data_summary.y_value]].head())\n",
    "            print (\"\")\n",
    "            print (\"\")\n",
    "            print (\"\")\n",
    "            print (\"All versions of all columns to be used for analysis of Test/Validate\")\n",
    "        return data_frame, data_summary\n",
    "    \n",
    " \n",
    "        \n",
    "    #################################################################################################\n",
    "    # Detect outliers and return for one column in dataset.\n",
    "    # We find the z score for each of the data point in the dataset \n",
    "    # and if the z score is greater than 3 than we can classify that point as an outlier. \n",
    "    # Any point outside of \"thresh\" = 3 standard deviations would be an outlier.\n",
    "    # \n",
    "    #################################################################################################\n",
    "    def detect_outlier_and_describe(self, series, thresh = 3, data_type = \"numeric\"):\n",
    "        outliers=[]\n",
    "        threshold=thresh\n",
    "        size = series.count()\n",
    "        missing =  series.isnull().sum()\n",
    "        unique = len(series.unique())\n",
    "        pcnt_missing = missing/size *100\n",
    "        html = \"\"\n",
    "        if data_type == \"numeric\":\n",
    "            mean_1 = np.mean(series)\n",
    "            std_1 =np.std(series)\n",
    "        \n",
    "            html = \"Outlier is defind as any point outside \" + str(thresh) + \" standard deviations<br>\" \n",
    "            html = html + \"Min: \" + str(np.min(series)) + \"<br>\"\n",
    "            html = html + \"Max: \" + str( np.max(series)) + \"<br>\"\n",
    "            html = html + \"Mean: \" + str( mean_1) + \"<br>\"\n",
    "            html = html + \"Standard Deviation: \"+ str( std_1) + \"<br>\"\n",
    "            for y in series:\n",
    "                z_score= (y - mean_1)/std_1 \n",
    "                if np.abs(z_score) > threshold:\n",
    "                    outliers.append(y)\n",
    "            html = html + \"Number of outliers: \"+ str( len(outliers)) + \"<br>\"\n",
    "            html = html + \"Outliers: \"+ str(outliers) + \"<br>\"\n",
    "        \n",
    "\n",
    "         \n",
    "        html = html + \"Number of observations: \"+ str( size) + \"<br>\"\n",
    "        html = html + \"Num of unique values: \"+ str(unique) + \"<br>\"\n",
    "        html = html + \"Missing cells: \"+ str( missing) + \"<br>\"\n",
    "        html = html + \"Missing cells%: \"+ str( missing) + \"<br>\"\n",
    "        \n",
    "        \n",
    "        return html, outliers\n",
    "    \n",
    "        \n",
    "    #################################################################################################\n",
    "    #  \n",
    "    # \n",
    "    #################################################################################################\n",
    "    \n",
    "    def get_train_test_split_data(self, data_frame, data_summary, include_protected):\n",
    "        if include_protected == True:\n",
    "            cols = data_summary.protected_x + data_summary.non_protected_x\n",
    "        else:\n",
    "            cols = data_summary.non_protected_x\n",
    "        return  data_frame.drop(data_summary.y_value, axis = 1), data_frame[data_summary.y_value], cols\n",
    "    \n",
    "    \n",
    "    \n",
    "    def shap_analysis(self, shap_values, explainer, x, data_summary):\n",
    "        try:\n",
    "            shap.initjs()\n",
    "        except:\n",
    "            print ( 'shap.initjs() failed to load javascript')\n",
    "        \n",
    "        outOverview = widgets.Output(layout={})\n",
    "        out1 = widgets.Output(layout={})\n",
    "        out2 = widgets.Output(layout={})\n",
    "        out3 = widgets.Output(layout={})\n",
    "        out4 = widgets.Output(layout={})\n",
    "        out5 = widgets.Output(layout={})\n",
    "        tab_contents = [out1, out2, out3, out4, out5]\n",
    "        \n",
    "        children = tab_contents\n",
    "        tab = widgets.Tab(style={'description_layout':'auto', 'title_layout':'auto'})\n",
    "        tab.children = children\n",
    "        \n",
    "        tab.set_title(0, \"Summary Importance plot\")\n",
    "        tab.set_title(1, \"Importance plot\")\n",
    "        tab.set_title(2, \"Dependence plot\")\n",
    "        tab.set_title(3, \"Individual force plot\")\n",
    "        tab.set_title(4, \"Collective force plot\")\n",
    "        \n",
    "        local_layout = {'width': 'auto', 'visibility':'visible'}\n",
    "        local_layout_hidden  = {'width': 'auto', 'visibility':'hidden'}\n",
    "        local_style = {'description_width':'initial'}\n",
    "        display(outOverview)\n",
    "        display(tab)\n",
    "        \n",
    "        \n",
    "        _choose = widgets.Dropdown(description = \"Select Feature\", \n",
    "                                    options = data_summary.protected_x + data_summary.non_protected_x,\n",
    "                                    layout = local_layout,\n",
    "                                    style = local_style)\n",
    "        all_comb = {}\n",
    "        for f in data_summary.protected_x:\n",
    "            for a in  x[f].unique():\n",
    "                all_comb[(f+\":\"+ str(a))] = a\n",
    "        \n",
    "        _protected = widgets.Dropdown(description = \"Filter by Protected Feature\", \n",
    "                                     options = all_comb,\n",
    "                                     layout = local_layout,\n",
    "                                     style = local_style)\n",
    "        \n",
    "        toggle = widgets.ToggleButton(\n",
    "                            value=False,\n",
    "                            description='Generate',\n",
    "                            disabled=False,\n",
    "                            button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
    "                            \n",
    "                            )\n",
    "        \n",
    "        with outOverview:\n",
    "            display (HTML('''<h3>SHAP</h3>(SHapley Additive exPlanations) KernelExplainer is a \n",
    "            model-agnostic method which builds a weighted linear regression by using training/test data, \n",
    "            training/test predictions, and whatever function that predicts the predicted values. \n",
    "            SHAP values represent a feature's responsibility for a change in the model output.\n",
    "            It computes the variable importance values based on the Shapley values from game theory, \n",
    "            and the coefficients from a local linear regression. </br>\n",
    "            see: https://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions.pdf <br>\n",
    "\n",
    "            It offer a high level of interpretability for a model, through two distinct approaches:\n",
    "\n",
    "            <b>Global interpretability</b> — the SHAP values can show how much each predictor contributes, \n",
    "            either positively or negatively, to the target variable. Similar to a variable importance plot however it also indicates the positive or negative relationship between each feature and the target output.\n",
    "\n",
    "            <b>Local interpretability</b> — each observation is assigned it's own SHAP value. \n",
    "            This provides a very granular level of transparency and interpretability where we can \n",
    "            determine why an individual cases receive a specific prediction  and the contribution of \n",
    "            each feature to the prediction. Generally speaking variable importance algorithms usually \n",
    "            only show the results across the entire dataset but not on each individual case.'''))\n",
    "            \n",
    "        with out1:\n",
    "          \n",
    "            html_desc = '''\n",
    "            <b>Summary importance plot </b><br><b>Feature importance:</b> Variables are ranked in descending order. The top variables contribute more to the model than the bottom ones and thus have high predictive power.<br>\n",
    "            ''' \n",
    "            wi1 = widgets.Output(layout=Layout(width='60%'))\n",
    "            with wi1:\n",
    "                shap.summary_plot(shap_values, x, plot_type=\"bar\"); \n",
    "            wi2 = widgets.HTML(value=html_desc,layout=Layout(width='30%') ) ; \n",
    "            sidebyside = widgets.HBox([wi1, wi2])\n",
    "            display (sidebyside)\n",
    "        with out2:\n",
    "            display (HTML('''<b>Importance plot:</b> lists the most significant variables in descending order. \n",
    "                          The top variables contribute more to the model than the bottom ones and thus have high predictive power.'''))\n",
    "            html_desc = '''\n",
    "            <b>Feature importance:</b> Variables are ranked in descending order.<br>\n",
    "            <b>Impact:</b> Horizontal location indicates if effect of feature is associated with a higher or lower prediction.<br>\n",
    "            <b>Original value:</b> Colour indicates if feature variable is high(red) or low(blue) for the particular observation.<br>\n",
    "            <b>Correlation:</b> A high or low impact(indicated by colour), a positive or negative impact(indicated by position on x-axis)\n",
    "                '''  \n",
    "            wi1 = widgets.Output(layout={})\n",
    "            with wi1:\n",
    "                shap.summary_plot(shap_values, x);\n",
    "            wi2 = widgets.HTML(value=html_desc,layout=Layout(width='30%') )  \n",
    "            sidebyside = widgets.HBox([wi1, wi2])\n",
    "            display (sidebyside)\n",
    "                \n",
    "        with out3:\n",
    "            \n",
    "            display (HTML (\"The decision variable is \" + str(data_summary.y_value)))\n",
    "            display (HTML ('''To understand how a single feature effects the output of the model a \n",
    "                             dependency plot plots the SHAP value of  that feature vs. the value of \n",
    "                             the feature for all the examples in a dataset.'''))\n",
    "            def show_dependancy_plot(choose):\n",
    "                html_desc = '''The dependency plots show relationship between the target ('''+ data_summary.y_value +  ''') \n",
    "                   and the selected feature ('''+ choose + ''') to review if it is linear, monotonic or \n",
    "                  more complex.  The additionla variable is the variable that the selected feature (''' + choose + ''') \n",
    "                  interacts with the most frequently. Vertical dispersion at a single value represents interaction \n",
    "                  effects with the other features.  '''\n",
    "                display (HTML(html_desc))\n",
    "                display (shap.dependence_plot(choose, shap_values, x))\n",
    "            interact(show_dependancy_plot, choose = _choose);\n",
    "    \n",
    "        with out4:\n",
    "            display (HTML (\"The decision variable is \" + str(data_summary.y_value)))\n",
    "            display (HTML ('''<b>Individual Force plot</b> shows the features which each contribute to push the model output \n",
    "                            from the base value (the average model output over the dataset passed) to the\n",
    "                            model output. Features pushing the prediction higher are shown in red, \n",
    "                            those pushing the prediction lower are shown in blue.'''))\n",
    "            # visualize the first prediction's explanation (use matplotlib=True to avoid Javascript)\n",
    "            display (HTML (\"<b>Generate random sample to investigate:</b>\"))\n",
    "            def show_individual_force_plot(protected, toggle):\n",
    "                feat = _protected.label.split(':')[0]\n",
    "                index = x[x[feat] == _protected.value].sample(1).index[0]\n",
    "                display (shap.force_plot(explainer.expected_value, \n",
    "                                     shap_values[index,:], \n",
    "                                     x.iloc[index,:],\n",
    "                                     matplotlib=True))\n",
    "            \n",
    "            interact(show_individual_force_plot, protected = _protected, toggle = toggle);\n",
    "         \n",
    "        with out5:\n",
    "            display (HTML (\"The decision variable is \" + str(data_summary.y_value)))\n",
    "            display (HTML ('''<b>Collective Force plot</b> A combination of all individual force plots, each rotated 90 degrees, and stacked\n",
    "                                horizontally, to explanation an entire dataset.'''))\n",
    "            display (shap.force_plot(explainer.expected_value, \n",
    "                                     shap_values, \n",
    "                                     x))\n",
    "\n",
    "    #################################################################################################\n",
    "    #  \n",
    "    # \n",
    "    #################################################################################################\n",
    "    def get_protected (self, summary):\n",
    "        return summary.protected_x\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #################################################################################################\n",
    "    #  \n",
    "    # \n",
    "    #################################################################################################\n",
    "    def get_protected_before_merge (self, summary):\n",
    "        return summary.all_columns_in_x\n",
    "        print (list([all_columns_in_x.contains('_bm')]))\n",
    "        print (list(X_train.columns[X_train.columns.str.contains('_benc')]))\n",
    "\n",
    "    \n",
    "    #################################################################################################\n",
    "    #  \n",
    "    # \n",
    "    #################################################################################################\n",
    "    def get_protected_before_transform (self, summary):\n",
    "        all_cols = summary.all_columns_in_x\n",
    "        prot = summary.protected_x\n",
    "\n",
    "        new_prot = []\n",
    "        for f in prot:\n",
    "            found = False\n",
    "            if f+'_bm' in all_cols:\n",
    "                new_prot.append(f+'_bm')\n",
    "                found = True\n",
    "            if f+'_benc' in all_cols:\n",
    "                new_prot.append(f+'_benc')\n",
    "                found = True\n",
    "            if f.endswith('_oh_benc'):\n",
    "                new_prot.append(f)\n",
    "                found = True\n",
    "        \n",
    "            if found == False:\n",
    "                new_prot.append(f)\n",
    "        return new_prot\n",
    "    \n",
    "    \n",
    "    #################################################################################################\n",
    "    #  \n",
    "    # \n",
    "    #################################################################################################\n",
    "    def prepare_to_shap(self, X_in, count = 100, save_to_path = './'):\n",
    "        x = shap.sample( X_in, count)\n",
    "        x = x.reset_index(drop=True)\n",
    "        explainer = shap.KernelExplainer(logistic_reg_model.predict, x ) # The second argument is the \"background\" dataset; a size of 100 rows is gently encouraged by the code\n",
    "        shap_values = explainer.shap_values(x, l1_reg=\"num_features(10)\")\n",
    "        print(f'length of SHAP values: {len(shap_values)}')\n",
    "        print(f'Shape of each element: {shap_values[0].shape}')\n",
    "        path =  save_to_path + \"shap_values.pickle\"\n",
    "        print (\"Shap_values saved to\", path)\n",
    "        dill.dump(shap_values, file = open(path, \"wb\"))\n",
    "        path =  save_to_path + \"shap_explainer.pickle\"\n",
    "        print (\"Shap_explainer saved to\", path)\n",
    "        dill.dump(explainer, file = open(path, \"wb\"))\n",
    "        path =  save_to_path +\"shap_x.pickle\"\n",
    "        print (\"Shap_explainer saved to\", path)\n",
    "        dill.dump(x, file = open(path, \"wb\"))\n",
    "        return explainer, shap_values, x\n",
    "\n",
    "    \n",
    "    #################################################################################################\n",
    "    #  \n",
    "    # \n",
    "    #################################################################################################\n",
    "    def reload_shap_data (self, _path):\n",
    "        path = _path \n",
    "        shap_values_path = path + \"/shap_values.pickle\"\n",
    "        explainer_path = path + \"/shap_explainer.pickle\"\n",
    "        x_path = path + \"/shap_x.pickle\"\n",
    "        shap_values = dill.load(open(shap_values_path, \"rb\"))\n",
    "        explainer = dill.load(open(explainer_path, \"rb\"))\n",
    "        x = dill.load(open(x_path, \"rb\"))\n",
    "        # Reload the file\n",
    "        return shap_values, explainer, x\n",
    "    \n",
    "    \n",
    "    #################################################################################################\n",
    "    #  \n",
    "    # \n",
    "    #################################################################################################\n",
    "    def get_features_type(self, df, unique_max):\n",
    "        cat = []\n",
    "        obj = []\n",
    "        for col in df.select_dtypes(include='number').columns:\n",
    "            if len(df[col].dropna().unique()) <= unique_max:\n",
    "                cat.append(col)\n",
    "        for col in df.select_dtypes(include='object').columns:\n",
    "            if len(df[col].dropna().unique()) <= unique_max:\n",
    "                obj.append(col)\n",
    "\n",
    "        all_categorical = cat + obj \n",
    "        all_numeric = list (df.columns)\n",
    "        all_numeric = [ele for ele in all_numeric if ele not in all_categorical] \n",
    "        return all_categorical, all_numeric\n",
    "    \n",
    "    \n",
    "    \n",
    "    #################################################################################################\n",
    "    #  \n",
    "    # \n",
    "    #################################################################################################\n",
    "    def get_feature_info (self, feature, unique_values, group_descriptions_dict, label_encoding_dict, oh_encoding_dict, merged_dict, trace = False):\n",
    "        values = unique_values\n",
    "        decoded_values = []\n",
    "        original_values = []\n",
    "        label_encoded_values = []\n",
    "        \n",
    "        keys = []\n",
    "        \n",
    "        if feature in oh_encoding_dict:\n",
    "            original_feature_bohe = oh_encoding_dict[feature][\"Original_col\"]\n",
    "            original_value_bohe = oh_encoding_dict[feature][\"Original_val\"]\n",
    "            if trace == True:\n",
    "                print (\"One Hot Encoded from feature:\", original_feature_bohe, \"value:\",original_value_bohe)\n",
    "                print (\"One Hot Encoded values:\", values)\n",
    "            _choice_dict_for_drop = dict(zip(values, values))\n",
    "            original_values = values\n",
    "            label_encoded_values = []\n",
    "            descriptions = values\n",
    "            return _choice_dict_for_drop, original_values, label_encoded_values, descriptions\n",
    "            \n",
    "        def get_key(val): #local method in get_feature_info\n",
    "            for key, value in label_encoding_dict[feature].items(): \n",
    "                if val == value: \n",
    "                    return key \n",
    "            return None\n",
    "        \n",
    "        #if feature is already encoded then unique_values will be the encoded versions\n",
    "        #If feature does not have a description saved then return {x:x, y:y etc} as\n",
    "        #the key value pairs for any dropdown. regardless of encoded or not.\n",
    "        if feature not in group_descriptions_dict:\n",
    "            original_values = values \n",
    "            if feature in label_encoding_dict:\n",
    "                for value in values:\n",
    "                    decoded_values.append(get_key(value))\n",
    "                    original_values = decoded_values\n",
    "                    label_encoded_values = values \n",
    "                descriptions = original_values\n",
    "                _choice_dict_for_drop = dict(zip(original_values, label_encoded_values))\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                _choice_dict_for_drop = dict(zip(values, values))\n",
    "                descriptions = values\n",
    "            \n",
    "            if trace == True:\n",
    "                print (\"Original values \", original_values)\n",
    "                print (\"Label Encoded values \", label_encoded_values )\n",
    "                print (\"Description \",  descriptions )\n",
    "                print (\"Key/Value for dropdown: \", _choice_dict_for_drop)\n",
    "            \n",
    "            return _choice_dict_for_drop, original_values, label_encoded_values, descriptions\n",
    "        \n",
    "        \n",
    "        if feature in group_descriptions_dict:\n",
    "            #first check if the input feature unique_values are the result of an Encode\n",
    "            if feature in label_encoding_dict:\n",
    "                for value in values:\n",
    "                    decoded_values.append(get_key(value))\n",
    "                original_values = decoded_values\n",
    "                label_encoded_values = values\n",
    "                if trace == True:\n",
    "                    print (\"Original values \", original_values)\n",
    "                    print (\"Label Encoded values \", label_encoded_values )\n",
    "             \n",
    "            if feature not in label_encoding_dict:\n",
    "                original_values = values\n",
    "                label_encoded_values = []\n",
    "                if trace == True:\n",
    "                    print (\"Original values \", original_values)\n",
    "                    print (\"Label Encoded values \", label_encoded_values )\n",
    "                \n",
    "            for key in original_values:\n",
    "                if key not in group_descriptions_dict[feature]:\n",
    "                    keys.append(key)\n",
    "                else:\n",
    "                    keys.append(group_descriptions_dict[feature][key])\n",
    "        # using zip() \n",
    "        # to convert lists to dictionary \n",
    "            _choice_dict_for_drop = dict(zip(keys,values))\n",
    "            descriptions = keys\n",
    "            if trace == True:\n",
    "                print (\"Description: \", keys)\n",
    "                print (\"Key/Value for dropdown: \", _choice_dict_for_drop)\n",
    "                if feature in merged_dict:\n",
    "                    print (\"Merged Values: \", merged_dict[feature])\n",
    "        return _choice_dict_for_drop, original_values, label_encoded_values, descriptions\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    #################################################################################################\n",
    "    #  \n",
    "    # \n",
    "    #################################################################################################\n",
    "    def phi_k_correlation(self, df):\n",
    "        intcols = []\n",
    "        selcols = []\n",
    "        for col in df.columns.tolist():\n",
    "            try:\n",
    "                tmp = (\n",
    "                        df[col]\n",
    "                        .value_counts(dropna=False)\n",
    "                        .reset_index()\n",
    "                        .dropna()\n",
    "                        .set_index(\"index\")\n",
    "                        .iloc[:, 0]\n",
    "                    )\n",
    "                if tmp.index.inferred_type == \"mixed\":\n",
    "                    continue\n",
    "\n",
    "                if pd.api.types.is_numeric_dtype(df[col]):\n",
    "                    intcols.append(col)\n",
    "                    selcols.append(col)\n",
    "                elif df[col].nunique() <= config[\n",
    "                    \"categorical_maximum_correlation_distinct\"\n",
    "                ].get(int):\n",
    "                    selcols.append(col)\n",
    "            except (TypeError, ValueError):\n",
    "                continue\n",
    "\n",
    "        if len(selcols) > 1:\n",
    "            correlation = df[selcols].phik_matrix(interval_cols=intcols)\n",
    "\n",
    "            return correlation\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    #################################################################################################\n",
    "    #  \n",
    "    # \n",
    "    #################################################################################################\n",
    "    def Benfords_law(self, df, feature, protected):\n",
    "        groups = df[protected].dropna().unique()\n",
    "        tab = widgets.Tab()\n",
    "        widget_arr = {}\n",
    "        tab_titles = []\n",
    "        fit_output = widgets.Output(layout={})       \n",
    "                    \n",
    "        for group in groups:\n",
    "            filtered = df[df[protected]==group]\n",
    "            X = filtered[feature].values\n",
    "            # # Make fit\n",
    "            with fit_output:\n",
    "                out = bl.fit(X)\n",
    "            # # Plot\n",
    "            widget_arr[group] = widgets.Output(layout={})\n",
    "            with widget_arr[group]:\n",
    "                display(bl.plot(out,\n",
    "                        title='Benfords law for '+ str(feature) + ' and group '+ str(group),  \n",
    "                        figsize=(8,4)));\n",
    "            tab_titles.append(str(group))\n",
    "        widget_arr[\"Output\"] = fit_output\n",
    "        tab.children = list(widget_arr.values())\n",
    "        \n",
    "        for x in range(len(tab_titles)):\n",
    "            tab.set_title(x, tab_titles[x])\n",
    "        tab.set_title(x+1,\"Output Trace\")\n",
    "        return tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  di_rule_html =''''Eighty percent rule is a rule of thumb or a guideline applied to the measurement of \n",
    "        disparate impact whereby a selection rate for  a protected group-A which is less than 80% of the\n",
    "         selection rate for group-B, where group-B is the group with the highest selection rate, will generally \n",
    "         be considered as evidence of adverse impact against group-A. The eighty percent rule does not\n",
    "         incorporate probability distribution to determine if the disparity is as a result of chance and therefor is not a definitive \n",
    "         test.''' \n",
    "    \n",
    "\n",
    "# Precision or  positive predictive value(PPV) is the proportion of the individuals with a positive test result for which the true\n",
    "# condition is positive. This rate is sometimes called the precision.\n",
    "#                     print ('''The ppr and difference in means are more generalized fairness metrics, since they \n",
    "#                     only consider how much the outcome differs between the protected groups. \n",
    "#                     This plot will show a Gi% probability for a member of group Gi to obtain a positive outcome. \n",
    "#                     The rate of this metric denotes Disparate Impact''')\n",
    "             \n",
    "        \n",
    "#                 .plot_fairness_group(group_val_fairness, group_metric='fpr')\n",
    "#                 .plot_fairness_group(group_val_fairness, group_metric='fnr'\n",
    "#                 .plot_fairness_group(group_val_fairness, group_metric='ppr')\n",
    "\n",
    "\n",
    "#                 html_parity = \"\"\"Considering the rule of thumb a parity should be between 0.5 and 1.5, \n",
    "#                 The disparate impact still shows that men are somewhat favored over women,\n",
    "#                 but the difference is not much reduced. Based on the false negative ratio parity \n",
    "#                 we can say that we managed to mitigate the bias, but the model is still unfair. \"\"\"\n",
    "                \n",
    "                \n",
    "#         except Exception as e:\n",
    "#             self.display_html(\"Something went wrong viewing Aequitas fairness metrics\", self.text_color, \"h4\")\n",
    "#             print (e)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": "30",
    "lenType": "30",
    "lenVar": "200"
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
